[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics for Social Work",
    "section": "",
    "text": "Welcome to SW 8409: Statistics II\nThis book integrates statistical concepts with real-world applications, focusing on equitable data analysis and actionable insights. It is designed for social work researchers, activists, and students seeking to harness the power of data for transformative change.\nThe book is built for my Stats II course in the College of Social Work at The Ohio State University.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistics for Social Work</span>"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus: Statistics for Social Work",
    "section": "",
    "text": "Miscellaneous Course Policies\nPlease download the OSU and CSW course policies that are incorporated by reference within this course.",
    "crumbs": [
      "**Course Overview**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Syllabus: Statistics for Social Work</span>"
    ]
  },
  {
    "objectID": "syllabus.html#course-information",
    "href": "syllabus.html#course-information",
    "title": "Syllabus: Statistics for Social Work",
    "section": "Course Information",
    "text": "Course Information\nCourse Title: Statistics II: Equity-Focused Data Analysis\nInstructor: Dr. Gia Elise Barboza-Salerno\nInstitution: College of Social Work, The Ohio State University\nTerm: Spring 2026",
    "crumbs": [
      "**Course Overview**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Syllabus: Statistics for Social Work</span>"
    ]
  },
  {
    "objectID": "syllabus.html#contact-information",
    "href": "syllabus.html#contact-information",
    "title": "Syllabus: Statistics for Social Work",
    "section": "Contact Information",
    "text": "Contact Information\nOffice Hours: Mondays 2–4 PM, or by appointment.\nEmail: barboza-salerno@osu.edu",
    "crumbs": [
      "**Course Overview**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Syllabus: Statistics for Social Work</span>"
    ]
  },
  {
    "objectID": "Assignments.html",
    "href": "Assignments.html",
    "title": "Assignments and Due Dates",
    "section": "",
    "text": "Schedule of Exercises and Due Dates\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nExercises and Deliverables\nDue Date\n\n\n\n\nWeek 1\nIntroduction to the Course\nBegin thinking about how to use data to reclaim your story.\nN/A\n\n\nWeek 2\nPre-Course Assessment\nComplete pre-course assessment.\nJanuary 13, 2025\n\n\nWeek 3\nNo Class - MLK Day\nN/A\nN/A\n\n\nWeek 4\nSimple Regression\nInteractive Escape Room Exercise.Data Makeover Challenge: Reimagine data using storytelling.\nJanuary 27, 2025\n\n\nWeek 5\nMultiple Regression\nHypothesis Auction: Justify chosen testable hypotheses.Explain regression results to argue for policy change. Assignment 1 Distributed.\nMarch 3, 2025\n\n\nWeek 6\nEffect Sizes & Confidence Intervals\nDebate Exercise: Practical and legal significance of findings.Write an op-ed on significance.\nFebruary 10, 2025\n\n\nWeek 7\nAssumptions and Violations of Assumptions\nAssumption Diagnosis Clinic: Diagnose and “treat” assumption violations.Create a “prescription card” summarizing fixes.\nFebruary 17, 2025\n\n\nWeek 8\nHierarchical Regression & Dummy Variables\nRegression Battle: Build the best hierarchical model.Write a brief on ethical implications of dummy variable coding.\nFebruary 24, 2025\n\n\nWeek 9\nLogistic Regression\nPredictive Policy Game: Use predictions for interventions.Create a policy recommendation.Submit Assignment 1.\nMarch 3, 2025\n\n\nWeek 10\nSpring Break\nN/A\nN/A\n\n\nWeek 11\nMediation & Suppressor Variables\nData Detective Roleplay: Investigate intervention mechanisms.Examine a “case file” for mediation analysis. Assignment 2 Distributed.\nMarch 17, 2025\n\n\nWeek 12\nModeration in Regression\nBuild-a-Story Workshop: Narratives around moderation analysis. Create a 1-page illustrated story on moderation findings.\nMarch 24, 2025\n\n\nWeek 13\nExploratory Factor Analysis (EFA)\nFactor Scavenger Hunt: Interpret factor loadings.Create an infographic summarizing EFA findings.\nMarch 31, 2025\n\n\nWeek 14\nConfirmatory Factor Analysis (CFA)\nModel Critique Workshop: Propose refinements to a CFA model.Submit a report evaluating and refining the CFA model.\nApril 7, 2025\n\n\nWeek 15\nLatent Class Analysis (LCA)\nLatent Storytelling: Use LCA findings to understand group experiences.Create a “persona deck” illustrating latent group characteristics.Submit Assignment 2.\nApril 14, 2025\n\n\nWeek 16\nStudent Presentations and Review\nPresent Final Project.Review the course content.\nApril 21, 2025\n\n\nFinal Exam\nCreate, Validate, and Apply Scales\nTake Final Exam or Submit a Publishable Manuscript.\nApril 28, 2025",
    "crumbs": [
      "**Course Overview**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignments and Due Dates</span>"
    ]
  },
  {
    "objectID": "01-introduction.html",
    "href": "01-introduction.html",
    "title": "Introduction to the Course",
    "section": "",
    "text": "Course Goals and Objectives\nThe course, Statistics II focuses on an equitable approach to data analysis. It aims to equip students with advanced statistical techniques while fostering critical thinking about how to apply those models to social work applications. I have tried to find a good balance of instruction, innovation, and hands-on learning. I want you to be excited about statistics and data; hence, I have tried to stucture the course in a way that encourages you to explore regression, measurement, and latent variable models in the context of social justice. By emphasizing storytelling and data interpretation, students will develop the skills needed to reclaim and communicate narratives of oppression, focusing on equity and systemic challenges. The course also focuses on practical applications, such as building models and interpreting statistical findings to support policy changes and advocate for marginalized communities.\nOne of the course’s primary objectives is to prepare students to use statistics as a tool for actionable change. Weekly sessions integrate technical skills, such as using R for data analysis and visualization, with real-world social work challenges. Activities like the “Data Makeover Challenge” and “Latent Storytelling” push students to think creatively about data, while assignments emphasize ethical implications and advocacy. My idea about writing an oped comes from the workshop I did in the summer of 2024, where I learned how to write one effectively. You can read it here.\nI have also tried very hard to make the course integrative. That is the reason for this website. There are (and will be) links between modules, readings, and assignments so that everything is connected as it should be. This is obviously a lot of work, so I appreciate your patience, and consideration.\nHopefully, by the end of the semester, students will have gained not only proficiency in statistical methods but also the confidence to apply them meaningfully to address pressing social issues.",
    "crumbs": [
      "**Course Overview**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introduction to the Course</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html",
    "href": "02-simple-regression.html",
    "title": "Introduction to Simple Linear Regression",
    "section": "",
    "text": "Week 3: January 27, 2026",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#todays-reading",
    "href": "02-simple-regression.html#todays-reading",
    "title": "Introduction to Simple Linear Regression",
    "section": "Today’s Reading",
    "text": "Today’s Reading\n\nDiez et al., Chapter 8, pp. 304-340. Intro to linear regression. Be sure to check out the embedded videos.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#simple-linear-regression-introduction-to-the-topic",
    "href": "02-simple-regression.html#simple-linear-regression-introduction-to-the-topic",
    "title": "Introduction to Simple Linear Regression",
    "section": "Simple Linear Regression – Introduction to the Topic",
    "text": "Simple Linear Regression – Introduction to the Topic\nThis week, we will delve into Simple Linear Regression, a foundational tool in statistical analysis that allows us to model relationships between two variables. Students will learn how to interpret the slope, intercept, and residuals, and use regression output to draw meaningful conclusions about data. Through this process, students will develop a deeper understanding of how regression can be used to predict outcomes and test hypotheses in social work research.\nIn this unit we will learn to quantify the relationship between two numerical variables, as well as modeling numerical response variables using a numerical or categorical explanatory variable.\n\n\nWhat will students learn this week?\n\nThe fundamental components of a simple linear regression model (slope, intercept, and residuals).\nHow to interpret regression output, including unstandardized and standardized coefficients.\nThe practical steps to fit a simple linear regression model in R using lm().\nHow to visualize regression results and residuals using ggplot2.\n\n\n\n\nWhy is this topic important?\nSimple Linear Regression serves as the building block for more advanced statistical methods, such as multiple regression, moderation, and mediation analysis. It allows social work researchers to identify relationships between variables, predict outcomes, and inform data-driven decision-making. Mastering this concept is essential for understanding more complex techniques later in the course.\n\n\n\nHow does it relate to previous or future content?\n\nTies to previous content: Builds upon last week’s review of descriptive statistics and introduces the concept of relationships between variables.\nPrepares for future topics: Provides a foundation for upcoming topics like multiple regression (Week 5), where we will expand from one predictor to multiple predictors, and interaction effects (Week 9), where regression will be used to explore moderating relationships.\n\n\nThis session emphasizes the practical and theoretical importance of regression analysis, helping students connect statistical techniques to real-world social work applications.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#class-files",
    "href": "02-simple-regression.html#class-files",
    "title": "Introduction to Simple Linear Regression",
    "section": "Class Files",
    "text": "Class Files\n\nLecture Notes\n\nToday’s Lecture Notes\n\n\n\nR Code\n\nIntroduction to R",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#resources",
    "href": "02-simple-regression.html#resources",
    "title": "Introduction to Simple Linear Regression",
    "section": "Resources",
    "text": "Resources\n\nHere is my annotated file for correlation and SLR\nHere is the data I used if you want to replicate it in SPSS",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#todays-reading-1",
    "href": "02-simple-regression.html#todays-reading-1",
    "title": "Introduction to Simple Linear Regression",
    "section": "Today’s Reading",
    "text": "Today’s Reading\n\nPrimary Reading: Simple Linear Regression\nOptional Reading: Extrapolatoin - an example of what not to do despite the potential publication in a highly regarded journal",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#r-lab-files",
    "href": "02-simple-regression.html#r-lab-files",
    "title": "Introduction to Simple Linear Regression",
    "section": "R Lab Files",
    "text": "R Lab Files\n\nLab Instructions\nLab Dataset\nThe Escape Room Exercise",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#additional-notes",
    "href": "02-simple-regression.html#additional-notes",
    "title": "Introduction to Simple Linear Regression",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nRemain calm",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html",
    "href": "03-multiple-regression.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Week 4: February 3, 2026",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#reading",
    "href": "03-multiple-regression.html#reading",
    "title": "Multiple Linear Regression",
    "section": "Reading",
    "text": "Reading\n\nDiez et al. Chapter 9: Multiple Regression, up through pp 371; sec. 9.5",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#week-4-multiple-linear-regression-introduction-to-the-topic",
    "href": "03-multiple-regression.html#week-4-multiple-linear-regression-introduction-to-the-topic",
    "title": "Multiple Linear Regression",
    "section": "Week 4: Multiple Linear Regression – Introduction to the Topic",
    "text": "Week 4: Multiple Linear Regression – Introduction to the Topic\nThis week, we will explore Multiple Linear Regression, a powerful extension of simple regression that allows us to analyze relationships between a dependent variable and multiple predictors. Students will learn how to specify, fit, and interpret multiple regression models, including how to assess their statistical significance and practical relevance. This week’s focus is on building and refining regression models that capture the complexity of real-world social work research.\n\n\nWhat will students learn this week?\n\nThe core components of multiple regression models, including F-tests, p-values, R², and adjusted R².\n\nHow to specify hypotheses in a multiple regression context.\n\nHow to fit and interpret multiple regression models in R using lm().\n\nTechniques to evaluate assumptions and diagnose issues in multiple regression models.\n\n\n\n\nWhy is this topic important?\nMultiple Linear Regression is one of the most widely used tools in statistical analysis. It enables social work researchers to: - Explore complex relationships between multiple predictors and outcomes. - Control for confounding variables and better isolate the effect of specific predictors. - Answer nuanced research questions that cannot be addressed with simple regression.\nBy mastering multiple regression, students gain the ability to analyze more realistic and multifaceted data, making their findings more robust and applicable to real-world settings.\n\n\n\nHow does it relate to previous or future content?\n\nTies to previous content: Builds on the foundation of Simple Linear Regression by introducing multiple predictors and exploring how they contribute to variance in outcomes.\n\nPrepares for future topics: Sets the stage for advanced methods like Effect Sizes and Confidence Intervals, Mediation Analysis, and Hierarchical Regression, where multiple predictors and their relationships play an even greater role.\n\n\nThis week’s topic bridges the gap between basic ## Class Files\n\n\nLecture Notes\n\nIntroduction to MLR\n\n\n\nR Code\n\nCorrelation and Regression\n\n\n\nData Sets\n\nPregnancy Risk Assessment Monitoring System Data file: Use this file to run correlate.R\nAnnotated JASP file for PRAMS data\nAnnotated JASP file (in lecture notes)\nGRE-GPA Example Data (in lecture notes)\nAdmissions Data (in lecture notes)",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#resources",
    "href": "03-multiple-regression.html#resources",
    "title": "Multiple Linear Regression",
    "section": "Resources",
    "text": "Resources\nI have put together a detailed explanation that explains correlation, partial correlation, semipartial correlation using the PRAMS dataset\nAlso check out the video on semi-partial correlations. This is a key idea behind regression",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#todays-reading",
    "href": "03-multiple-regression.html#todays-reading",
    "title": "Multiple Linear Regression",
    "section": "Today’s Reading",
    "text": "Today’s Reading\nA few years ago I wrote a paper examining classes of adversity and comparing the ACEs sum score across classes. Since the analyses we use today examine ACEs using the sum score, I thought it would be a good idea to have you reflect more about the methodology, and in particular how the choice of methodology can not only be not useful, it can be damaging. I will leave you to ask me about this so we can further talk about it from a social justice perspective.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#additional-notes",
    "href": "03-multiple-regression.html#additional-notes",
    "title": "Multiple Linear Regression",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nKeep calm and be significant.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html",
    "href": "04-effect-sizes.html",
    "title": "Effect Sizes",
    "section": "",
    "text": "Week 5: February 10, 2026",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#introduction-to-the-topic",
    "href": "04-effect-sizes.html#introduction-to-the-topic",
    "title": "Effect Sizes",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we delve into the critical concepts of effect sizes and confidence intervals, two foundational elements in interpreting statistical results. These tools play a central role in assessing the strength of relationships and the precision of estimates, bridging the gap between raw statistical outputs and meaningful real-world insights.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#key-concepts",
    "href": "04-effect-sizes.html#key-concepts",
    "title": "Effect Sizes",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nEffect Sizes: Quantify the magnitude of a relationship or difference, providing context beyond mere statistical significance.\nConfidence Intervals (CIs): Represent the range within which a population parameter is likely to fall, offering a measure of result precision.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#relevance",
    "href": "04-effect-sizes.html#relevance",
    "title": "Effect Sizes",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to interpret and calculate effect sizes, understanding their role in evaluating practical significance.\nStudents will explore confidence intervals as tools for assessing the reliability and variability of parameter estimates.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#why-this-is-important",
    "href": "04-effect-sizes.html#why-this-is-important",
    "title": "Effect Sizes",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nEffect sizes complement p-values by answering how much rather than just if there is an effect.\nConfidence intervals provide critical information about the certainty of results, promoting better decision-making and interpretation.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#how-this-ties-into-the-overall-course",
    "href": "04-effect-sizes.html#how-this-ties-into-the-overall-course",
    "title": "Effect Sizes",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon last week’s exploration of hypothesis testing and statistical significance.\nPrepares students for future modules on meta-analysis and advanced modeling techniques, where effect sizes and confidence intervals are integral.\n\nBy the end of this week, students will have the skills to interpret effect sizes and confidence intervals confidently, ensuring they can evaluate research findings critically and apply these concepts to their own analyses.\n\nLecture Notes\n\nEffect Sizes, Confidence Intervals, Assumptions\n\n\n\nR Code\n\nSimple and Multiple Linear Regression\nCalculating Cohen’s D: The full explanation of the code is here. This file calculates Cohen’s D effect size with the added bones of also demonstrating how to download the Area Deprivation Index (ADI) which is frequently used in Social Work and Public Health. Even bettern there is a county-level map of the ADI! See Barboza-Salerno (2023).\n\n\n\nData Sets\n\nAdmissions Data (in lecture notes)\nGRE and graduate student GPA Data (in lecture notes)",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#resources",
    "href": "04-effect-sizes.html#resources",
    "title": "Effect Sizes",
    "section": "Resources",
    "text": "Resources\nI have put together a detailed explanation about simple and multiple linear regression in R.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#todays-reading",
    "href": "04-effect-sizes.html#todays-reading",
    "title": "Effect Sizes",
    "section": "Today’s Reading",
    "text": "Today’s Reading\nToday’s in class assignment is going to ask you to run a multiple linear regression using the National Survey of Child and Adolescent Well-Being (NSCAW I) survey. I used this data in a couple of manuscripts “Trajectories of post-traumatic stress and externalizing psychopathology among maltreated foster care youth: A parallel process latent growth curve model” Barboza et al. (2017) and “Longitudinal growth of post-traumatic stress and depressive symptoms following a child maltreatment allegation: An examination of violence exposure, family risk and placement type” See Barboza & Dominguez (2017).",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#additional-notes",
    "href": "04-effect-sizes.html#additional-notes",
    "title": "Effect Sizes",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nKeep calm and DO NOT be normal.\n\n\n\n\n\nBarboza, G. E., & Dominguez, S. (2017). Longitudinal growth of post-traumatic stress and depressive symptoms following a child maltreatment allegation: An examination of violence exposure, family risk and placement type. Children and Youth Services Review, 81, 368–378.\n\n\nBarboza, G. E., Dominguez, S., & Pinder, J. (2017). Trajectories of post-traumatic stress and externalizing psychopathology among maltreated foster care youth: A parallel process latent growth curve model. Child Abuse & Neglect, 72, 370–382.\n\n\nBarboza-Salerno, G. E. (2023). The neighborhood deprivation gradient and child physical abuse and neglect: A bayesian spatial model. Child Abuse & Neglect, 146, 106501.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html",
    "href": "05-assumptions.html",
    "title": "Regression Assumptions",
    "section": "",
    "text": "Week 6: February 17, 2026",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#introduction-to-the-topic",
    "href": "05-assumptions.html#introduction-to-the-topic",
    "title": "Regression Assumptions",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nToday we are finishing up last week’s discussion of effect sizes and regression assumptions. Then we will turn to an even more exciting topic: dummy variables. Regression assumptions are foundational principles that must be met for linear regression models to provide valid and reliable results. Understanding and testing these assumptions is essential for sound statistical inference.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#key-concepts",
    "href": "05-assumptions.html#key-concepts",
    "title": "Regression Assumptions",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nLinearity: The relationship between predictors and the outcome variable should be linear.\nIndependence: Observations should be independent of each other.\nHomoscedasticity: The variance of errors should be consistent across levels of predictors.\nNormality of Residuals: Residuals (errors) should follow a normal distribution.\nMulticollinearity: Predictors should not be highly correlated with each other.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#relevance",
    "href": "05-assumptions.html#relevance",
    "title": "Regression Assumptions",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to evaluate each regression assumption using diagnostic tests and visualizations.\nStudents will gain skills to address violations of assumptions, such as transforming variables or using robust regression methods.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#why-this-is-important",
    "href": "05-assumptions.html#why-this-is-important",
    "title": "Regression Assumptions",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nViolations of regression assumptions can lead to biased estimates, incorrect conclusions, and reduced model reliability.\nBy understanding these assumptions, students can ensure the validity of their regression analyses and effectively communicate findings.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#how-this-ties-into-the-overall-course",
    "href": "05-assumptions.html#how-this-ties-into-the-overall-course",
    "title": "Regression Assumptions",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon prior topics like linear regression by adding a deeper layer of model evaluation and diagnostics.\nPrepares students for advanced topics like generalized linear models and robust regression techniques, which relax some assumptions.\n\nBy the end of this week, students will be able to test and address regression assumptions, ensuring their models meet the necessary criteria for accurate and reliable results.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#dummy-variables",
    "href": "05-assumptions.html#dummy-variables",
    "title": "Regression Assumptions",
    "section": "Dummy Variables",
    "text": "Dummy Variables\nIn regression analysis, many predictors are categorical rather than numerical. However, standard regression models require numerical inputs. Dummy variables are a way to include categorical variables in a regression model by converting them into numerical representations.\n\nWhat are Dummy Variables?\nA dummy variable is a binary variable (0 or 1) that represents different categories of a categorical predictor. It allows regression models to account for group differences. We will learn how to recode variables in SPSS, and R, and include them in our models. This requires understanding how to select the reference category. Read this article for a social justice application of selecting reference variables in regression models. I used this idea to code trans man as the reference category in this paper .\n\nWhy Use Dummy Variables?\n\nThey quantify categorical differences in a regression model.\nThey allow us to compare groups while controlling for other factors.\nThey help capture interaction effects when combined with numerical predictors.\n\n\n\nExtending Dummy Variables:\n\nFor variables with more than two categories, we create multiple dummy variables (e.g., for “Region: North, South, West,” we need two dummy variables to represent three categories).\nReference category: One category is omitted to prevent multicollinearity, and all other categories are compared against it.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#class-files",
    "href": "05-assumptions.html#class-files",
    "title": "Regression Assumptions",
    "section": "Class Files",
    "text": "Class Files\n\nLecture Notes\n\nToday’s Lecture Notes\n\n\n\nR Code\n\nScript 1: CLT Application of Central Limit Theorem to A$AP Rocky’s case: Should he get a new trial?\nScript 2: CLT More CLT Fun\nDirected Acyclic Graph - DAGS And even more fun, check out how you can create diagrams, including DAGS, in R.\n\n\n\nData Sets\n\nNational Survey of Child and Adolescent Well-Being: We are going to examine the following research question using a subset of the dataset: Do children who are removed from the home have higher levels of post-traumatic stress controlling for demographic and exposure variables?\nInfluence, Outliers, and Leverage Part I, Part II, Part III, Part IV",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#r-lab-files",
    "href": "05-assumptions.html#r-lab-files",
    "title": "Regression Assumptions",
    "section": "R Lab Files",
    "text": "R Lab Files\n\nLab Instructions We are going to run some simple and multiple regressions using R with the NSCAW data.\nHere is a partially annotated data file to get us started.\nLab Dataset\nAnother practice assignment that we never got it. Check it out and see if you can answer the questions.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#additional-notes",
    "href": "05-assumptions.html#additional-notes",
    "title": "Regression Assumptions",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nKeep calm and be influential.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html",
    "href": "07-logistic-regression.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Week 7: February 24, 2026",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#reading",
    "href": "07-logistic-regression.html#reading",
    "title": "Logistic Regression",
    "section": "Reading",
    "text": "Reading\n\nDiez et al. Chapter 9: Logistic Regression, from pp 371; sec. 9.5\nSee resources",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#introduction-to-the-topic",
    "href": "07-logistic-regression.html#introduction-to-the-topic",
    "title": "Logistic Regression",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we focus on logistic regression, a statistical method used to model binary outcomes and predict probabilities. Logistic regression is a cornerstone technique in statistical modeling, particularly for research questions involving categorical dependent variables.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#key-concepts",
    "href": "07-logistic-regression.html#key-concepts",
    "title": "Logistic Regression",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nLogistic Regression Models: Analyze the relationship between independent variables and a binary dependent variable (e.g., success vs. failure).\nOdds Ratios: Interpret the effect of predictors on the likelihood of the outcome.\nModel Fit and Diagnostics: Evaluate the accuracy and robustness of logistic regression models.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#relevance",
    "href": "07-logistic-regression.html#relevance",
    "title": "Logistic Regression",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to build logistic regression models and interpret their results, including coefficients, odds ratios, and predicted probabilities.\nStudents will explore model evaluation techniques, such as goodness-of-fit measures and ROC curves.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#why-this-is-important",
    "href": "07-logistic-regression.html#why-this-is-important",
    "title": "Logistic Regression",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nLogistic regression is widely used in various fields, including social sciences, medicine, and marketing, to answer questions about classification and prediction.\nUnderstanding logistic regression provides the foundation for advanced modeling techniques like multinomial and ordinal regression.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#how-this-ties-into-the-overall-course",
    "href": "07-logistic-regression.html#how-this-ties-into-the-overall-course",
    "title": "Logistic Regression",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon previous weeks’ focus on linear regression and effect sizes, extending these concepts to binary outcomes.\nPrepares students for upcoming topics like machine learning classification models and survival analysis, where logistic regression plays a foundational role.\n\nBy the end of this week, students will be able to confidently apply logistic regression to real-world problems, interpret model outputs, and evaluate model performance for binary classification tasks.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#class-files",
    "href": "07-logistic-regression.html#class-files",
    "title": "Logistic Regression",
    "section": "Class Files",
    "text": "Class Files\n\nLecture Notes\n\nToday’s Lecture Notes and a review of risk and odds calculations using contingency tables\n\n\n\nR Code\n\nScript 1: Logistic Regression Application of Logistic Regression using R\n\n\n\nData Sets\n\nGPA-College Enrollment Example: In class example showing the mechanics of logistic regression?\nPredicting Probabilities with Logistic Regression Here is an excel file illustrating the math behind predicting probabilities\nAn annotated jasp file of logistic regression output including how to do the log-likelihood test\n\n\n\nResources\n\nThere are a million ways to recode variables in R\nNow that you are familiar with using R, check out this amazing book called R for Data Science which is written by the Hadley who co-authored the tidyverse suite.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#additional-notes",
    "href": "07-logistic-regression.html#additional-notes",
    "title": "Logistic Regression",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nKeep calm and don’t be a dummy.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "06-mediation.html",
    "href": "06-mediation.html",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "",
    "text": "Week 8: March 3, 2026",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#reading",
    "href": "06-mediation.html#reading",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Reading",
    "text": "Reading\n\nHayes, Andrew. (2018). Introduction to Mediation, Moderation, and Conditional Process Analysis Chapters 1 - 4.\nHere is an applied paper in Social Work that you should be able to understand after going through this week’s materials.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#introduction-to-the-topic",
    "href": "06-mediation.html#introduction-to-the-topic",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we explore mediation analysis, a statistical approach used to understand the mechanisms through which an independent variable influences a dependent variable via a third variable, known as the mediator. Mediation analysis is essential for uncovering causal pathways in research.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#key-concepts",
    "href": "06-mediation.html#key-concepts",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nDirect Effects: The relationship between the independent variable and the dependent variable, excluding the mediator.\nIndirect Effects: The portion of the relationship explained through the mediator.\nTotal Effects: The combined impact of direct and indirect effects.\nBootstrapping: A resampling method for testing the significance of indirect effects.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#relevance",
    "href": "06-mediation.html#relevance",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to identify and test mediating variables in a causal framework. Make sure you review our discussion of confounding\nStudents will explore how to decompose total effects into direct and indirect components to better understand relationships among variables.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#why-this-is-important",
    "href": "06-mediation.html#why-this-is-important",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nMediation analysis allows researchers to move beyond simple relationships to uncover how and why effects occur.\nUnderstanding mediation is critical for testing theoretical models in fields like psychology, sociology, and public health.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#how-this-ties-into-the-overall-course",
    "href": "06-mediation.html#how-this-ties-into-the-overall-course",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon previous topics, such as regression and effect sizes, by extending these tools to explore causal pathways.\nPrepares students for advanced concepts like moderated mediation and structural equation modeling (SEM), where mediation analysis is a core component.\n\nBy the end of this week, students will be able to conduct mediation analyses, interpret direct and indirect effects, and evaluate the significance of mediators using bootstrapping methods.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#an-example-of-logistic-regression-from-last-week",
    "href": "06-mediation.html#an-example-of-logistic-regression-from-last-week",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "An example of logistic regression from last week",
    "text": "An example of logistic regression from last week\nWe ran out of time last week but I put together an example and write up of logistic regression. This uses the PRAMS dataset to inquire about whether stress during pregnancy predicts IPV exposure during pregnancy. Recall the variable measurements which we noted here. The JASP file is here and it is fully annotated.\n\nIn-Class Files and Data Sets",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#a-note-on-linear-transformations",
    "href": "06-mediation.html#a-note-on-linear-transformations",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "A Note on Linear Transformations",
    "text": "A Note on Linear Transformations\nLinear Transformations: We start class today with a quick example of how to transform variables when the model assumptions are violated. As I mentioned in class, this trick has almost never worked with the datasets I use. However, I was successful in transforming the dependent variable once, using a cultivated dataset on area deprivation, housing, and “child maltreatment” substantiations which can be accessed here. I have used these data often see Elise Barboza-Salerno (2024) for an example.\nThe cultivated dataset comes from many sources. The H+T index comes from this website. The ADI comes from the sociome package in R, and we saw an example when we learned how to quantify effect sizes with Cohen’s D. I calculated the distances to SNAP retail locations from home addresses based on information from the SNAP retail locator, which can be accessed here.\nTest yourself on partial mediation, full mediation, and supression: I created sample output for each effect, can you select the correct model that illustrates each mechanism?\nMediation: We will use a subset of the NSCAW I to examine whether symptoms of post-traumatic stress mediate the association between exposure to violence at Wave I and child externalizing behaviors at Wave III. Now DON’T LOOK at the model write-up until AFTER you have the analysis done. Then, and only then, can you take a gander at my write-up here",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#lab-files",
    "href": "06-mediation.html#lab-files",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Lab Files",
    "text": "Lab Files\nAfter we do the above example together, we have an in-class assessment to get a sense of how well you are comprehending the analyses. This includes some multiple choice questions along with an analysis of the Adolescent Health Survey Data which is a longitudinal dataset that has been collected since about 1995 when youth were 15 years of age. Please download the assessment here. See Elise Barboza & Siller (2021) for a similar analysis published in the Journal of Interpersonal Violence, or this paper Barboza (2020) that also used these data.\n\nLecture Notes\n\nDownload today’s slides here\n\n\n\nR Code\nI wrote the code to show you how to use PROCESS in R. Yes, R has a package that runs the same macro that SPSS can run. The example is based on the NSCAW dataset as well. Check it out here",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#resources",
    "href": "06-mediation.html#resources",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Resources",
    "text": "Resources\nThis is an amazing resources from UCLA on introduction to mediation, moderation and conditional process models. The website has a tutorial that I am strongly suggesting you do, and also additional powerpoint slides for Andrew Hayes’ book.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#additional-notes",
    "href": "06-mediation.html#additional-notes",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay calm and do everything in moderation.\n\n\n\n\nBarboza, G. E. (2020). Child Maltreatment, Delinquent Behavior, and School Factors as Predictors of Depressive Symptoms from Adolescence to Adulthood: A Growth Mixture Model. Youth & Society, 52(1), 27–54. https://doi.org/10.1177/0044118X17721803Previous methodological approaches have not been flexible enough to model the heterogeneity of depressive symptoms or to identify variations between prototypical trajectories conditional on risk and protective factors. The current study examined latent class trajectories of depressive symptoms using data from 3,819 respondents of the Adolescent Health Survey. Four trajectory profiles of depressive symptoms were identified: low-stable, high-decreasing, low-increasing, and moderate-decreasing. A broad array of risk factors were included into the modeling procedure to identify predictors of group membership. Relative to the low-stable group, membership in one of the three symptomatic groups (i.e., heightened depressive symptoms) was predicted by poverty, low self-esteem, gender, drinking frequency, poor academic outcomes, delinquency, and child maltreatment type. This study contributes to our understanding about the longitudinal manifestations of depression and identifies a broad array of factors significantly related to pathways of resilience.\n\n\nElise Barboza, G., & Siller, L. A. (2021). Child Maltreatment, School Bonds, and Adult Violence: A Serial Mediation Model. Journal of Interpersonal Violence, 36(11-12), NP5839–NP5873. https://doi.org/10.1177/0886260518805763Physically abused youth are vulnerable to experiencing difficulties across multiple domains of school functioning. Most of the literature examining the relationship between child physical abuse (CPA) and adult violence has focused narrowly on academic outcomes rather than taking a broader view that explores the processes undergirding school engagement and connections. The present study adopted Connell?s model of school engagement, connectedness and outcomes within a social bond framework to examine (a) the link between CPA and school social bonds, (b) the link between CPA and adult violence persistence, and (c) the mediational (parallel, serial) effects of school bonds (engagement, connection, and achievement) on violence perpetration in adulthood. Consistent with previous research, results indicated that children who experience physical abuse have poorer academic performance, which, in turn, is related to future violent trajectories. We further found that the relationship between CPA and violence persistence is mediated by a process of bonding to school that begins with being actively engaged in school activities and ends with higher levels of academic achievement. In particular, some of the ?school achievement? effect found in previous research operates through behavioral and emotional manifestations and may be partly explained through physically abused children?s lessened ability to be engaged with and connected to school activities. We conclude with a discussion of the policy implications stemming from our findings.\n\n\nElise Barboza-Salerno, G. (2024). Material Hardship, Labor Market Characteristics and Substantiated Child Maltreatment: A Bayesian Spatiotemporal Analysis. Children and Youth Services Review, 157, 107371. https://doi.org/10.1016/j.childyouth.2023.107371Child maltreatment is a critical public health problem whose structural underpinnings underscore the need to move prevention efforts from individual-level risk factors to social policy. Despite previous studies exploring the evolution of child maltreatment risk in socially vulnerable contexts, little is known about how neighborhood level material deprivation and job market characteristics, beyond the employment context, impact substantiated maltreatment risk. The present analysis integrates multiple streams of data to explore the complexity of child maltreatment in the most populous county in New Mexico as a case-study. A geospatial model was used to produce posterior risk estimates and exceedance probabilities of substantiated child maltreatment derived from administrative records controlling for financial strength, economic inequality and hardship, educational attainment, housing and food insecurity and labor market characteristics. Findings showed that over the nine-year study period, the average relative risk of child maltreatment increased substantially, however, there was substantial regional and temporal heterogeneity. More specifically, substantiated child maltreatment risk became more highly concentrated into the most deprived 20% of neighborhoods over time. The results showed a very strong area deprivation effect such that: (1) the risk of maltreatment in the most deprived 20% of neighborhoods on financial strength was 130.78% higher compared to the least deprived 20% of neighborhoods; and (2) maltreatment rates in the bottom 20% of neighborhoods on economic inequality and hardship were 40.52% higher compared to the least deprived 20% of neighborhoods. Finally, substantiated child maltreatment was significantly associated with multiple labor market characteristics including commuting times to work, origin–destination job flows, and mode of transportation to work. From a policy perspective, the results of this study support structural interventions aimed at reducing neighborhood-level material hardship and labor market disadvantage as avenues to support parents so that children and families can thrive.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html",
    "href": "07-moderation.html",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "",
    "text": "Week 11: March 24, 2026",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#reading",
    "href": "07-moderation.html#reading",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Reading",
    "text": "Reading\n\nHayes, Andrew. (2018). Introduction to Mediation, Moderation, and Conditional Process Analysis Chapters 7 - 10.\nI have used these methods on several occasions, check out Barboza-Salerno & Meshelemiah (2024) and Elise Barboza & Siller (2021).\n\nBarboza-Salerno, G. E., & Meshelemiah, J. C. (2024). Associations between early child adversity and lifetime suicide attempts among gender diverse individuals: A moderated mediation. Child Abuse & Neglect, 149, 106705.\nBarboza, G., & Siller, L. A. (2021). Child Maltreatment, School Bonds, and Adult Violence: A Serial Mediation Model. Journal of Interpersonal Violence, 36(11–12), NP5839–NP5873. https://doi.org/10.1177/0886260518805763",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#introduction-to-the-topic",
    "href": "07-moderation.html#introduction-to-the-topic",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we explore moderation analysis, a statistical approach used to understand how the relationship between two variables changes depending on a third variable, known as the moderator. Unlike simple regression, where we assess a direct relationship between an independent and dependent variable, moderation analysis allows us to examine whether this relationship varies in strength or direction based on different levels of another variable.\nModeration is particularly useful in social sciences, public health, and policy research, where the effect of an intervention or exposure may differ depending on contextual factors such as age, gender, socioeconomic status, or environmental conditions. For example, in public health studies, we might investigate whether the relationship between neighborhood poverty and child maltreatment rates is moderated by community resources or green space availability.\nThroughout this week, we will discuss how to interpret interaction effects, visualize moderation using interaction plots, and apply these concepts using statistical software. By the end of the module, you will be able to identify when moderation is appropriate, test for moderation effects, and communicate findings effectively in research and policy contexts",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#key-concepts",
    "href": "07-moderation.html#key-concepts",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nDefinition: Moderation occurs when the strength or direction of the relationship between an independent variable X and a dependent variable Y depends on a third variable W, called the moderator.\nInteraction/Effect moderation: The key indicator of moderation is a statistically significant interaction term, X * W, in a regression model, suggesting that the effect of X on Y varies depending on W.\nVisualization: Simple slopes analysis and interaction plots help visualize and interpret moderation effects.\nProbing Interactions: This is an extremely useful technique in which you can detect statistically significant regions of the interaction. Super exciting!\nDistinguishing Moderation from Mediation:\n\nModeration affects the strength of the relationship between X and Y.\nMediation explains the mechanism through which X affects Y via an intermediate variable.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#relevance",
    "href": "07-moderation.html#relevance",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to use PROCESS in R and SPSS to test effect moderation to examine when or for whom an effect occurs (e.g., does the effect of stress on mental health differ based on social support?)\nStudents will begin to understand what conditional (i.e., moderation) indirect effects (i.e., mediation) are and how to use them to test innovative hypotheses in social work (i.e., moderated mediation).",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#why-this-is-important",
    "href": "07-moderation.html#why-this-is-important",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nMediation analysis, as we saw last week, allows researchers to move beyond simple relationships to uncover how and why effects occur.\nUnderstanding mediation is critical for testing theoretical models in fields like social work, psychology, sociology, and public health.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#how-this-ties-into-the-overall-course",
    "href": "07-moderation.html#how-this-ties-into-the-overall-course",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon previous topics, such as regression and effect sizes, by extending these tools to explore conditional effects.\nPrepares students for advanced concepts like moderated mediation and structural equation modeling (SEM), where interaction terms can be useful.\n\nBy the end of this week, students will be able to conduct moderation analyses, interpret conditional effects, and evaluate the significance of effect moderation using SPSS and R.\n\nIn-Class Files and Data Sets\nData sets: We will use datasets from Hayes on workplace related stress: estress.sav and presumed media influence on the intention to purchase: pmi.sav.\nMediation Extensions: First, are going to extend the simple mediation model we learned last time by incorporating multiple mediators. I have saved the SPSS output for several different examples:\n\nExample 1: Dichotomous Predictor, Simple Mediation, The PMI study\nExample 2: Continuous Predictor, Economic Stress Among Small Business Owners\nExample 3 Continuous Predictor with controls, Economic Stress Among Small Business Owners (same data set as above)\n\nNext, we extend the simple case using examples representing parallel, serial mediation and serial mediation with contrasts.\nModeration: Finally, we end today with an example of how to implement moderation. We will use these files:\n\nExample 1: Dichotomous Moderation Effect, Sexual Minority. I saved the SPSS output\nExample 2: Continuous Moderation Effect, NSCAW",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#lab-files",
    "href": "07-moderation.html#lab-files",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Lab Files",
    "text": "Lab Files\nMediation: You are going to do this lab using the NSCAW data to examine whether (1) children investigated for abuse or neglect who have witnessed severe violence at Wave 1 (EV_W1) are more likely to engage in externalizing behavior at Wave 3 (bcext3); and (2) post-traumatic stress at Wave 1 (tra1) is the mechanism violence exposure is linked to externalizing behavior.\nModeration: I have created some Excel output so you can learn how to take the output and visualize the results. One file plots the effect moderation for age on the association between post-traumatic stress and delinquent behaviors using a subset of the NSCAW. Now, you can use this file to practice making a similar chart using excel to answer the question: What is the effect moderation of sexual minority status on the association between post-traumatic stress and delinquent behavior?\n\nLecture Notes & Class Files\n\nDownload today’s slides here\nCheck out my annotated Word document interpreting parallel mediation (with sample write-up) here",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#resources",
    "href": "07-moderation.html#resources",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Resources",
    "text": "Resources\nThere are a number of mediation, moderation, and mediated moderation models that you can use to test various hypotheses. Once you have a basic familairity of the models they become intuitive. Model templates are located here.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#additional-notes",
    "href": "07-moderation.html#additional-notes",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay calm and remove interactions with toxic people.\n\n\n\n\nBarboza-Salerno, G. E., & Meshelemiah, J. C. (2024). Associations between early child adversity and lifetime suicide attempts among gender diverse individuals: A moderated mediation. Child Abuse & Neglect, 149, 106705.\n\n\nElise Barboza, G., & Siller, L. A. (2021). Child Maltreatment, School Bonds, and Adult Violence: A Serial Mediation Model. Journal of Interpersonal Violence, 36(11-12), NP5839–NP5873. https://doi.org/10.1177/0886260518805763Physically abused youth are vulnerable to experiencing difficulties across multiple domains of school functioning. Most of the literature examining the relationship between child physical abuse (CPA) and adult violence has focused narrowly on academic outcomes rather than taking a broader view that explores the processes undergirding school engagement and connections. The present study adopted Connell’s model of school engagement, connectedness and outcomes within a social bond framework to examine (a) the link between CPA and school social bonds, (b) the link between CPA and adult violence persistence, and (c) the mediational (parallel, serial) effects of school bonds (engagement, connection, and achievement) on violence perpetration in adulthood. Consistent with previous research, results indicated that children who experience physical abuse have poorer academic performance, which, in turn, is related to future violent trajectories. We further found that the relationship between CPA and violence persistence is mediated by a process of bonding to school that begins with being actively engaged in school activities and ends with higher levels of academic achievement. In particular, some of the “school achievement” effect found in previous research operates through behavioral and emotional manifestations and may be partly explained through physically abused children’s lessened ability to be engaged with and connected to school activities. We conclude with a discussion of the policy implications stemming from our findings.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html",
    "href": "07a-moderation.html",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "",
    "text": "Week 10: March 23, 2026",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#reading",
    "href": "07a-moderation.html#reading",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Reading",
    "text": "Reading\n\nHayes, Andrew. (2018). Introduction to Mediation, Moderation, and Conditional Process Analysis Chapters 7 - 10.\nI have used these methods on several occasions, check out Barboza-Salerno & Remillard (2023).\n\nBarboza-Salerno, G. E., & Remillard, A. (2023). Early child adversity and delinquent behavior in foster care youth: do future expectations and sexual identity moderate the mediating role of posttraumatic stress?. Journal of Child & Adolescent Trauma, 16(4), 945-957.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#introduction-to-the-topic",
    "href": "07a-moderation.html#introduction-to-the-topic",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week we continue to learn about advanced mediation models and effect moderation. To review, please see last week’s page\n\nIn-Class Files and Data Sets\nData sets:\n– Our first example uses the presumed media influence study: pmi.sav to estimate a serial mediation of article importance and PMI jointly. – Next, we are going to use PRAMS data to examine potential pathways by which intimate partner violence prior to pregnancy impacts poor birth outcomes, i.e., low birth weight in infants. Please note that this is not only a public health issue, low birth weight disproportionately effects persons on the basis of race, and so it qualifies as a civil rights issue.\nModeration: Finally, we will learn about moderation effects, which we did not get to last week. We will use these files:\n\nExample 1: Dichotomous Moderation Effect, Sexual Minority. I saved the SPSS output\nExample 2: Continuous Moderation Effect, NSCAW",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#lab-files",
    "href": "07a-moderation.html#lab-files",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Lab Files",
    "text": "Lab Files\nMediation: You are going to do this lab using the NSCAW data to examine whether (1) children investigated for abuse or neglect who have witnessed severe violence at Wave 1 (EV_W1) are more likely to engage in externalizing behavior at Wave 3 (bcext3); and (2) post-traumatic stress at Wave 1 (tra1) is the mechanism violence exposure is linked to externalizing behavior.\nModeration: I have created some Excel output so you can learn how to take the output and visualize the results. One file plots the effect moderation for age on the association between post-traumatic stress and delinquent behaviors using a subset of the NSCAW. Now, you can use this file to practice making a similar chart using excel to answer the question: What is the effect moderation of sexual minority status on the association between post-traumatic stress and delinquent behavior?\nModeration in R: I have written the code to show you how to implement moderation in R.\n\nLecture Notes & Class Files\n\nDownload today’s slides here\nI want us to assess our knowledge of mediation today",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#resources",
    "href": "07a-moderation.html#resources",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Resources",
    "text": "Resources\nThere are a number of mediation, moderation, and mediated moderation models that you can use to test various hypotheses. Once you have a basic familairity of the models they become intuitive. Model templates are located here.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#additional-notes",
    "href": "07a-moderation.html#additional-notes",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay calm and BE BRAVE.\n\n\n\n\nBarboza-Salerno, G. E., & Remillard, A. (2023). Early child adversity and delinquent behavior in foster care youth: Do future expectations and sexual identity moderate the mediating role of posttraumatic stress? Journal of Child & Adolescent Trauma, 16(4), 945–957.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "11-efa.html",
    "href": "11-efa.html",
    "title": "EFA",
    "section": "",
    "text": "Week 12: March 31, 2026",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#reading",
    "href": "11-efa.html#reading",
    "title": "EFA",
    "section": "Reading",
    "text": "Reading\n\nPituch et al. Chapter 9: Exploratory Factor Analysis, from pp 339\nHahs-Vaughn. Chapter 9: Applied Multivariate Statistical Concepts, from pp 362\nYong and Pearce - 2013 - A beginner’s guide to factor analysis",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#introduction-to-the-topic",
    "href": "11-efa.html#introduction-to-the-topic",
    "title": "EFA",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we focus on Exploratory Factor Analysis (EFA), a statistical method used to uncover the underlying structure of a set of observed variables. EFA is a critical tool for identifying latent constructs in datasets.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#key-concepts",
    "href": "11-efa.html#key-concepts",
    "title": "EFA",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nLatent Variables: Unobserved factors inferred from observed variables.\nFactor Loadings: The relationship between observed variables and underlying factors.\nEigenvalues and Scree Plots: Tools for determining the number of factors to retain.\nRotation Methods: Techniques (e.g., Varimax, Promax) to simplify factor structure.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#relevance",
    "href": "11-efa.html#relevance",
    "title": "EFA",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to conduct EFA to explore latent structures in data.\nStudents will gain skills to evaluate factor solutions and interpret factor loadings.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#why-this-is-important",
    "href": "11-efa.html#why-this-is-important",
    "title": "EFA",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nEFA helps researchers identify patterns and groupings in data without predefined hypotheses.\nIt is widely used in psychology, education, and social sciences to develop and validate measurement tools.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#how-this-ties-into-the-overall-course",
    "href": "11-efa.html#how-this-ties-into-the-overall-course",
    "title": "EFA",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon prior topics like correlations and covariance by introducing latent structures.\nPrepares students for Confirmatory Factor Analysis (CFA), where hypothesized factor structures are tested.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#lab-files",
    "href": "11-efa.html#lab-files",
    "title": "EFA",
    "section": "Lab Files",
    "text": "Lab Files\n\nSAQ-8: First, we illustrate factor analysis with a simple example from UCLA which you can read more about here. It uses the SAQ-8 to examine the latent structure of LOVING statistics.\nPIAAC: Then, we will use read data from the Program for the International Assessment of Adult Competencies (PIAAC) located here. From the website, the PIAAC survey seeks to answer the following policy questions:\n\nHow are skills distributed? A comparison of skill levels, skill requirements, investments in education and training across countries, investment mismatches across countries, as well as of investments and mismatches within countries, across demographic categories, regions, sectors of industry, levels and fields of schooling.\n\nWhy are skills important? The relation of skills to relevant labor market outcomes such as employment opportunities, earnings, job security, and skill utilization, as well as to other outcomes such as health, civic engagement, and social trust.\nWhat factors are related to skill acquisition and decline? The relation between various learning activities – education, training, informal learning activities – and skill acquisition. The relation of experiences at work, in education and everyday life to skill decline among older individuals.\n\nWe are using a subsetted spss file from the USA that you can download here and I also created a JASP file of the same data that is fully annotated here. The final, reduced model output with the variables that did not load highly on the factors is here in case you are interested.\n\nGenerations: A Study of the Life and Health of LGB People in a Changing Society: We will conduct a full FA using a dataset called Generations:A Study of the Life and Health of LGB People in a Changing Society We will use these data wo explore the factor structure of an ethnic identity scale and differences in the structure across race. The analysis is based on a paper by Johnson et al. (2022) that you can download here called The Group-Based Law Enforcement Mistrust Scale: Psychometric Properties of an Adapted Scale and Implications for Public Health and Harm Reduction Research\n\nTHE IN-CLASS EXAMPLE is located here and then you can study how this same analysis can be performed using R here\n\nLecture Notes\n\nDownload today’s slides here",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#resources",
    "href": "11-efa.html#resources",
    "title": "EFA",
    "section": "Resources",
    "text": "Resources",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#additional-notes",
    "href": "11-efa.html#additional-notes",
    "title": "EFA",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay calm and and let your life unfold one factor at a time.\n\n\n\n\nJohnson, L. M., Devereux, P. G., & Wagner, K. D. (2022). The group-based law enforcement mistrust scale: Psychometric properties of an adapted scale and implications for public health and harm reduction research. Harm Reduction Journal, 19(1), 60.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "efa_R.html",
    "href": "efa_R.html",
    "title": "EFA in R",
    "section": "",
    "text": "Prelims\nBefore interpreting the results of an exploratory factor analysis (EFA), it is essential to consider whether the assumptions underlying the method are reasonably met. One key assumption is that the observed variables are continuous and approximately normally distributed. While EFA is somewhat robust to violations of normality, particularly when using large sample sizes or estimation methods like principal axis factoring, violations can still impact the accuracy of factor loadings and model fit statistics. In this study, the six racial/ethnic identity items (RE1–RE6) were measured on a 5-point Likert scale, which, although technically ordinal, can often be treated as continuous in practice—especially when items have five or more categories and exhibit approximately symmetric distributions.\nAnother important assumption is multivariate normality, especially when using estimation methods such as maximum likelihood (ML), which relies on normality to produce unbiased estimates and valid fit indices. Although ML estimation was used in this analysis, the relatively large sample size may mitigate concerns about non-normality. If substantial departures from normality were present, alternative estimation methods—such as principal axis factoring or robust maximum likelihood—could offer more reliable results.\nIn addition to distributional assumptions, EFA assumes that the variables included are conceptually coherent and intercorrelated, such that they are likely to reflect common latent constructs. This assumption is supported in the present analysis, as the six items were explicitly designed to capture theoretically distinct but related dimensions of racial/ethnic identity. Prior research supports a multidimensional structure of racial and ethnic identity, particularly models that distinguish between exploration (active engagement in learning about one’s racial or ethnic group) and commitment or affirmation (a sense of belonging or attachment). These dual processes are foundational in Phinney’s (1992) Multigroup Ethnic Identity Measure (MEIM) and further validated by studies that replicate two-factor or higher-order factor structures across diverse racial/ethnic groups (Roberts et al., 1999; Yip, 2005). Theoretical and empirical support for these dimensions provides a strong rationale for modeling racial/ethnic identity as multifactorial and reinforces the construct validity of the current EFA findings.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>EFA in R</span>"
    ]
  },
  {
    "objectID": "efa_R.html#introduction",
    "href": "efa_R.html#introduction",
    "title": "EFA in R",
    "section": "Introduction",
    "text": "Introduction\nAcross multiple studies, ethnic identity (EI) has consistently been conceptualized as a multidimensional construct encompassing both affective and behavioral components. While specific factor labels varied, each study identified two primary dimensions: one reflecting a sense of affirmation, belonging, or identification with one’s ethnic group, and the other capturing exploration, participation, or engagement in ethnic behaviors. Roberts et al., Spencer et al., and Yancey et al. all found support for this two-factor structure among adolescents, reinforcing the view that EI involves both internalized group attachment and active efforts to understand and engage with one’s cultural background.\nThis analysis explores the underlying structure of six race/ethnic identity items from the Multigroup Ethnic Identity Measure using the Life and Health of LGBT People Study. These items are measured on a 5-point Likert scale ranging from 1 (“Strongly disagree”) to 5 (“Strongly agree”) and include:\n\nExploration\nThese items reflect behavioral and cognitive efforts to learn more about one’s racial/ethnic background:\n\nRE1: I have spent time trying to find out more about my race/ethnic group, such as its history, traditions, and customs.\nRE4: I have often done things that will help me understand my race/ethnic background better.\nRE5: I have often talked to other people in order to learn more about my race/ethnic group.\n\n\n\nCommitment/Belonging\nThese items express a sense of attachment, emotional connection, or identification with the group:\n\nRE2: I have a strong sense of belonging to my own race/ethnic group.\nRE3: I understand pretty well what my race/ethnic group membership means to me.\nRE6: I feel a strong attachment towards my own race/ethnic group.\n\nThese items reflect cognitive, behavioral, and emotional dimensions of racial/ethnic identity exploration and commitment.\nBased on their content and alignment with established ethnic identity frameworks such as Phinney’s MEIM, the six items should be categorized into two dimensions: Exploration and Commitment/Belonging. This categorization is consistent with empirical studies that distinguish between active engagement in learning about one’s ethnicity (Exploration) and emotional or attitudinal connection to the group (Commitment/Belonging).\n\n# Load dataset\ndata_path &lt;- \"C:/Users/barboza-salerno.1/Downloads/life and health of lgbt people study.sav\"\ndf &lt;- read_sav(data_path)\n\nre_items &lt;- df %&gt;%\n  select(RE1, RE2, RE3, RE4, RE5, RE6) \n\n\nsummary(re_items)\n\n      RE1             RE2             RE3             RE4       \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:3.000   1st Qu.:2.000  \n Median :4.000   Median :3.000   Median :4.000   Median :3.000  \n Mean   :3.355   Mean   :3.205   Mean   :3.722   Mean   :3.253  \n 3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :15      NA's   :19      NA's   :19      NA's   :22     \n      RE5             RE6       \n Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :3.000  \n Mean   :3.179   Mean   :3.097  \n 3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000  \n NA's   :18      NA's   :18     \n\n\n\ncolSums(is.na(re_items))\n\nRE1 RE2 RE3 RE4 RE5 RE6 \n 15  19  19  22  18  18 \n\n\n\n# Select the six RE variables\nre_items &lt;- re_items %&gt;%\n   drop_na()  # Remove rows with missing values\n\n\n\nKMO and Bartlett’s Test\n\n# Check correlation matrix and Bartlett’s test\ncor_matrix &lt;- cor(re_items, use = \"pairwise.complete.obs\")\nKMO(cor_matrix)\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = cor_matrix)\nOverall MSA =  0.82\nMSA for each item = \n RE1  RE2  RE3  RE4  RE5  RE6 \n0.86 0.77 0.88 0.81 0.82 0.81 \n\ncortest.bartlett(cor_matrix, n = nrow(re_items))\n\n$chisq\n[1] 4215.477\n\n$p.value\n[1] 0\n\n$df\n[1] 15\n\n\n\nNote: All MSA’s here were acceptable. If they were not, you would want to eliminate those variables with MSA’s below a certain value, perhaps .50 at minimum. You can do this easily as follows:\n\n\nmydat &lt;- cor_matrix[, KMO(cor_matrix)$MSAi&gt;0.50] \n\n\nNote: Bartlett’s test compares the correlation matrix to the identity matrix and the null hypothesis is:\n\n\\[H_0: I_{mat} = Corr_{mat}\\] #### Determine the number of Factors to Extract This is the most important determination for EFA. The goal is to examine the latent structure for a certain number of variables that are coherent, or highly correlated. Therefore, we want to find factors that explain a substantial proportion of variation within the data. Recall there are numerous ways to make such a determination, and none of them are wrong. However, some are more correct than others, and the gold standard is to use parallel analysis as demonstrated below:\n\nfa.parallel(re_items, fa = \"fa\", n.iter = 100, show.legend = TRUE)\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n\n\nLovely, we don’t have to guess, according to the code, we should select 2 factors.\n\n\nExtract (and rotate) factors\nUnless the correlation between factors is low, we want use oblique rotation. Oblique rotations will provide a correlation matrix that describes the relationships between factors. There are two primary selections: Oblique option 1: promax - Promax rotation is better able to handle large datasets and results in greater correlation values between factors.\nOblique option 2: oblimin The direct oblimin rotation approach is less efficient with large datasets, but produces a simpler factor structure.\n\n# Suppose parallel analysis suggests 2 factors\nefa_result &lt;- fa(re_items, nfactors = 2, rotate = \"oblimin\", fm = \"ml\")  # or \"pa\"\nprint(efa_result, sort = TRUE)\n\nFactor Analysis using method =  ml\nCall: fa(r = re_items, nfactors = 2, rotate = \"oblimin\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n    item   ML1   ML2   h2   u2 com\nRE4    4  0.85  0.03 0.76 0.24 1.0\nRE5    5  0.84  0.00 0.70 0.30 1.0\nRE1    1  0.74 -0.01 0.54 0.46 1.0\nRE2    2 -0.07  0.95 0.82 0.18 1.0\nRE6    6  0.18  0.66 0.62 0.38 1.2\nRE3    3  0.16  0.52 0.40 0.60 1.2\n\n                       ML1  ML2\nSS loadings           2.13 1.70\nProportion Var        0.36 0.28\nCumulative Var        0.36 0.64\nProportion Explained  0.56 0.44\nCumulative Proportion 0.56 1.00\n\n With factor correlations of \n    ML1 ML2\nML1 1.0 0.6\nML2 0.6 1.0\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  2.84 with Chi Square =  4215.48\ndf of  the model are 4  and the objective function was  0.02 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  1487 with the empirical chi square  9.41  with prob &lt;  0.052 \nThe total n.obs was  1487  with Likelihood Chi Square =  27.13  with prob &lt;  1.9e-05 \n\nTucker Lewis Index of factoring reliability =  0.979\nRMSEA index =  0.062  and the 90 % confidence intervals are  0.041 0.086\nBIC =  -2.09\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.94 0.94\nMultiple R square of scores with factors          0.88 0.88\nMinimum correlation of possible factor scores     0.75 0.75\n\n\n\n# Extract the factor loadings (2 factors)\nload &lt;- as.matrix(efa_result$loadings[, 1:2])\n\n# Assign variable names as rownames if they are missing\nrownames(load) &lt;- colnames(re_items)\n\n# Plot the loadings\nplot(load, type = \"n\", xlab = \"Factor 1\", ylab = \"Factor 2\", main = \"Factor Loading Plot\")\ntext(load, labels = rownames(load), cex = 0.8)\n\n\n\n\n\n\n\n\n\nfa.diagram(efa_result, simple = FALSE, digits = 2)\n\n\n\n\n\n\n\n\n\n\nColumn Definitions\n\nML1 and ML2: Standardized factor loadings on Factor 1 and Factor 2, respectively.\nh2 (Communality): Proportion of each item’s variance explained by the two factors combined.\nu2 (Uniqueness): Proportion of each item’s variance not explained by the factors (i.e., residual variance).\n\n\n\nInterpretation of Each Item\n\nFactor 1 (ML1): Ethnic Identity Exploration\n\nRE4 (“…help me understand my race/ethnic background better”) loads very strongly (0.85) on ML1, suggesting this item taps into active exploration.\nRE5 (“…talked to other people…”) loads very strongly (0.84) on ML1—again, an exploratory behavior.\nRE1 (“…find out more about my race/ethnic group…”) loads strongly (0.74) on ML1 and near-zero on ML2, reinforcing its alignment with exploration.\n\n\nThese three items all reflect actions taken to explore racial/ethnic identity, justifying labeling this factor Exploration.\n\nFactor 2 (ML2): Ethnic Identity Commitment/Belonging\n\nRE2 (“…strong sense of belonging…”) loads very strongly (0.95) on ML2 and has virtually no loading on ML1, indicating it is a strong indicator of commitment or attachment.\nRE6 (“…strong attachment…”) loads moderately on ML2 (0.66) and weakly on ML1 (0.18), suggesting it primarily reflects commitment but with some overlap.\nRE3 (“…understand what race/ethnic group membership means…”) loads moderately on ML2 (0.52), weakly on ML1 (0.16), suggesting a somewhat conceptual but still committed aspect.\n\n\nTogether, these items reflect commitment, attachment, and clarity of identity, aligning factor 2 with Commitment/Belonging to racial identity.\n\n\nCommunalities and Uniqueness\n\nHighest communality: RE2 (0.82) — well-explained by the factors.\nLowest communality: RE3 (0.40) — less well-explained, possibly more complex or ambiguous in meaning.\nUniqueness is highest for RE3 (0.60), suggesting additional variance not captured by the two-factor model (possibly due to conceptual ambiguity or measurement noise).",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>EFA in R</span>"
    ]
  },
  {
    "objectID": "efa_R.html#summary-of-factor-structure",
    "href": "efa_R.html#summary-of-factor-structure",
    "title": "EFA in R",
    "section": "Summary of Factor Structure",
    "text": "Summary of Factor Structure\nThe exploratory factor analysis revealed a clear two-factor solution, aligning with theoretical models of racial/ethnic identity development. The first factor, which we interpret as Exploration, includes items RE1, RE4, and RE5. These items reflect active efforts to learn about one’s racial or ethnic background, such as seeking out cultural knowledge, engaging in learning activities, and conversing with others to deepen understanding. The second factor, labeled Commitment/Belonging, comprises items RE2, RE6, and RE3. These items center on emotional attachment, a sense of belonging, and internal clarity regarding one’s racial or ethnic identity.\nThis factor structure supports a multidimensional model of racial/ethnic identity, consistent with developmental frameworks such as Phinney’s model. These models conceptualize identity as composed of both exploratory behaviors and a stable sense of affiliation or commitment, recognizing these as distinct yet interrelated domains. The presence of both factors in the data provides empirical support for treating racial/ethnic identity as more than a unidimensional construct.\n\nAre the factors correlated?\n\n(efa_result$Phi)\n\n          ML1       ML2\nML1 1.0000000 0.5957431\nML2 0.5957431 1.0000000\n\n\nThe use of oblique rotation in the factor analysis was both theoretically and statistically appropriate, as the constructs of exploration and commitment are expected to be correlated. In practice, individuals who engage in active exploration of their racial or ethnic heritage may also develop stronger feelings of attachment and belonging, reflecting the developmental trajectory of identity formation. The factor correlation matrix confirms this relationship: the correlation between the two factors was 0.60, indicating a moderate positive association. This supports the conceptualization of exploration and commitment as distinct yet meaningfully related dimensions of racial/ethnic identity.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>EFA in R</span>"
    ]
  },
  {
    "objectID": "efa_R.html#reliability",
    "href": "efa_R.html#reliability",
    "title": "EFA in R",
    "section": "Reliability",
    "text": "Reliability\nThe next logical question is: How good are these factors? We are interested in whether the variables in each factor form a coherent whole when used together. In other words, are the variances internally consistent between variables in a factor?\nOne of the most commonly used measures of reliability is Cronbach’s alpha (α), which assesses the internal consistency among a set of items—that is, how closely related the items are as a group. While it is not necessary to conduct an exploratory factor analysis (EFA) in order to calculate Cronbach’s alpha, EFA provides a useful context for introducing this concept. After identifying factors through EFA, Cronbach’s alpha can be used to evaluate the reliability of each factor by assessing how consistently the items within that factor measure the same underlying construct. This helps ensure that the grouped items form a coherent and reliable scale.\nTo run alpha on your factors you will first need to specify which variables belong to each factor.\n\nf1 &lt;- re_items %&gt;% select(RE1, RE4, RE5)\nf2 &lt;- re_items %&gt;% select(RE2, RE3, RE6)\n\nSo, we simply created two objects corresponding to each of our factors, \\(f1\\) and \\(f2\\) with the variables that loaded on each.\nCronbach’s alpha ranges between zero and 1.0. To evaluate the level of reliability, you are looking for values &gt; 0.70 at a minimum. Values between 0.70 and 0.80 are adequate to fair, between 0.80 and 0.90 are good and above .90 are considered excellent.\n\npsych::alpha(f1)\n\n\nReliability analysis   \nCall: psych::alpha(x = f1)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean sd median_r\n      0.85      0.85     0.8      0.66 5.8 0.0067  3.3  1     0.64\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.84  0.85  0.86\nDuhachek  0.84  0.85  0.86\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nRE1      0.84      0.84    0.72      0.72 5.2   0.0083    NA  0.72\nRE4      0.76      0.76    0.61      0.61 3.2   0.0124    NA  0.61\nRE5      0.78      0.78    0.64      0.64 3.6   0.0113    NA  0.64\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nRE1 1487  0.86  0.86  0.73   0.68  3.4 1.2\nRE4 1487  0.89  0.90  0.83   0.76  3.2 1.1\nRE5 1487  0.89  0.89  0.81   0.74  3.2 1.2\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nRE1 0.10 0.18 0.18 0.36 0.18    0\nRE4 0.08 0.18 0.30 0.31 0.13    0\nRE5 0.09 0.23 0.22 0.32 0.14    0\n\n\n\npsych::alpha(f2)\n\n\nReliability analysis   \nCall: psych::alpha(x = f2)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.81      0.81    0.75      0.58 4.1 0.0085  3.3 0.94     0.55\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.79  0.81  0.82\nDuhachek  0.79  0.81  0.82\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nRE2      0.65      0.66    0.50      0.50 2.0   0.0174    NA  0.50\nRE3      0.82      0.82    0.69      0.69 4.5   0.0095    NA  0.69\nRE6      0.70      0.71    0.55      0.55 2.4   0.0151    NA  0.55\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean   sd\nRE2 1487  0.89  0.88  0.81   0.73  3.2 1.15\nRE3 1487  0.78  0.80  0.63   0.57  3.7 0.97\nRE6 1487  0.88  0.86  0.77   0.68  3.1 1.20\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nRE2 0.08 0.20 0.30 0.29 0.14    0\nRE3 0.03 0.08 0.23 0.46 0.20    0\nRE6 0.11 0.19 0.32 0.23 0.14    0\n\n\n\nInterpretation\nWe are concerned with the “raw-alpha” value for the entire factor. This is what is reported in manuscripts as “Cronbach’s α.” That tells us how consistent a set of variables are in generaly. In this case, we are exploring item consistency within each factor. Here, the reliability coefficient (i.e., Cronbach’s α) for Factor 1 (f1) is 0.851 and for f2 its 0.805. This means that the variables that load onto each factor have excellent internally consistency.\nThe next thing to consider is how internal consistency might change after removing any single variable. To better understand this, we focus on the column titled “raw_alpha” under “Reliability if an iterm is dropped.” For example, the consistency of variables loading on f2 would be higher if we removed RE3 - the effect would be to increase alpha to 0.817. In this case, there is no need to remove a variable to increase reliability because reliability is good with the variable included.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>EFA in R</span>"
    ]
  },
  {
    "objectID": "13-lca.html",
    "href": "13-lca.html",
    "title": "LCA",
    "section": "",
    "text": "Week 14: April 14, 2026",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#introduction-to-the-topic",
    "href": "13-lca.html#introduction-to-the-topic",
    "title": "LCA",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we dive into Latent Class Analysis (LCA), a method used to identify subgroups or classes within a population based on observed data. LCA is essential for uncovering hidden heterogeneity in data.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#key-concepts",
    "href": "13-lca.html#key-concepts",
    "title": "LCA",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nLatent Classes: Unobserved subgroups identified through patterns in the data.\nClass Membership Probabilities: The likelihood that an individual belongs to a specific class.\nModel Fit: Using tools like BIC and AIC to determine the optimal number of classes.\nInterpreting Profiles: Understanding differences between identified classes.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#relevance",
    "href": "13-lca.html#relevance",
    "title": "LCA",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to use LCA to identify meaningful subgroups in their data.\nStudents will explore applications of LCA in areas like health disparities, education, and consumer behavior.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#why-this-is-important",
    "href": "13-lca.html#why-this-is-important",
    "title": "LCA",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nLCA provides insights into population heterogeneity, allowing researchers to identify distinct subgroups with unique characteristics.\nIt is a powerful tool for tailoring interventions and understanding diverse outcomes.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#how-this-ties-into-the-overall-course",
    "href": "13-lca.html#how-this-ties-into-the-overall-course",
    "title": "LCA",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon prior topics like EFA by extending latent variable modeling to categorical data.\nPrepares students for advanced mixture modeling techniques and combining LCA with SEM.\n\nBy the end of this week, students will be able to perform LCA, interpret latent class solutions, and use these insights to answer research questions about population heterogeneity.\n\nClass files\n\nDownload today’s slides here\nDownload the data for today from the National Child Health Survey (NCHS) in SPSS and CSV to import into JASP.\nHere is my example excel file to create a chart of the conditional item probabilities",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#additional-notes",
    "href": "13-lca.html#additional-notes",
    "title": "LCA",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay Calm… This is the Last Latent Class.\nWe’ve reached model convergence. The entropy is high. The fit is good. And yes… this is the final class.\nFor some of you (and for me), the fun is over. For others, the fun is just beginning. If that’s true, we’ve officially detected a latent subgroup of students.\nLet’s hope the class proportions are:\n\nClass 1 – “Loved Every Minute”: 99.1%\nClass 2 – “Thrilled It’s Over”: 0.9%\n\nModel fit? Impeccable. Classification? Accurate. Emotion? Mixed. But this… this was a class worth identifying.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "14-final-project.html",
    "href": "14-final-project.html",
    "title": "Final Project",
    "section": "",
    "text": "Week 15: April 21, 2026",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Final Project</span>"
    ]
  },
  {
    "objectID": "14-final-project.html#final-project-presentations",
    "href": "14-final-project.html#final-project-presentations",
    "title": "Final Project",
    "section": "Final Project Presentations",
    "text": "Final Project Presentations",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Final Project</span>"
    ]
  },
  {
    "objectID": "assignment.html",
    "href": "assignment.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Install libraries\nThis assignment uses the PRAMS data file that is fully described here\nThe assignment assumes the following packages have been installed:\nlibrary(emoji)\nlibrary(emoji)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(officer)\nlibrary(flextable)\nlibrary(ppcor)\nlibrary(ggcorrplot)\nlibrary(fastDummies)\nlibrary(emmeans)\nlibrary(gtsummary)\nlibrary(flextable)\nlibrary(performance)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#data-preparation-and-descriptive-statistics",
    "href": "assignment.html#data-preparation-and-descriptive-statistics",
    "title": "Assignment 1",
    "section": "1. Data Preparation and Descriptive Statistics",
    "text": "1. Data Preparation and Descriptive Statistics\n\n1.1 Load and Clean the Data\n\ndata &lt;- read.csv(\"C:/Users/barboza-salerno.1/Downloads/KSPRAMS_SUB_WEIGHT_ANALYSIS.csv\")\n\n# Selecting relevant variables \ndata &lt;- data %&gt;% dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale, Race_Ethnicity) \n\nBefore removing the missing data, let’s get a sense of the missingness across race & ethnicity. What is the distribution of missing respondents by race? Are there any implications?\n\n# Select only rows with missing data\ndf_missing &lt;- data[!complete.cases(data), ]\ndf_missing |&gt; tbl_summary(include = c(Race_Ethnicity))\n\n\n\n1.2 Missing Data Analysis\nHow many cases are missing? Calculate the number of omitted cases due to missing values:\n\ndata &lt;- data %&gt;% na.omit()\nnum_omitted &lt;- nrow(read.csv(\"C:/Users/barboza-salerno.1/Downloads/KSPRAMS_SUB_WEIGHT_ANALYSIS.csv\")) - nrow(data)\ncat(\"Number of omitted cases:\", num_omitted, \"\\n\")",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#correlation-analysis",
    "href": "assignment.html#correlation-analysis",
    "title": "Assignment 1",
    "section": "2. Correlation Analysis",
    "text": "2. Correlation Analysis\n\n2.1 Which variables are significantly correlated?\n\n\n2.2 Why are we using Spearman and not Pearson Correlaion?\n\n\n2.3 What variable changes the least after partialing out the other variables?\n\n# Compute correlation matrix\ncor_matrix &lt;- cor(data %&gt;% dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale), use = \"complete.obs\", method = \"spearman\")\n\nggplot_correlation &lt;- ggcorrplot(cor_matrix, lab = TRUE, title = \"Correlation Matrix\")\nprint(ggplot_correlation)\n\n\n\n\n\n\n\nprint(cor_matrix)\n# Compute partial correlations\npartial_corrs &lt;- pcor(data %&gt;% dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale))\nprint(partial_corrs)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#creating-dummy-variables-for-categorical-data",
    "href": "assignment.html#creating-dummy-variables-for-categorical-data",
    "title": "Assignment 1",
    "section": "3. Creating Dummy Variables for Categorical Data",
    "text": "3. Creating Dummy Variables for Categorical Data\n\n3.1 Frequency of Race/Ethnicity Categories\nWhat is the distribution by race?\n\ntable(data$Race_Ethnicity)\n\n\n\n3.2 Creating Dummy Variables\nRace/Ethnicity is categorical. We need to create dummies to include them into the model. The best way to do this is by using fastDummies. Follow this below. Describe exactly what this line of code is doing, word by word.\n\ndata &lt;- dummy_cols(data, select_columns = \"Race_Ethnicity\", remove_first_dummy = TRUE)\n\nExplanation: This function converts categorical Race_Ethnicity into binary variables while removing the first level as a reference category.\n\n\n3.3 Re-leveling Race/Ethnicity\nSometimes its nice to re-level the variable. The original variable distribution is given above.\n\ndata$Race_Ethnicity &lt;- relevel(factor(data$Race_Ethnicity), ref = \"NH White\")\n\nThis reorders the levels so that “NH White” is the reference category in our regression model.\n\ndata &lt;- dummy_cols(data, select_columns = \"Race_Ethnicity\", remove_first_dummy = TRUE)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#running-regression-models",
    "href": "assignment.html#running-regression-models",
    "title": "Assignment 1",
    "section": "4. Running Regression Models",
    "text": "4. Running Regression Models\nWe are predicting cigartette use during pregnancy by whether the pregnant person experienced any abuse during pregnancy, ACEs, is depressed (BPG_DEPRS8), and by race/ethnicity. Fit progressively more complex models: starting with Any_Abuse, etc…\n\nmodel0 &lt;- lm(CIG_1TRI ~ Any_Abuse, data = data)\nmodel1 &lt;- lm(CIG_1TRI ~ Any_Abuse + ACEs_Scale, data = data)\nmodel2 &lt;- lm(CIG_1TRI ~ Any_Abuse + ACEs_Scale + BPG_DEPRS8, data = data)\nmodel3 &lt;- lm(CIG_1TRI ~ Any_Abuse + ACEs_Scale + BPG_DEPRS8 + Race_Ethnicity_Hispanic + `Race_Ethnicity_NH Black` + Race_Ethnicity_Other, data = data)\n\nsummary(model3)\n\nWhat variable is omitted, and why? How much more of the variance is explained by ACEs_Scale, BPG_DEPRS8, and Race_Ethnicity compared to just Any_Abuse?",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#model-diagnostics",
    "href": "assignment.html#model-diagnostics",
    "title": "Assignment 1",
    "section": "5. Model Diagnostics",
    "text": "5. Model Diagnostics\nThe performance package is a very cool package in R. It facilitates model diagnostics. Then, plots it. Follow along.\n\n5.1 Checking Assumptions\n\ncheck_collinearity(model3)\ncheck_heteroscedasticity(model3)\ncheck_normality(model3)\ncheck_outliers(model3)\n\n\n\n5.2 Visualizing Diagnostic Plots\n\ndiagnostic_plots &lt;- plot(check_model(model3, panel = FALSE))\n\n# Display plots\nprint(diagnostic_plots[[2]]) # Q-Q plot\n\n\n\n\n\n\n\nprint(diagnostic_plots[[3]]) # Residuals vs Fitted plot\n\n\n\n\n\n\n\nprint(diagnostic_plots[[4]]) # Scale-location plot\n\n\n\n\n\n\n\nprint(diagnostic_plots[[5]]) # Cook’s distance",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#post-hoc-analysis-using-estimated-marginal-means-emms",
    "href": "assignment.html#post-hoc-analysis-using-estimated-marginal-means-emms",
    "title": "Assignment 1",
    "section": "6. Post-Hoc Analysis Using Estimated Marginal Means (EMMs)",
    "text": "6. Post-Hoc Analysis Using Estimated Marginal Means (EMMs)\nThe emmeans package allows us to predict cigarette use by any variable, here race/ethnicity. Then, we can use the confint to get confidence intervals.\n\nemm &lt;- emmeans(model3, pairwise ~ Race_Ethnicity_Hispanic)\nprint(emm)\nconfint(emm, level = 0.95)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#saving-results-to-a-word-document",
    "href": "assignment.html#saving-results-to-a-word-document",
    "title": "Assignment 1",
    "section": "7. Saving Results to a Word Document",
    "text": "7. Saving Results to a Word Document\nCreate a structured report including tables and regression results:\n\ndata %&gt;%\n  dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale, Race_Ethnicity) %&gt;%\n  tbl_summary(include = c(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale, Race_Ethnicity)) %&gt;%\n  as_flex_table() %&gt;%\n  print()\n\n\ndoc &lt;- read_docx()\n\ndoc1 &lt;- doc %&gt;%\n  body_add_par(\"Descriptive Statistics\", style = \"heading 1\") %&gt;%\n  body_add_flextable(\n    data %&gt;%\n      dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale, Race_Ethnicity) %&gt;%\n      tbl_summary(\n        type = all_continuous() ~ \"continuous2\",\n        statistic = all_continuous() ~ c(\n          \"{N_nonmiss}\",\n          \"{median} ({p25}, {p75})\",\n          \"{min}, {max}\"\n        ),\n        missing = \"no\"\n      ) %&gt;%\n      as_flex_table()\n  ) %&gt;%\n  body_add_par(\"Regression Model Summary\", style = \"heading 1\") %&gt;%\n  body_add_flextable(\n    tbl_regression(model3) %&gt;%  # Corrected function placement\n      add_global_p() %&gt;%\n      as_flex_table()\n  ) %&gt;%\n  body_add_par(\"Correlation Analysis\", style = \"heading 1\") %&gt;%\n  body_add_gg(ggplot_correlation)\n\nprint(doc1, target = \"C:/Users/barboza-salerno.1/Downloads/Regression_Report_FINAL.docx\")",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#write-up-guidelines",
    "href": "assignment.html#write-up-guidelines",
    "title": "Assignment 1",
    "section": "7. Write-Up Guidelines",
    "text": "7. Write-Up Guidelines\n\nWrite a report that includes:\n\nIntroduction: Briefly describe the purpose of the analysis.\nData Description: Briefly explain the data set and key variables used, including how they were coded and re-coded as applicable.\nStatistical Analysis: Describe the analytic approach taken. This includes descriptive statistics, regression analysis, diagnostic assessment, and marginal means.\nDescriptive Statistics: Present summary statistics and missing data analysis (Table 1 in Word). Correlation analysis (Figure 1).\nRegression Models: Interpret key findings from each model. Describe how the models change. Present final model (Table 2 in Word).\nModel Assumption Checks: Discuss the model’s validity based on assumption checks. Include plots as appendix.\nPost-Hoc Analysis: Interpret estimated marginal means. Create a table of the estimated marginal means for smoking by Race/Ethnicity (By hand - Table 3).\nConclusion: Summarize key insights and possible limitations. Suggest two policy recommendations for addressing smoking during pregnancy.",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#submission-instructions",
    "href": "assignment.html#submission-instructions",
    "title": "Assignment 1",
    "section": "Submission Instructions:",
    "text": "Submission Instructions:\n\nSubmit both the .R script and the Word document.\nEnsure all tables and plots are properly formatted.\nAssignment due by email by end of Week 9.",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#grading-criteria",
    "href": "assignment.html#grading-criteria",
    "title": "Assignment 1",
    "section": "Grading Criteria:",
    "text": "Grading Criteria:\n\n\n\nSection\nPoints\n\n\n\n\nData Cleaning & Preparation\n20\n\n\nDescriptive Statistics\n20\n\n\nRegression Models\n20\n\n\nModel Diagnostics\n20\n\n\nWrite-Up & Interpretation\n20\n\n\nTotal\n100\n\n\n\nGood luck with your analysis!\nSee my sample write-up",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "slides/inclass.html",
    "href": "slides/inclass.html",
    "title": "In Class Assignment",
    "section": "",
    "text": "In Class assignment – Simple Linear Regression Mechanics\nThis file uses data from the 2021 BRFSS that is available for download here\nFor this assignment, download the subsetted SPSS file I created, and follow these steps:",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>In Class Assignment</span>"
    ]
  },
  {
    "objectID": "slides/inclass.html#in-class-assignment-simple-linear-regression-mechanics",
    "href": "slides/inclass.html#in-class-assignment-simple-linear-regression-mechanics",
    "title": "In Class Assignment",
    "section": "",
    "text": "The BRFSS data contains information on 11 separate ACEs. The file codes them as follows 1 = the respondent endorsed the ACE; 2 = the respondent did not endorse the ACE. Create a scale that ranges from 0 (No ACEs) to 11 (ALL ACEs) representing the ACEs sum score (i.e. cumulative risk).\nReport the mean, range and standard deviation of your ACEs scale.\nReport the correlations between all ACEs except for the three sexual abuse/assault variables (note how these variables are measured)\nRun a simple linear regression that predicts 1) the number of days the respondent reported being in poor mental health in the past 30 days; 2) the number of days the respondent reported being in poor physical health in the past 30 days; and 3) binge drinking. Then answer the following questions\n\n\nHow many days on average did Respondents with no ACEs report having poor mental health?\nHow many days on average did Respondents with no ACEs report having poor mental health?\nHow many days on average did the respondent report binge drinking?\nInterpret the slope parameter for each model. What is the null hypothesis. Comment on the statistical significance of the slope parameter.\nHow much of the variation in mental health, physical health and binge drinking is explained by ACEs for each model respectively. What factors should be considered when interpreting R square?",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>In Class Assignment</span>"
    ]
  },
  {
    "objectID": "slides/medmod/mediationR.html",
    "href": "slides/medmod/mediationR.html",
    "title": "Simple Mediation",
    "section": "",
    "text": "The conceptual model\nMediation analysis can be conducted using the processR package. We will only examine the most simple model, Hayes Model 4.\nI will use the same dataset when we get to [moderation]. First, we will test whether the variable associated with symptoms of post-traumatic stress (tra1) mediates the association between experiencing child sexual abuse (sexab) and delinquent behaviors, which is slightly different from the question that we examined in class.\nRemove missingness (na)\nThe conceptual model that illustrates those relationships is provided below. For the simple mediation model, both conceptual and statistical diagrams are the same. NOTE that I changed the model number from 1 to 4, see the Hayes macro template I provided to you in the lecture.\nlabels=list(X=\"Sexual\\nAbuse\",M=\"PTSS\",Y=\"DELIN\")\nNotice I used the option rady to increase the y dimension of the box so that the words “Sex Abuse” will fit. Try running the code without the option to demonstrate the difference in output.\nNote m use of the package processR below.\nprocessR::pmacroModel(4,labels=labels, rady = 0.07)\nprocessR::statisticalDiagram(4,labels=labels, rady = 0.07)\nNote that we must remove missing values before the model will run. This is part of the ‘trial and error’ common in R programming.\nBelow is the same code we used before to mean center the variable for PTSS (tra1).\nmediation_example$tra1_mean &lt;- \n  mediation_example$tra1 - mean(mediation_example$tra1, na.rm = T)\nBelow is a quick plot using Base R to visualize the variables.\nplot(y=mediation_example$bcdel1, \n     x=mediation_example$tra1_mean,\n     xlab = \"PTSS\", ylab = \"DELINQ\")\ncor(mediation_example$tra1_mean, mediation_example$bcdel1)\n\n[1] 0.1356008\nresult &lt;- process(\n  data = mediation_example, \n  y = \"bcdel1\", \n  x = \"sexab\", \n  m = \"tra1\", \n  total = 1, \n  normal = 1, \n  model = 4, \n  seed = 31216)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Simple Mediation</span>"
    ]
  },
  {
    "objectID": "slides/medmod/mediationR.html#the-conceptual-model",
    "href": "slides/medmod/mediationR.html#the-conceptual-model",
    "title": "Simple Mediation",
    "section": "",
    "text": "Note\n\n\n\nNote that by including the \\n between the space in the word “Sexual Abuse” I am telling R to mimic a hard carriage return so that the words appear on different lines.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel 4 Results\n\n\n\n\n\nModel 4 Effects",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Simple Mediation</span>"
    ]
  },
  {
    "objectID": "logistic.html",
    "href": "logistic.html",
    "title": "Logistic Regression Example",
    "section": "",
    "text": "The Dataset\nThe data is a mixed variable dataset containing 14 variables of 297 patients for their heart disease diagnosis. The data comes in an R package called kmed which you can read about on your own. Patients were diagnosed with heart disease in four classes. We will used this dataset to illustrate how multiple risk factors are related to a heart disease diagnosis, such as age (years), sex (FALSE = female; TRUE = male), chest pain (1 = typical angina, 2 = atypical angina, 3 = non-anginal pain, and 4 = asymptomatic) and thalach (max heart rate achieved).\n\nlibrary(kmed)\ndat &lt;- heart\n\n\n# select variables\nlibrary(dplyr)\ndat &lt;- dat %&gt;%\n  dplyr::select(\n    age,\n    sex,\n    cp,\n    thalach,\n    class\n  )\n# print dataset's structure\nstr(dat)\n\n'data.frame':   297 obs. of  5 variables:\n $ age    : num  63 67 67 37 41 56 62 57 63 53 ...\n $ sex    : logi  TRUE TRUE TRUE TRUE FALSE TRUE ...\n $ cp     : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 4 4 3 2 2 4 4 4 4 ...\n $ thalach: num  150 108 129 187 172 178 160 163 147 155 ...\n $ class  : int  0 2 1 0 0 0 3 0 2 1 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:6] 88 167 193 267 288 303\n  ..- attr(*, \"names\")= chr [1:6] \"88\" \"167\" \"193\" \"267\" ...\n\n\n\n# rename variables\ndat &lt;- dat %&gt;%\n  dplyr::rename(\n    chest_pain = cp,\n    max_heartrate = thalach,\n    heart_disease = class\n  )\n\n\n# recode sex\ndat$sex &lt;- factor(dat$sex,\n  levels = c(FALSE, TRUE),\n  labels = c(\"female\", \"male\")\n)\n\n\n# recode chest_pain\ndat$chest_pain &lt;- factor(dat$chest_pain,\n  levels = 1:4,\n  labels = c(\"typical angina\", \"atypical angina\", \"non-anginal pain\", \"asymptomatic\")\n)\n\n\n# recode heart_disease into 2 classes\ndat$heart_disease &lt;- ifelse(dat$heart_disease == 0,\n  0,\n  1\n)\n\n\n# set labels for heart_disease\ndat$heart_disease &lt;- factor(dat$heart_disease,\n  levels = c(0, 1),\n  labels = c(\"no disease\", \"disease\")\n)\n\n\nlevels(dat$heart_disease)\n\n[1] \"no disease\" \"disease\"   \n\n\n\n# save model\nm1 &lt;- glm(heart_disease ~ age,\n  data = dat,\n  family = \"binomial\"\n)\n\n\nsummary(m1)\n\n\nCall:\nglm(formula = heart_disease ~ age, family = \"binomial\", data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.05122    0.76862  -3.970  7.2e-05 ***\nage          0.05291    0.01382   3.829 0.000128 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 394.25  on 295  degrees of freedom\nAIC: 398.25\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n# OR for age\nexp(coef(m1)[\"age\"])\n\n     age \n1.054331 \n\n\n\n# prob(heart disease) for age = 0\nexp(coef(m1)[1]) / (1 + exp(coef(m1)[1]))\n\n(Intercept) \n 0.04516478 \n\n\n\n# 95% CI for the OR for age\nexp(confint(m1,\n  parm = \"age\"\n))\n\n   2.5 %   97.5 % \n1.026699 1.083987 \n\n\n\n# predict probability to develop heart disease\npred &lt;- predict(m1,\n  newdata = data.frame(age = c(30)),\n  type = \"response\"\n)\n\n\npred\n\n        1 \n0.1878525 \n\n\n\n# predict probability to develop heart disease\npred &lt;- predict(m1,\n  newdata = data.frame(age = c(30)),\n  type = \"response\",\n  se = TRUE\n)\n\n\npred$fit\n\n        1 \n0.1878525 \n\n\n\n# 95% confidence interval for the prediction\nlower &lt;- pred$fit - (qnorm(0.975) * pred$se.fit)\nupper &lt;- pred$fit + (qnorm(0.975) * pred$se.fit)\nc(lower, upper)\n\n         1          1 \n0.07873357 0.29697138 \n\n\n\n# 95% confidence interval for the prediction\nlower &lt;- pred$fit - (1.96 * pred$se.fit)\nupper &lt;- pred$fit + (1.96 * pred$se.fit)\nc(lower, upper)\n\n         1          1 \n0.07873156 0.29697339 \n\n\n\nlibrary(sjPlot)\n\nInstall package \"strengejacke\" from GitHub (`devtools::install_github(\"strengejacke/strengejacke\")`) to load all sj-packages at once!\n\nlibrary(ggplot2)\n\n\n# plot\nplot_model(m1,\n  type = \"pred\",\n  terms = \"age\"\n) +\n  labs(y = \"Prob(heart disease)\") + theme_bw()\n\n\n\n\n\n\n\n\n\n# levels for sex\nlevels(dat$sex)\n\n[1] \"female\" \"male\"  \n\n\n\n# save model\nm2 &lt;- glm(heart_disease ~ sex,\n  data = dat,\n  family = \"binomial\"\n)\n\n\nsummary(m2)\n\n\nCall:\nglm(formula = heart_disease ~ sex, family = \"binomial\", data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.0438     0.2326  -4.488 7.18e-06 ***\nsexmale       1.2737     0.2725   4.674 2.95e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 386.12  on 295  degrees of freedom\nAIC: 390.12\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nexp(coef(m2)[\"sexmale\"])\n\n sexmale \n3.573933 \n\n\n\n# prob(disease) for sex = female\nexp(coef(m2)[1]) / (1 + exp(coef(m2)[1]))\n\n(Intercept) \n  0.2604167 \n\n\n\nchisq.test(table(dat$heart_disease, dat$sex))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(dat$heart_disease, dat$sex)\nX-squared = 21.852, df = 1, p-value = 2.946e-06\n\n\n\n# predict probability to develop heart disease\npred &lt;- predict(m2,\n  newdata = data.frame(sex = c(\"male\")),\n  type = \"response\"\n)\npred\n\n        1 \n0.5572139 \n\n\n\n# plot\nplot_model(m2,\n  type = \"pred\",\n  terms = \"sex\"\n) +\n  labs(y = \"Prob(heart disease)\")\n\n\n\n\n\n\n\n\n\n# create data frame of new patient\nnew_patient &lt;- data.frame(\n  age = 32,\n  sex = \"female\"\n)\n\n\nm3 &lt;- glm(heart_disease ~ sex + age,\n  data = dat,\n  family = \"binomial\"\n)\n# predict probability to develop heart disease\npred &lt;- predict(m3,\n  newdata = new_patient,\n  type = \"response\"\n)\n# print prediction\npred\n\n         1 \n0.06224456 \n\n\n\n# 1. age, sex and chest pain on prob of disease\nplot_model(m3,\n  type = \"pred\",\n  terms = c(\"age\",  \"sex\"),\n  ci.lvl = NA # remove confidence bands\n) +\n  labs(y = \"Prob(heart disease)\")\n\nData were 'prettified'. Consider using `terms=\"age [all]\"` to get smooth\n  plots.\n\n\n\n\n\n\n\n\n\n\ntab_model(m3, m2,\n  show.ci = FALSE, # remove CI\n  show.aic = TRUE, # display AIC\n  p.style = \"numeric_stars\" # display p-values and stars\n)\n\n\n\n\n \nheart disease\nheart disease\n\n\nPredictors\nOdds Ratios\np\nOdds Ratios\np\n\n\n(Intercept)\n0.01 ***\n&lt;0.001\n0.35 ***\n&lt;0.001\n\n\nsex [male]\n4.47 ***\n&lt;0.001\n3.57 ***\n&lt;0.001\n\n\nage\n1.07 ***\n&lt;0.001\n\n\n\n\nObservations\n297\n297\n\n\nR2 Tjur\n0.142\n0.078\n\n\nAIC\n370.435\n390.118\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\nlibrary(pROC)\n\n\n# save roc object\nres &lt;- roc(heart_disease ~ fitted(m3),\n  data = dat\n)\n# plot ROC curve\nggroc(res, legacy.axes = TRUE)\n\n\n\n\n\n\n\n\n\nres$auc\n\nArea under the curve: 0.713\n\n\n\n# plot ROC curve with AUC in title\nggroc(res, legacy.axes = TRUE) +\n  labs(title = paste0(\"AUC = \", round(res$auc, 2)))\n\n\n\n\n\n\n\n\n\nlibrary(gtsummary)\n\n\n# print table of results\ntbl_regression(m3, exponentiate = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n    female\n—\n—\n\n\n\n\n    male\n4.47\n2.57, 8.05\n&lt;0.001\n\n\nage\n1.07\n1.04, 1.10\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\n\nlibrary(finalfit)\n# set variables\ndependent &lt;- \"heart_disease\"\nindependent &lt;- c(\"age\", \"sex\")\nindependent_final &lt;- c(\"age\", \"sex\", \"chest_pain\")\n\ndat %&gt;% or_plot(dependent, independent,\n  table_text_size = 3.5 # reduce text size\n)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Logistic Regression Example</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html",
    "href": "slides/moderation/moderation.html",
    "title": "Moderation Analysis",
    "section": "",
    "text": "Prelims\ninstall.packages(c(“haven”, “interactions”, “ggplot2”, “jtools”))\n# Load libraries\nlibrary(haven)         # For reading SPSS files\nlibrary(ggplot2)       # For plotting\nlibrary(jtools)        # For interaction and J-N plot\n\nWarning: package 'jtools' was built under R version 4.3.3\n\nlibrary(interactions)  # For Johnson-Neyman analysis\n\nWarning: package 'interactions' was built under R version 4.3.3\n\n# Load the data\ndata &lt;- read_sav(\"../../slides/medmod2/sexmin_pts_delinq.sav\")\n# Check variable types\nstr(data)\n\ntibble [126 × 3] (S3: tbl_df/tbl/data.frame)\n $ sexmin: num [1:126] 0 1 0 0 0 0 0 1 0 0 ...\n  ..- attr(*, \"format.spss\")= chr \"F1.0\"\n $ delinq: num [1:126] 0 0 2 4 5 0 0 0 0 0 ...\n  ..- attr(*, \"format.spss\")= chr \"F2.0\"\n $ ptss  : num [1:126] 2 2 2 2 2 3 3 3 4 4 ...\n  ..- attr(*, \"format.spss\")= chr \"F2.0\"",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html#data-types",
    "href": "slides/moderation/moderation.html#data-types",
    "title": "Moderation Analysis",
    "section": "Data types",
    "text": "Data types\nSexual minority is binary coded as 0/1. This does not make for a nice plot, but the JN method does not accept factor variables. So, for plotting, you can convert sexmin to factor and use labels (i.e., “Sexual Minority” “Not a Sexual Minority”), otherwise skip it. Try it yourself to see what happens.\n\ndata$sexmin1 &lt;- as.factor(data$sexmin)\ndata$sexmin1 &lt;- ifelse(data$sexmin1 == 1, \"Sexual Minority\", \"Not a Sexual Minority\")",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html#the-linear-regression-model",
    "href": "slides/moderation/moderation.html#the-linear-regression-model",
    "title": "Moderation Analysis",
    "section": "The Linear Regression Model",
    "text": "The Linear Regression Model\n\n# Fit moderation model\nmod &lt;- lm(delinq ~ ptss * sexmin, data = data)\n\n# Summary of model\nsummary(mod)\n\n\nCall:\nlm(formula = delinq ~ ptss * sexmin, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8245 -1.7327 -0.7327  1.4922 11.4534 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.13733    0.61912   3.452 0.000767 ***\nptss        -0.04496    0.06167  -0.729 0.467336    \nsexmin      -0.72060    1.39755  -0.516 0.607066    \nptss:sexmin  0.25795    0.12457   2.071 0.040517 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.511 on 121 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.1406,    Adjusted R-squared:  0.1193 \nF-statistic: 6.599 on 3 and 121 DF,  p-value: 0.0003623\n\n\n\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\nTable 1. Regression Coefficients\n\n\n\n\n\n\n\n\n\n\nPredictor\nEstimate\nStd..Error\nt.value\np.value\nSignificance\n\n\n\n\nIntercept\n2.137\n0.619\n3.452\n0.001\n***\n\n\nPTSS\n-0.045\n0.062\n-0.729\n0.467\n\n\n\nSexual Minority (vs. non-minority)\n-0.721\n1.398\n-0.516\n0.607\n\n\n\nPTSS × Sexual Minority\n0.258\n0.125\n2.071\n0.041\n*\n\n\n\n\n\nThis should look familiar. The model predicts delinquent behavior using PTSS, sexual minority status, and their interaction as predictors.\nREVIEW:\n\nIntercept (2.14): This is the expected value of the outcome when PTSS = 0 and the individual is not a sexual minority.\nPTSS (-0.045): Among non-sexual minority individuals, PTSS is not significantly associated with the outcome (p = 0.467).\nSexual Minority main effect (-0.721): Among individuals with PTSS = 0, being a sexual minority is not significantly associated with the outcome (p = 0.607).\nPTSS × Sexual Minority interaction (0.258): This term is statistically significant (p = 0.041), indicating that the association between PTSS and the outcome differs by sexual minority status. Specifically, PTSS has a stronger positive effect on the outcome for sexual minority individuals.\n\n\nReminder: All model assumptions (?) must be met, unfortunately.\n\n# Visualize interaction effect\ninteract_plot(mod,\n              pred = ptss,\n              modx = sexmin,\n              plot.points = F,\n              interval = TRUE,\n              int.width = 0.95,\n              main.title = \"Moderation of PTSS and Sexual Minority Status on Delinquency\",\n              legend.main = \"Identity\",\n              x.label = \"PTSS\",\n              y.label = \"Delinquency\")",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html#interpretation",
    "href": "slides/moderation/moderation.html#interpretation",
    "title": "Moderation Analysis",
    "section": "Interpretation",
    "text": "Interpretation\nThis plot shows how post-traumatic stress symptoms (PTSS) predict delinquency, and how this relationship differs by sexual minority status.\nSolid Line (sexmin = 1) → Sexual minority individuals\n\nThe slope is positive, indicating that as PTSS increases, delinquency increases for sexual minority youth.\nThis relationship is statistically significant. Note that you can assess significance from the plot because the confidence band (shaded area) does not cross zero\n\nDashed Line (sexmin = 0) → Non-sexual minority individuals\n\nThe slope is slightly negative, mostly flat, suggesting that PTSS is not associated with delinquency in this group.\n\nInteraction effect: The effect of PTSS on delinquency depends on sexual minority status. More PTSS = More delinquency for sexual minority youth, more PTSS has no effect for youth who do not identify as a sexual minority.\n\n# Johnson-Neyman technique\njohnson_neyman(mod, pred = sexmin, modx = ptss)\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen ptss is OUTSIDE the interval [-164.38, 7.60], the slope of sexmin is p\n&lt; .05.\n\nNote: The range of observed values of ptss is [2.00, 17.00]",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html#interpretation-of-the-johnson-neyman-plot-j-n",
    "href": "slides/moderation/moderation.html#interpretation-of-the-johnson-neyman-plot-j-n",
    "title": "Moderation Analysis",
    "section": "Interpretation of the Johnson-Neyman Plot (J-N)",
    "text": "Interpretation of the Johnson-Neyman Plot (J-N)\nThis J-N plot shows how the effect of sexual minority status on delinquency changes depending on the level of PTSS.\nKey Interpretation: - The red shade shows where the effect of sexual minority status on delinquency is not statistically significant (p &gt; .05). - The blue shade shows where the effect *is** statistically significant (p &lt; .05). - The dashed vertical line marks the (J-N — the *threshold of PTSS** where the effect of sexmin becomes significant. - The black horizontal bar along the x-axis shows the *observed range of PTSS in the data**.\n\nRegions of significance\nFor individuals with PTSS scores below ~8, the difference in delinquency between sexual minority and non-minority youth is not statistically significant. However, when PTSS exceeds ~8, sexual minority youth show significantly higher delinquency compared to their peers.\n\n\nLink to policy and practice\nI have several published articles using this type of methodology. In one article Barboza-Salerno & Remillard (2023) we examined the impact of future orientation in buffering the effect of early child adversity on delinquent behavior. Read it, you should be able to write the paper now.\n\n\n\n\nBarboza-Salerno, G. E., & Remillard, A. (2023). Early child adversity and delinquent behavior in foster care youth: Do future expectations and sexual identity moderate the mediating role of posttraumatic stress? Journal of Child & Adolescent Trauma, 16(4), 945–957.",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "infant_mortality.html",
    "href": "infant_mortality.html",
    "title": "Infant Mortality Example",
    "section": "",
    "text": "Odds and Risk ratios\nRisk ratios are tricky because they are invariant, but odds ratios are not. By using risk ratios, the data can show BOTH gross disparities of infant mortality by race and also show no racial disparities at the same time. The reason comes down to the invariance property.\nOdds ratios and risk ratios are both measures used in statistics to compare the likelihood of an event occurring between two groups. However, they have different properties when it comes to interpretation.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Infant Mortality Example</span>"
    ]
  },
  {
    "objectID": "infant_mortality.html#mortality-rates-per-1000-births",
    "href": "infant_mortality.html#mortality-rates-per-1000-births",
    "title": "Infant Mortality Example",
    "section": "Mortality Rates per 1,000 births",
    "text": "Mortality Rates per 1,000 births\nThe interpretation is: in California, there are about 3.04 infant deaths per 1,000. What is going on with Indiana?\n\n(df$inf_mort_white_1000 &lt;- (\n  df$white_infant_deaths/df$white_births)*1000\n )\n\n[1] 3.047175 3.522871 2.247074 6.016995 3.653389 5.047984 5.131467 4.275928\n\n\n\nknitr::kable(\n  df[, c(1,8)],  \n  col.names = c(\n    'State', \n    'White Infant Mortality per 1,000'\n    ), \n  align = \"lc\"\n  )\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nState\nWhite Infant Mortality per 1,000\n\n\n\n\nCalifornia\n3.047175\n\n\nColorado\n3.522871\n\n\nConnecticut\n2.247074\n\n\nIndiana\n6.016995\n\n\nMaryland\n3.653389\n\n\nMichigan\n5.047984\n\n\nOhio\n5.131467\n\n\nPennsylvania\n4.275928\n\n\n\n\n\nThe infant mortality rate for Black infants is substantially higher. In Michigan, there are 14.2 Black infants who die for every 1,000 births.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Infant Mortality Example</span>"
    ]
  },
  {
    "objectID": "infant_mortality.html#mortality-ratios",
    "href": "infant_mortality.html#mortality-ratios",
    "title": "Infant Mortality Example",
    "section": "Mortality Ratios",
    "text": "Mortality Ratios\n\n(df$inf_mort_black_1000 &lt;- (\n  df$black_infant_deaths/df$black_births)*1000\n )\n\n[1]  9.066566 11.713521  8.951113 11.710539  9.584821 14.162292 13.206092\n[8] 10.747552\n\n\n\nknitr::kable(\n  df[, c(1,9)],  \n  col.names = c(\n    'State', \n    'Black Infant Mortality per 1,000'\n    ), \n  align = \"lc\"\n  )\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nState\nBlack Infant Mortality per 1,000\n\n\n\n\nCalifornia\n9.066566\n\n\nColorado\n11.713521\n\n\nConnecticut\n8.951113\n\n\nIndiana\n11.710539\n\n\nMaryland\n9.584821\n\n\nMichigan\n14.162292\n\n\nOhio\n13.206092\n\n\nPennsylvania\n10.747552\n\n\n\n\n\nBelow, I calculate the relative risk ratio for Black infants compared to Whites. You can see very large disparities. For example, in California the relative risk of death for Black infants is almost three times higher than for White infants (2.975)\n\n(df$RR_mort_black_white &lt;- \n   df$inf_mort_black_1000/df$inf_mort_white_1000)\n\n[1] 2.975401 3.324993 3.983454 1.946244 2.623542 2.805535 2.573551 2.513502",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Infant Mortality Example</span>"
    ]
  },
  {
    "objectID": "infant_mortality.html#survivorship-ratios",
    "href": "infant_mortality.html#survivorship-ratios",
    "title": "Infant Mortality Example",
    "section": "Survivorship Ratios",
    "text": "Survivorship Ratios\nLet’s calculate the survivorship ratio\n\ndf$inf_surv_white &lt;- \n  df$white_births - df$white_infant_deaths\ndf$inf_surv_black  &lt;- \n   df$black_births - df$black_infant_deaths\n\ndf$inf_surv_white_1000 &lt;- \n    (df$white_births/df$inf_surv_white)*1000\ndf$inf_surv_black_1000 &lt;- \n    (df$black_births/df$inf_surv_black)*1000\n\n\n(df$RR_surv_black_white &lt;- \n   df$inf_surv_black_1000/df$inf_surv_white_1000)\n\n[1] 1.006074 1.008288 1.006765 1.005761 1.005989 1.009245 1.008183 1.006542\n\n\n\nggplot(\n  df, \n  aes(x = as.factor(Location), \n      y = RR_mort_black_white, \n      group = 1)\n) +\n  geom_line() +\n  ylim(0, 4) +\n  labs(\n    title = \"Relative Risk of Infant Mortality: Black - White\",\n    x = \"Location\",\n    y = \"Relative Risk\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(\n  df, \n  aes(x = as.factor(Location), \n      y = RR_surv_black_white, \n      group = 1)\n) +\n  geom_line() +\n  ylim(0, 1.1) +\n  labs(\n    title = \"Relative Risk of Infant Survival: Black - White\",\n    x = \"Location\",\n    y = \"Relative Risk\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipGGthemes\n\n\n\nWe can make nicer charts with the add-on package called ggthemes. Let’s install it and see if we can make prettier charts. install.packages(ggthemes) then library(ggthemes)\n\n\n\nPlotting the differences\nBelow, I am selecting the theme called theme_stata which makes the output look like a stata graph.\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.3.3\n\nggplot(df, \n  aes(x=as.factor(Location), \n  y=RR_surv_black_white, group=1))  + \n  geom_line(color = \"midnightblue\") + \n  ylim(0, 1.1) + \n  theme_stata() +\n  labs(title = \"Black-White Survivorship\", x = \"Location\", y = \"Relative Risk\")\n\n\n\n\n\n\n\nggplot(df, \n  aes(x=as.factor(Location), \n  y=RR_mort_black_white, group=1))  + \n  geom_line(color = \"darkred\") + \n  ylim(1, 4) + \n  theme_stata() +\n  labs(\n    title = \"Black-White Mortality\", \n    x = \"Location\", \n    y = \"Relative Risk\"\n    )\n\n\n\n\n\n\n\n\n\nYour tasks\nIt is very reasonable to examine these data further.\n\nWhat research questions would you propose to examine infant mortality disparities across states?\nWould the research question be the same if you were examining survivorship versus mortality?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Infant Mortality Example</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html",
    "href": "PRAMS_Correlation_Analysis.html",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "",
    "text": "Dataset Description\nThe Pregnancy Risk Assessment Monitoring System (PRAMS) Phase 8 dataset collects data on maternal behaviors and experiences before, during, and after pregnancy. The sample is drawn from birth certificate records across multiple jurisdictions, covering 81% of U.S. live births. I would provide the link to the data but of course it is now gone due to the censorship happening with our government currently, which has substantial implications for the reproductive health of women and other persons regardless of their pregnancy status.\nThis analysis uses the data from Kansas. These data were used because I wanted to focus on associations between ACEs, maternal education, parenting stress, and intimate partner violence. Each state administers its own modules, and for some reason Kansas asked these. If you would like to read a summary of the findings from these data, check out this website.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#introduction",
    "href": "PRAMS_Correlation_Analysis.html#introduction",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Introduction",
    "text": "Introduction\nUnderstanding how early-life adversity, maternal education, and stress during pregnancy interact is crucial for maternal and child health research. This analysis examines the relationships between Adverse Childhood Experiences (ACEs), Stress During Pregnancy (STRESS), and Maternal education (Meduc) using partial and semi-partial correlation techniques. The goal is to determine whether maternal education during pregnancy influences stress levels beyond what can be explained by prior adverse experiences (ACEs).",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#research-question",
    "href": "PRAMS_Correlation_Analysis.html#research-question",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Research Question",
    "text": "Research Question\n\nDoes Maternal Education predict Stress During Pregnancy after controlling for Adverse Childhood Experiences (ACEs)?\nDoes dverse Childhood Experiences (ACEs) predict Stress During Pregnancy after controlling for Maternal Education?\nHow does the relationship between ACEs and Stress change when we control for education in both variables (Partial Correlation) vs. when we remove the effect of education only from Stress (Semi-Partial Correlation)?\n\n\nData and Variables\nClick here for the dataset used in the analysis.\nClick here for the R script for which this example is based.\nThe table below provides an overview of the key variables used in this analysis:\n\n\nWarning: package 'knitr' was built under R version 4.3.3\n\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\nPRAMS Phase 8 Variable Descriptions\n\n\n\n\n\n\n\nVariable_Name\nLabel\nRecodes\n\n\n\n\nNEED_TRAN\nAccess to Basic Needs - Affordable Transportation\nMaterial Hardship\n\n\nNEED_FOOD\nBasic Needs - Food Insecurity\nMaterial Hardship\n\n\nNEED_SHOUS\nBasic Needs - Safe Housing\nMaterial Hardship\n\n\nNEED_CHOUS\nBasic Needs - Consistent Housing\nMaterial Hardship\n\n\nNEED_CROWD\nBasic Needs - Crowded Housing\nMaterial Hardship\n\n\nNEED_UTIL\nBasic Needs - Utilities\nMaterial Hardship\n\n\nNEED_PHON\nBasic Needs - Phone Access\nMaterial Hardship\n\n\nNEED_OTH\nBasic Needs - Other Unmet Needs\nMaterial Hardship\n\n\nHDP_SAF\nPartner Threatened Safety\nIntimate Partner Violence\n\n\nHDP_ANGR\nPartner Anger/Threats\nIntimate Partner Violence\n\n\nHDP_CTRL\nPartner Control of Activities\nIntimate Partner Violence\n\n\nHDP_SEX\nPartner Forced Sexual Activity\nIntimate Partner Violence\n\n\nSTRS_FM3\nClose Family Member Hospitalized\nSocial Stressor\n\n\nSTRS_DV3\nDivorce or Separation\nSocial Stressor\n\n\nSTRS_MOV\nMoved to a New Address\nSocial Stressor\n\n\nSTRSHOME\nHomelessness\nSocial Stressor\n\n\nSTRS_JOB\nPartner Lost Job\nSocial Stressor\n\n\nSTRS_WRK\nLost Job Despite Wanting to Work\nSocial Stressor\n\n\nSTRS_PAY\nCut in Work Hours or Pay\nSocial Stressor\n\n\nSTRS_AWY\nSeparated from Partner Due to Deployment/Travel\nSocial Stressor\n\n\nSTRS_ARG\nFrequent Arguments with Partner\nSocial Stressor\n\n\nSTRS_PG\nPartner Did Not Want Pregnancy\nSocial Stressor\n\n\nSTRS_BIL\nProblems Paying Rent/Mortgage\nSocial Stressor\n\n\nSTRS_DRG\nClose Person Had a Drug or Alcohol Problem\nSocial Stressor\n\n\nSTRS_DH3\nClose Person Died\nAdverse Childhood Experiences\n\n\nCDHD_DVRC\nParent or Guardian Divorced/Separated\nAdverse Childhood Experiences\n\n\nCDHD_HOUS\nMoved Due to Rent/Mortgage Issues\nAdverse Childhood Experiences\n\n\nCDHD_FOOD\nWent Hungry Due to Food Insecurity\nAdverse Childhood Experiences\n\n\nCDHD_JAIL\nParent or Guardian Involved in Legal System\nAdverse Childhood Experiences\n\n\nCDHD_SUBS\nParent or Guardian Had Substance Use Issues\nAdverse Childhood Experiences\n\n\nCDHD_FSTR\nExperience in Foster Care\nAdverse Childhood Experiences\n\n\nCIG_1TRI\nCigarettes Smoked Daily - 1st Trimester\nCigarettes Smoked Daily - 1st Trimester\n\n\nMAT_ED\nMaternal Years of Education\nMaternal Education",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#explanation-of-correlation-types",
    "href": "PRAMS_Correlation_Analysis.html#explanation-of-correlation-types",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Explanation of Correlation Types",
    "text": "Explanation of Correlation Types\n\nCorrelation\nDefinition: Measures the direct (linear) relationship between two variables without controlling for other influences.\n\nWhat does it ask? “How strongly are two variables associated?” “When one variable increases, does the other also increase (positive correlation), decrease (negative correlation), or are the variables not linearly related?”\nWhy does this matter?\n\n\nIdentifies basic associations: Helps determine whether two variables have a relationship worth further investigation.\nGuides hypothesis development: Provides an initial understanding before applying more complex statistical techniques like partial correlation or regression.\nDoes not imply causation: A strong correlation does not mean one variable causes changes in the other; it simply indicates they move together.\n\n\nExample Interpretation: If ACEs and Stress During Pregnancy have a positive correlation, it suggests that individuals with higher adverse childhood experiences tend to experience more stress during pregnancy. However, other factors (e.g., education, income) could be influencing this relationship.\nPositive values indicate a direct relationship (when one increases, the other also increases).\nNegative values indicate an inverse relationship (when one increases, the other decreases).\nValues closer to 0 suggest a weak or no linear association between the variables. This DOES NOT mean that no relationship exists.\n\n\n\nPartial Correlation\nDefinition: Measures the direct relationship between two variables while controlling for the effect of a third variable.\n\nWhat does it ask? “What is the association between Maternal Education and Stress During Pregnancy, after removing the effect of ACEs from both?”\n\nWhy does this matter? If the correlation remains significant, this suggests that education independently contributes to stress beyond what can be explained by early-life adversity.\n\n\n\nSemi-Partial (Part) Correlation\nDefinition: Measures the relationship between two variables while controlling for a third variable’s effect on just one of them.\n\nWhat does it ask? “What is the association between Maternal Education and Stress During Pregnancy, after removing the effect of ACEs only from Stress During Pregnancy?”\nWhy does this matter? If the relationship weakens, it suggests that ACEs account for some of the variance in how education affects stress. Another way to think about this is that ACEs partly explain how education effects stress. And, yet another ‘connect-the-dots’ moment is that tf the relationship weakens, then ACEs mediate some of the observed effects of education on stress",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#data-import-and-preprocessing",
    "href": "PRAMS_Correlation_Analysis.html#data-import-and-preprocessing",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Data Import and Preprocessing",
    "text": "Data Import and Preprocessing\n\nlibrary(tidyverse)\nlibrary(ppcor) # For partial and semi-partial correlation\n\n# Load dataset\ndf &lt;- read.csv(\"data/KSPRAMS_SUB_COR.csv\")\n\n# Select relevant columns\ndata_subset &lt;- df %&gt;% \n  dplyr::select(ACEs, STRESS, Meduc) %&gt;% \n  na.omit()\n\n# Check summary statistics\nsummary(data_subset)\n\n      ACEs           STRESS           Meduc      \n Min.   :0.000   Min.   : 0.000   Min.   :1.000  \n 1st Qu.:0.000   1st Qu.: 0.000   1st Qu.:3.000  \n Median :0.000   Median : 1.000   Median :4.000  \n Mean   :1.043   Mean   : 1.892   Mean   :3.916  \n 3rd Qu.:2.000   3rd Qu.: 3.000   3rd Qu.:5.000  \n Max.   :6.000   Max.   :14.000   Max.   :5.000  \n\n\n\n\n\n\n\n\nWarning\n\n\n\nPlease pay particular attention to the handling of missing data in R. There are many ways to handle missing data with significant implications for your analysis. For some good guides to handling missing data in R see How does R handle missing data from UCLA and Missing data tutorial in R from Princeton University.\n\n\n\n# Compute Pearson correlation matrix\ncor_matrix &lt;- cor(data_subset, method = \"pearson\")\n\n# Print correlation matrix\nprint(cor_matrix)\n\n             ACEs     STRESS      Meduc\nACEs    1.0000000  0.3411429 -0.2399357\nSTRESS  0.3411429  1.0000000 -0.2105974\nMeduc  -0.2399357 -0.2105974  1.0000000\n\n\n\nComputed Correlation Matrix\nThe table below presents Pearson correlation coefficients between ACEs (Adverse Childhood Experiences), STRESS (Stress During Pregnancy), and Meduc (Maternal Education Level). Each correlation value ranges from -1 to 1.\nBelow is the Pearson correlation matrix for the selected variables:\n\n\n\nVariable\nACEs\nSTRESS\nMeduc\n\n\n\n\nACEs\n1.00\n0.341\n-0.239\n\n\nSTRESS\n0.341\n1.00\n-0.210\n\n\nMeduc\n-0.239\n-0.210\n1.00\n\n\n\nInterpretation of Results:\n\nACEs and STRESS ( r = 0.341 ):\n\n\nThere is a moderate positive correlation between adverse childhood experiences and stress during pregnancy.\nThis suggests that individuals who report more childhood adversity tend to experience higher stress levels during pregnancy.\n\n\nACEs and Meduc ( r = -0.239 ):\n\n\nThere is a moderate negative correlation between ACEs and maternal education.\nThis indicates that individuals with higher levels of childhood adversity tend to have lower levels of educational attainment.\n\n\nSTRESS and Meduc ( r = -0.210 ):\n\n\nA moderate negative correlation exists between stress and maternal education.\nThis suggests that individuals with lower educational attainment tend to experience higher stress levels during pregnancy.\n\n\n\nSummary & Implications\nWomen with more Adverse Childhood Experiences (ACEs) tend to experience higher levels of stress during pregnancy and have lower education levels. Higher maternal education is linked to lower stress, potentially due to greater access to resources, stability, or support systems. This is important. When interpreting results, it is very important to go back to the original operationalization of the variables so we are on the same page. How is stress defined here? And, what may be some limitations both methodologicall and conceptually? Whereas we know this analysis is not causal, we can begin linking the results to some important policy implications See Barboza-Salerno (2020) here .",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#compute-partial-and-semi-partial-correlations",
    "href": "PRAMS_Correlation_Analysis.html#compute-partial-and-semi-partial-correlations",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Compute Partial and Semi-Partial Correlations",
    "text": "Compute Partial and Semi-Partial Correlations\n\n# Compute Partial Correlation (controlling for ACEs)\npartial_corr &lt;- pcor(data_subset)\nprint(\"Partial Correlation Matrix:\")\n\n[1] \"Partial Correlation Matrix:\"\n\nprint(partial_corr$estimate)\n\n             ACEs     STRESS      Meduc\nACEs    1.0000000  0.3062254 -0.1829213\nSTRESS  0.3062254  1.0000000 -0.1410824\nMeduc  -0.1829213 -0.1410824  1.0000000\n\n# Compute Semi-Partial Correlation (controlling for ACEs only in STRESS)\nsemi_partial_corr &lt;- spcor(data_subset)\nprint(\"Semi-Partial Correlation Matrix:\")\n\n[1] \"Semi-Partial Correlation Matrix:\"\n\nprint(semi_partial_corr$estimate)\n\n             ACEs     STRESS      Meduc\nACEs    1.0000000  0.2972802 -0.1719481\nSTRESS  0.2993577  1.0000000 -0.1326190\nMeduc  -0.1788189 -0.1369612  1.0000000",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#correlation-analysis",
    "href": "PRAMS_Correlation_Analysis.html#correlation-analysis",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Correlation Analysis",
    "text": "Correlation Analysis\nWe computed three types of correlation matrices:\n\nZero-Order (Regular) Correlation: The direct correlation between variables.\nPartial Correlation: The correlation between two variables while controlling for a third variable (Meduc).\nSemi-Partial Correlation: The correlation between two variables while controlling for a third variable’s influence on just one of them.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#results-and-interpretation",
    "href": "PRAMS_Correlation_Analysis.html#results-and-interpretation",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Results and Interpretation",
    "text": "Results and Interpretation\n\nRegular (Zero-Order) Correlation from above\n\n\n\nVariable\nACEs\nSTRESS\nMeduc\n\n\n\n\nACEs\n1.00\n0.341\n-0.239\n\n\nSTRESS\n0.341\n1.00\n-0.210\n\n\nMeduc\n-0.239\n-0.210\n1.00\n\n\n\n\nACEs and STRESS: ( r = 0.341 ) → A moderate positive correlation, indicating that individuals with higher ACEs tend to experience higher stress levels during pregnancy.\nACEs and Meduc: ( r = -0.239 ) → A negative correlation, suggesting that individuals with more childhood adversity tend to have lower educational attainment.\nSTRESS and Meduc: ( r = -0.210 ) → A negative correlation, implying that lower maternal education is linked to higher stress.\n\n\n\n\nPartial Correlation\n\n\n\nVariable\nACEs\nSTRESS\nMeduc\n\n\n\n\nACEs\n1.00\n0.306\n-0.182\n\n\nSTRESS\n0.306\n1.00\n-0.141\n\n\nMeduc\n-0.182\n-0.141\n1.00\n\n\n\n\nACEs and STRESS controlling (partialing out) Meduc: ( r = 0.306 ) → The correlation remains positive but slightly decreases compared to the zero-order correlation ( r = 0.341 ), indicating that while education partly explains the relationship, ACEs still have a significant effect on stress.\nACEs and Meduc controlling ACEs: ( r = -0.182 ) → The correlation between ACEs and education weakens slightly after controlling for stress.\nSTRESS and Meduc controlling for STRESS: ( r = -0.141 ) → The relationship between stress and education is weaker when controlling for ACEs.\n\n\n\nImplication of Partial Correlation\nBy controlling for maternal education, we isolate the direct effect of ACEs on stress. The reduction in correlation values suggests that education contributes to stress, but ACEs continue to have a strong independent effect.\n\n\n\nSemi-Partial Correlation (Controlling for Meduc Only in STRESS)\n\n\n\nVariable\nACEs\nSTRESS\nMeduc\n\n\n\n\nACEs\n1.00\n0.297\n-0.171\n\n\nSTRESS\n0.299\n1.00\n-0.132\n\n\nMeduc\n-0.178\n-0.136\n1.00\n\n\n\n\nACEs and STRESS: ( r = 0.297 ) → A slight decrease in the strength of the relationship compared to the partial correlation (( r = 0.306 )), meaning that education explains a small part of the ACEs-stress relationship. In other words, it’s the correlation between ACEs and the part of STRESS that is independent of Meduc.\nACEs and Meduc: ( r = -0.171 ) → The correlation weakens slightly after accounting for stress.\nSTRESS and Meduc: ( r = -0.132 ) → A marginal decrease in the strength of the relationship.\n\n\n\nImplication of Semi-Partial Correlation\nThe semi-partial correlations examine how each independent variable uniquely contributes to the dependent variable while removing the effect of the control variable only from the dependent variable. Since the values remain similar to the partial correlations, this suggests that maternal education influences stress, but ACEs still have an independent impact.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#key-takeaways",
    "href": "PRAMS_Correlation_Analysis.html#key-takeaways",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nACEs are a strong predictor of stress during pregnancy, even after controlling for maternal education.\nMaternal education partially explains the relationship between ACEs and stress, but ACEs continue to have an independent effect.\nHigher maternal education is associated with lower stress, but its effect is weaker when ACEs are accounted for.\nThe semi-partial correlation results confirm that maternal education plays a role, but ACEs have an independent impact on stress, highlighting the importance of addressing childhood adversity in maternal mental health interventions.\n\nThese results suggest that public health interventions should target both early-life adversity (ACEs) and educational opportunities to reduce stress during pregnancy, which may have long-term effects on maternal and child health outcomes.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#conclusion",
    "href": "PRAMS_Correlation_Analysis.html#conclusion",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis demonstrates how Maternal Education, Stress During Pregnancy, and ACEs interact within a structured correlation framework. Using partial and semi-partial correlations, we disentangle the direct and indirect effects of early-life adversity on maternal stress, providing insights for interventions aimed at reducing stress-related health disparities. If ACEs remains a significant predictor of stress after controlling for education, interventions targeting early life adversity may help alleviate psychosocial stress during pregnancy, improving both maternal and child health outcomes.\n\n\n\n\nBarboza-Salerno, G. E. (2020). Cognitive readiness to parent, stability and change in postpartum parenting stress and social-emotional problems in early childhood: A second order growth curve model. Children and Youth Services Review, 113, 104958.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "cohensd.html",
    "href": "cohensd.html",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "",
    "text": "Introduction\nThis analysis examines the Area Deprivation Index (ADI) across U.S. counties. The goal is to assess disparities between areas of high- and low-deprivation (by county) and quantify the effect size using Cohen’s d.\nThe ADI provides a measure of socioeconomic disadvantage, with higher values indicating greater deprivation. We also map ADI values across counties and exclude non-contiguous U.S. states and territories.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#data-collection-preparation",
    "href": "cohensd.html#data-collection-preparation",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "Data Collection & Preparation",
    "text": "Data Collection & Preparation\n\n# Install and load required packages\n# install.packages(\"sociome\")\n# install.packages(\"ggplot2\")\n# install.packages(\"dplyr\")\n# install.packages(\"sf\")\n# install.packages(\"tigris\")\n# install.packages(\"effectsize\")\n\nlibrary(sociome)     # For ADI data\nlibrary(ggplot2)     # For visualization\nlibrary(dplyr)       # For data manipulation\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(sf)          # For mapping spatial data\n\nLinking to GEOS 3.11.2, GDAL 3.7.2, PROJ 9.3.0; sf_use_s2() is TRUE\n\nlibrary(tigris)      # For county boundaries\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nlibrary(effectsize)  # For Cohen's d calculation\n\nWarning: package 'effectsize' was built under R version 4.3.3\n\n\nWe first retrieve the ADI data for 2020 at the county level.\n\n# --- Step 1: Get ADI Data by County ---\nadi_data &lt;- get_adi(year = 2020, geography = \"county\")\n\n# Extract GEOID, county name, and ADI\nadi_data &lt;- adi_data %&gt;%\n  dplyr::select(GEOID, NAME, ADI)\n\n\nExcluding Non-Contiguous U.S. States and Territories\nTo focus on the contiguous U.S., we exclude: - Alaska (02) & Hawaii (15) - U.S. territories: Puerto Rico, Guam, American Samoa, Northern Mariana Islands, U.S. Virgin Islands.\n\n# List of FIPS codes for non-contiguous states/territories\nnon_contiguous_fips &lt;- c(\"02\", \"15\", \"60\", \"66\", \"69\", \"72\", \"78\")  \n\n# Load county boundaries and exclude non-contiguous areas\ncounties &lt;- counties(cb = TRUE, resolution = \"20m\", year = 2020) %&gt;%\n  filter(!STATEFP %in% non_contiguous_fips)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |=================================                                     |  46%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |======================================================================| 100%\n\n# Merge ADI data with county geometries\nadi_map_data &lt;- counties %&gt;%\n  left_join(adi_data, by = c(\"GEOID\" = \"GEOID\"))",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#mapping-adi-by-county",
    "href": "cohensd.html#mapping-adi-by-county",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "Mapping ADI by County",
    "text": "Mapping ADI by County\nThe following map visualizes area deprivation across the contiguous U.S.. Darker areas represent higher deprivation levels.\nYou should play around with ggplot to get used to its functionality.\n\nlibrary(ggplot2)\nggplot(adi_map_data) +\n  geom_sf(aes(fill = ADI), color = NA) +\n  scale_fill_viridis_c(option = \"plasma\", name = \"ADI\") +\n  labs(\n    title = \"Area Deprivation by County (Contiguous U.S., ADI Data 2020)\",\n    subtitle = \"Excludes Alaska, Hawaii, & U.S. Territories\",\n    caption = \"Source: Sociome package ADI 2020\"\n  ) +\n  theme_void()",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#adi-disparities-effect-size-cohens-d",
    "href": "cohensd.html#adi-disparities-effect-size-cohens-d",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "ADI Disparities & Effect Size (Cohen’s d)",
    "text": "ADI Disparities & Effect Size (Cohen’s d)\nWe divide counties into low-deprivation (least disadvantaged, bottom 25%) and high-deprivation (most disadvantaged, top 25%) groups. The income differences between these groups are quantified using Cohen’s d, a measure of standardized effect size.\n\n# Define thresholds: Top 25% (most deprived) vs. Bottom 25% (least deprived)\nquantiles &lt;- quantile(adi_data$ADI, probs = c(0.25, 0.75), na.rm = TRUE)\nlow_deprivation &lt;- adi_data %&gt;% filter(ADI &lt;= quantiles[1])\nhigh_deprivation &lt;- adi_data %&gt;% filter(ADI &gt;= quantiles[2])\n\n# Compute Cohen's d\ncohens_d_value &lt;- cohens_d(high_deprivation$ADI, low_deprivation$ADI)\n\n# Print Cohen's d result\nprint(cohens_d_value)",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#interpretation-of-cohens-d-results",
    "href": "cohensd.html#interpretation-of-cohens-d-results",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "Interpretation of Cohen’s d Results",
    "text": "Interpretation of Cohen’s d Results\nCohen’s d tells us how large the difference in ADI between low- and high-deprivation counties:\n\n( d = 0.2 ) → Small effect\n( d = 0.5 ) → Medium effect\n( d = 0.8+ ) → Large effect\n\nIf the result is negative, it means that high-deprivation counties have significantly higher ADI scores than low-deprivation counties. The absolute value of d still represents the effect size.\n\nKey Findings\n🔹 A large Cohen’s d suggests significant deprivation disparities between counties with low and high deprivation.\n🔹 This reinforces the need for economic policies addressing regional deprivation.\n🔹 Mapping ADI allows for geographically targeted interventions to reduce socioeconomic inequalities.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#conclusion",
    "href": "cohensd.html#conclusion",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "Conclusion",
    "text": "Conclusion\nThe effect size tells us that the ADI in low-deprivation counties is 3.39 standard deviations higher than in high-deprivation counties. Since Cohen’s d is standardized, this means the deprivation difference is very large in relative terms. This analysis confirms that county-level deprivation is strongly associated with huge disparities in ADI, with high-deprivation counties having more economic inequaltity, low educational attainment, and less financial strength. Future research could associate some outcome across levels of ADI.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "admissions_R_ex.html",
    "href": "admissions_R_ex.html",
    "title": "Admissions Data Analysis",
    "section": "",
    "text": "Introduction\nThis code analyzes admissions data, focusing on predicting SAT Math scores using SAT Verbal scores and high school class size. The analysis employs linear regression models, including simple linear regression, multiple linear regression, correlation assessments, and visualizations to explore the relationships between these variables.\nHere is the admissions data and you can download the script to run in R here\n\n\nLoad Necessary Libraries\n\nlibrary(foreign)    # For reading .sav files\nlibrary(ggplot2)    # For visualization\nlibrary(dplyr)      # For data manipulation\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(gtsummary)  # For creating regression tables\nlibrary(officer)    # For exporting to Word\nlibrary(flextable)  # For table formatting\n\n\nAttaching package: 'flextable'\n\n\nThe following object is masked from 'package:gtsummary':\n\n    continuous_summary\n\n\n\n\nLoad and Inspect Data\n\nadmissions &lt;- read.spss(\"data/admissions.sav\", to.data.frame = TRUE)\nhead(admissions) # Display first few rows\n\n  row_number paiddeposit scholarship_yes_no Type_of_scholarship_offered Female\n1          7           1                  0                                  0\n2         12           0                  0                                  0\n3         19           1                  0                                  0\n4         23           1                  0                                  0\n5         25           0                  0                                  0\n6         28           0                  0                                  1\n             Race HS_rank HS_class_size HS_Quintile HS_CODE\n1 white               190           281        4/5   392835\n2 white               111           223        3/5   393655\n3 white               109           371        2/5    51830\n4 Asian                88           266        2/5   390527\n5 white                NA            NA              390870\n6 white                59           382        1/5   392655\n                  HS_NAME SAT_verbal ACT Honors_college_eligible\n1 FRANKLIN_REGIONAL_SR_HI        560  NA                     no \n2 CENTRAL_CATHOLIC_HIGH_S        600  NA                     no \n3 WESTCHESTER_HIGH_SCHOOL        550  NA                     no \n4 CEDAR_CLIFF_HIGH_SCHOOL        520  NA                     no \n5 HOLY_GHOST_PREPARATORY         650  NA                     no \n6 PENN_MANOR_HIGH_SCHOOL         460  20                     no \n  distancefromPitt state Number_of_family_alumni father_alumni grand_alumni\n1        14.228946    PA                       0             0            0\n2         7.162134    PA                       0             0            0\n3       232.363382    PA                       0             0            0\n4       163.462296    PA                       0             0            0\n5       261.534151    PA                       0             0            0\n6       192.493359    PA                       0             0            0\n  mother_alumni sibling_alumni step_parent_alumni other_family_alumni\n1             0              0                  0                   0\n2             0              0                  0                   0\n3             0              0                  0                   0\n4             0              0                  0                   0\n5             0              0                  0                   0\n6             0              0                  0                   0\n  SAT_composite ACT_as_SAT Max_Test_Score Training from_PA\n1          1180         NA           1180        0       1\n2          1150         NA           1150        0       1\n3          1190         NA           1190        0       1\n4          1140         NA           1140        0       1\n5          1200         NA           1200        0       1\n6           940        950            950        0       1\n               alumniYN SAT_math\n1 Family is not an alum      620\n2 Family is not an alum      550\n3 Family is not an alum      640\n4 Family is not an alum      620\n5 Family is not an alum      550\n6 Family is not an alum      480\n\n\n\n\nData Preprocessing\n\nadmissions_clean &lt;- admissions %&gt;% \n  dplyr::select(SAT_math, SAT_verbal, HS_class_size) %&gt;% \n  na.omit()\n\n\n\nSimple Linear Regression: SAT Math ~ SAT Verbal\n\nsimple_model &lt;- lm(SAT_math ~ SAT_verbal, data = admissions_clean)\nsummary(simple_model) # Regression summary\n\n\nCall:\nlm(formula = SAT_math ~ SAT_verbal, data = admissions_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-168.125  -43.568   -1.667   41.119  188.462 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 329.24934   19.49133   16.89   &lt;2e-16 ***\nSAT_verbal    0.45572    0.03448   13.22   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61.42 on 689 degrees of freedom\nMultiple R-squared:  0.2023,    Adjusted R-squared:  0.2011 \nF-statistic: 174.7 on 1 and 689 DF,  p-value: &lt; 2.2e-16\n\n\n\nInterpretation:\n\nSAT Verbal has a positive effect on SAT Math scores (Estimate = 0.45572, p &lt; 0.001).\nModel explains ~20.2% of variance in SAT Math scores (Adjusted R² = 0.2011), meaning SAT Verbal alone is a moderate predictor.\nResiduals appear reasonably distributed, suggesting no major violations of normality assumptions.\n\n\n\n\nCompute Fitted Values and Residuals\n\nadmissions_clean$fitted_simple &lt;- fitted(simple_model)\nadmissions_clean$residuals_simple &lt;- residuals(simple_model)\n\n\n\nCompute Standardized Values\n\nadmissions_clean$std_fitted_simple &lt;- scale(admissions_clean$fitted_simple)\nadmissions_clean$std_residuals_simple &lt;- scale(admissions_clean$residuals_simple)\n\n\n\nVisualization: Residuals vs. Fitted\n\nggplot(admissions_clean, aes(x = std_fitted_simple, y = std_residuals_simple)) +\n  geom_point(color = \"blue\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Standardized Residuals vs. Standardized Fitted Values (Simple Model)\",\n       x = \"Standardized Fitted Values\", y = \"Standardized Residuals\")\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nResiduals are fairly symmetrically distributed around zero, suggesting the linear model is appropriate.\nNo major patterns in residuals indicate homoscedasticity.\n\n\n\n\nHistogram of Residuals\n\nggplot(admissions_clean, aes(x = residuals_simple)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals (Simple Model)\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nResiduals follow a normal-like distribution, supporting the assumption of normality.\n\n\n\n\nCorrelation Analysis\n\ncor(admissions_clean[, c(\"SAT_math\", \"SAT_verbal\", \"fitted_simple\", \"residuals_simple\")], use = \"complete.obs\")\n\n                  SAT_math    SAT_verbal fitted_simple residuals_simple\nSAT_math         1.0000000  4.497305e-01  4.497305e-01     8.931643e-01\nSAT_verbal       0.4497305  1.000000e+00  1.000000e+00    -5.014076e-16\nfitted_simple    0.4497305  1.000000e+00  1.000000e+00    -1.828283e-15\nresiduals_simple 0.8931643 -5.014076e-16 -1.828283e-15     1.000000e+00\n\n\n\nInterpretation:\n\nStrong positive correlation between SAT Math and SAT Verbal (r ≈ 0.45).\nFitted values highly correlate with SAT Verbal, confirming its predictive power.\n\n\n\n\nMultiple Linear Regression: SAT Math ~ SAT Verbal + HS Class Size\n\nmultiple_model &lt;- lm(SAT_math ~ SAT_verbal + HS_class_size, data = admissions_clean)\nsummary(multiple_model)\n\n\nCall:\nlm(formula = SAT_math ~ SAT_verbal + HS_class_size, data = admissions_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-165.924  -44.589   -1.418   40.825  197.261 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   314.14654   19.47735  16.129  &lt; 2e-16 ***\nSAT_verbal      0.44864    0.03401  13.192  &lt; 2e-16 ***\nHS_class_size   0.06030    0.01295   4.656 3.88e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 60.52 on 688 degrees of freedom\nMultiple R-squared:  0.2266,    Adjusted R-squared:  0.2244 \nF-statistic: 100.8 on 2 and 688 DF,  p-value: &lt; 2.2e-16\n\n\n\nInterpretation:\n\nHS Class Size has a small but significant positive effect (Estimate = 0.06030, p &lt; 0.001).\nExplained variance increases to 22.4%, showing a slight improvement over the simple model.\n\n\n\n\nVisualization of SAT Verbal Effect\n\nggplot(admissions_clean, aes(x = SAT_verbal, y = SAT_math)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", col = \"blue\") +\n  labs(title = \"Effect of SAT Verbal on SAT Math\", x = \"SAT Verbal\", y = \"SAT Math\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nGenerate Regression Summary Table\n\nmlr_table &lt;- multiple_model %&gt;% \n  tbl_regression(label = list(SAT_verbal = \"SAT Verbal Score\", HS_class_size = \"High School Class Size\")) %&gt;%\n  modify_caption(\"Table 1: Multiple Linear Regression Results\") %&gt;%\n  add_n()\n\n\n\nSave Table to Word\n\nmlr_flextable &lt;- as_flex_table(mlr_table)\ndoc &lt;- read_docx()\ndoc &lt;- body_add_flextable(doc, value = mlr_flextable)\nprint(doc, target = \"MLR_Results.docx\")\n\n\n\nConclusion\n\nKey Findings:\n\nSAT Verbal scores significantly predict SAT Math scores, explaining ~20% of the variance.\nAdding HS Class Size improves the model slightly, raising the explained variance to 22.4%.\nBoth models suggest a linear relationship, with residuals showing normality and no major violations.\n\n\n\nImplications:\n\nSchools aiming to improve SAT Math scores may focus on strengthening verbal skills.\nClass size appears to play a small but relevant role in performance.\nFurther research could explore additional predictors (e.g., socioeconomic factors, study habits).",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Admissions Data Analysis</span>"
    ]
  },
  {
    "objectID": "nscaw.html",
    "href": "nscaw.html",
    "title": "NSCAW I In-Class Exercise",
    "section": "",
    "text": "Introduction\nThis exercise explores child aggression and trauma using the NSCAW I dataset. Because this is designed for you to do, I supressed all of the output. The chunks of code give you a hints regarding the code that will answer each question. Create an R script and answer each question below. Cut and paste the chunk of code into your script, and fill it in so that it runs.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-1-load-the-data",
    "href": "nscaw.html#step-1-load-the-data",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 1: Load the Data",
    "text": "Step 1: Load the Data\nMake sure all of these libraries are installed or you will not be able to run the code. Also, make sure that your data set is in a subdirectory called data in the same directory as the one in which your R script is saved.\n\n# Load necessary libraries\nlibrary(foreign)    # For reading SPSS files\nlibrary(dplyr)      # For data manipulation\nlibrary(ggplot2)    # For visualization\nlibrary(gtsummary)  # For creating regression tables\nlibrary(officer)    # For exporting tables to Word\nlibrary(flextable)  # For table formatting\n\n# Load NSCAW I dataset\nnscaw &lt;- read.spss(\"data/nscaw.sav\", to.data.frame = TRUE)\n\n# Inspect the first few rows\nhead(nscaw)\n\nQuestion: What type of variables are included in the dataset?\nTo get a sense of the variables in the dataset click here.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-2-select-variables-handle-missing-data",
    "href": "nscaw.html#step-2-select-variables-handle-missing-data",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 2: Select Variables & Handle Missing Data",
    "text": "Step 2: Select Variables & Handle Missing Data\n\n# Select relevant variables\nnscaw_clean &lt;- nscaw %&gt;% \n  dplyr::select(FILL THE VARIABLES IN HERE) \n\n# Remove missing values\nnscaw_clean &lt;- na.omit(nscaw_clean)\n\n# View summary statistics\nsummary(nscaw_clean)\n\nHint: Look at the summary statistics—do any variables have extreme values?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-3-compute-correlations",
    "href": "nscaw.html#step-3-compute-correlations",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 3: Compute Correlations",
    "text": "Step 3: Compute Correlations\n\n# Compute correlation matrix\ncor(nscaw_clean, use = \"complete.obs\")\n\nQuestion: Which variables are most strongly correlated? Does the direction make sense?\n\nRun the regression of child aggression on trauma score and age",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-4-run-a-multiple-regression-model",
    "href": "nscaw.html#step-4-run-a-multiple-regression-model",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 4: Run a Multiple Regression Model",
    "text": "Step 4: Run a Multiple Regression Model\n\n# Run regression: Predict aggression using trauma score and age\nreg_model &lt;- lm(WRITE THE CODE TO RUN THE REGRESSION)\n\n# Display model summary\nsummary(reg_model)\n\nHint: Examine the coefficients and p-values. Is trauma a significant predictor of aggression?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-5-compute-fitted-values-residuals",
    "href": "nscaw.html#step-5-compute-fitted-values-residuals",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 5: Compute Fitted Values & Residuals",
    "text": "Step 5: Compute Fitted Values & Residuals\n\n# Compute fitted values and residuals\nnscaw_clean$fitted &lt;- fitted(PROVIDE THE CODE HERE)\nnscaw_clean$residuals &lt;- residuals(reg_model)\n\n# Compute standardized residuals\nnscaw_clean$std_residuals &lt;- PROVIDE THE CODE HERE(nscaw_clean$residuals)\n\nQuestion: Why do we standardize residuals? What does this help us understand?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-6-visualize-residuals",
    "href": "nscaw.html#step-6-visualize-residuals",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 6: Visualize Residuals",
    "text": "Step 6: Visualize Residuals\n\n# Plot histogram of residuals\nggplot(nscaw_clean, aes(x = residuals)) +\n  PROVIDE THE CODE HERE(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\nHint: Look for skewness—are residuals normally distributed?\n\n\n# Plot standardized residuals vs. predicted values\nggplot(nscaw_clean, aes(x = fitted, y = std_residuals)) +\n  geom_point(PROVIDE THE CODE HERE) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(PROVIDE THE CODE HERE)\n\nHint: If you see patterns in the residuals, what assumption may be violated?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-7-create-export-regression-table",
    "href": "nscaw.html#step-7-create-export-regression-table",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 7: Create & Export Regression Table",
    "text": "Step 7: Create & Export Regression Table\n\n# Generate regression summary table\nreg_table &lt;- reg_model %&gt;% \n  tbl_regression(\n    label = list(tra1 = \"PTS Score\", bcagg1 = \"Aggressive Behavior\", ageY = \"Age\")\n  ) %&gt;% \n  modify_caption(\"Table 1: Regression Results for Aggression\")\n\n# Convert to flextable and export to Word\nreg_flextable &lt;- as_flex_table(reg_table)\ndoc &lt;- read_docx()\ndoc &lt;- body_add_flextable(doc, value = reg_flextable)\nprint(doc, target = \"Regression_Results.docx\")\n\nHint: Where does the p-value appear in the regression table? How does it inform significance?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#deliverables",
    "href": "nscaw.html#deliverables",
    "title": "NSCAW I In-Class Exercise",
    "section": "Deliverables",
    "text": "Deliverables\nDiscuss the following:\n\nCorrelation matrix output\nRegression model summary\nHistogram of residuals\nResiduals vs. fitted plot\nRegression results table (Word document)",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#discussion-questions",
    "href": "nscaw.html#discussion-questions",
    "title": "NSCAW I In-Class Exercise",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nBased on your results, does trauma significantly predict aggression?\nHow does child age influence the relationship between trauma and aggression?\nAre the residuals normally distributed? If not, what would you do differently?\nIf the p-value for trauma is significant, what does that imply in real-world terms?\nHow could you improve this model?\n\nFinal Thought: This exercise helps you develop a deeper understanding of how trauma influences child behavior. Future analyses could incorporate more variables (e.g., social support, environment) for better predictions.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "reading.html",
    "href": "reading.html",
    "title": "Required Course Materials",
    "section": "",
    "text": "Required Texts",
    "crumbs": [
      "**Additional Resources**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Required Course Materials</span>"
    ]
  },
  {
    "objectID": "reading.html#required-software",
    "href": "reading.html#required-software",
    "title": "Required Course Materials",
    "section": "Required Software",
    "text": "Required Software\n\nOpen Source Software\n\nJASP (Just Another Statistics Program)\n\nWe will use JASP to perform some analyses that SPSS does not. JASP is free, open source software available for both Mac, Linux and Windows platforms. To download this software please visit https://jasp-stats.org/download\n\n\n\nProcess for SPSS\n\nAn SPSS macro that runs dozens of mediation, moderation and conditional process models written by Andrew Hayes. Download the macro here https://www.processmacro.org/download.html and follow the installation instructions.\n\n\n\n\nProprietary\n\nSPSS",
    "crumbs": [
      "**Additional Resources**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Required Course Materials</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Reading List",
    "crumbs": [
      "**Additional Resources**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "references.html#reading-list",
    "href": "references.html#reading-list",
    "title": "References",
    "section": "",
    "text": "Linear Regression\n\nThis paper Razak (2019) provides an example of Simple Linear Regression.\nThis paper Littleton et al. (2024) provides an example of using Historic Redlining Scores to understand higher rates of child welfare reporting.\nPenn State has a nice tutorial with examples on how to conduct linear regression in R\n\n\n\nLogistic Regression\n\nThis paper uses the glm function to model the presence of fictional fantastic characters Corlatti (2021). Super cool.\nWhile we do not cover it here, this paper explains how to use multilevel modeling with a categorical dependent variable: Merlo et al. (2006).\nA recent co-authored manuscript used logistic regression, you can read it: Meshelemiah et al. (2024)\n\n\n\nMediation and Moderation\n\nThis paper Livingston & Haardörfer (2019) should be read together with Glick et al. (2019).\nThis paper is a tutorial on how to use the SPSS PROCESS macro by Hayes Clement & Bradley-Garcia (2022)\nI have used moderation and mediation in several papers, here is one example: Barboza-Salerno & Meshelemiah (2024)\n\n\n\nFactor Analysis\n\nThis paper has some cool visualizations: Štiglic et al. (2023) and I downloaded it here\nI have used factor analytic techniques in many papers, here is one example: Elise Barboza & Siller (2021)\n\n\n\nPower Analysis\nThis paper is good to follow if you need to calculate power for causal models Qin (2023)\n\n\nDummy Variable Coding\nThis paper is a must read Johfre & Freese (2021)\n\n\nSocial Justice Applications",
    "crumbs": [
      "**Additional Resources**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "references.html#while-not-directly-stating-it-in-this-paper-barboza2020cognitive-i-found-increases-in-post-partum-parenting-stress-is-linked-to-poor-socio-emotional-adjustment-in-children.-my-examination-of-the-prams-data-set-suggests-that-psychosocial-stressors-during-pregnancy-a-vulnerable-period-for-many-increases-the-risk-of-intimate-partner-violence.",
    "href": "references.html#while-not-directly-stating-it-in-this-paper-barboza2020cognitive-i-found-increases-in-post-partum-parenting-stress-is-linked-to-poor-socio-emotional-adjustment-in-children.-my-examination-of-the-prams-data-set-suggests-that-psychosocial-stressors-during-pregnancy-a-vulnerable-period-for-many-increases-the-risk-of-intimate-partner-violence.",
    "title": "References",
    "section": "While not directly stating it, in this paper Barboza-Salerno (2020) I found increases in post-partum parenting stress is linked to poor socio-emotional adjustment in children. My examination of the PRAMS data set suggests that psychosocial stressors during pregnancy, a vulnerable period for many, increases the risk of intimate partner violence.",
    "text": "While not directly stating it, in this paper Barboza-Salerno (2020) I found increases in post-partum parenting stress is linked to poor socio-emotional adjustment in children. My examination of the PRAMS data set suggests that psychosocial stressors during pregnancy, a vulnerable period for many, increases the risk of intimate partner violence.\n\n\n\n\nBarboza-Salerno, G. E. (2020). Cognitive readiness to parent, stability and change in postpartum parenting stress and social-emotional problems in early childhood: A second order growth curve model. Children and Youth Services Review, 113, 104958.\n\n\nBarboza-Salerno, G. E., & Meshelemiah, J. C. (2024). Associations between early child adversity and lifetime suicide attempts among gender diverse individuals: A moderated mediation. Child Abuse & Neglect, 149, 106705.\n\n\nClement, L. M., & Bradley-Garcia, M. (2022). A step-by-step tutorial for performing a moderated mediation analysis using PROCESS. The Quantitative Methods for Psychology, 18(3), 258–271.\n\n\nCorlatti, L. (2021). Regression Models, Fantastic Beasts, and Where to Find Them: A Simple Tutorial for Ecologists Using R. Bioinformatics and Biology Insights, 15, 11779322211051522. https://doi.org/10.1177/11779322211051522Regression modeling is a workhorse of statistical ecology that allows to find relationships between a response variable and a set of explanatory variables. Despite being one of the fundamental statistical ideas in ecological curricula, regression modeling can be complex and subtle. This paper is intended as an applied protocol to help students understand the data, select the most appropriate models, verify assumptions, and interpret the output. Basic ecological questions are tackled using data from a fictional series, ?Fantastic beasts and where to find them,? with the aim to show how statistical thinking can foster curiosity, creativity and imagination in ecology, from the formulation of hypotheses to the interpretation of results.\n\n\nElise Barboza, G., & Siller, L. A. (2021). Child maltreatment, school bonds, and adult violence: A serial mediation model. Journal of Interpersonal Violence, 36(11-12), NP5839–NP5873.\n\n\nGlick, A. F., Farkas, J. S., Mendelsohn, A. L., Fierman, A. H., Tomopoulos, S., Rosenberg, R. E., Dreyer, B. P., Melgar, J., Varriano, J., & Yin, H. S. (2019). Discharge Instruction Comprehension and Adherence Errors: Interrelationship Between Plan Complexity and Parent Health Literacy. The Journal of Pediatrics, 214, 193–200.e3. https://doi.org/10.1016/j.jpeds.2019.04.052Objective To examine associations between parent health literacy, discharge plan complexity, and parent comprehension of and adherence to inpatient discharge instructions. Study design This was a prospective cohort study of English/Spanish-speaking parents (n = 165) of children \\(\\leq\\)12 years discharged on \\(\\geq\\)1 daily medication from an urban, public hospital. Outcome variables were parent comprehension (survey) of and adherence (survey, in-person dosing assessment, chart review) to discharge instructions. Predictor variables included low parent health literacy (Newest Vital Sign score 0-3) and plan complexity. Generalized estimating equations were used to account for the assessment of multiple types of comprehension and adherence errors for each subject, adjusting for ethnicity, language, child age, length of stay, and chronic disease status. Similar analyses were performed to assess for mediation and moderation. Results Error rates were highest for comprehension of medication side effects (50%), adherence to medication dose (34%), and return precaution (78%) instructions. Comprehension errors were associated with adherence errors (aOR, 8.7; 95% CI, 5.9-12.9). Discharge plan complexity was associated with comprehension (aOR, 7.0; 95% CI, 5.4-9.1) and adherence (aOR, 5.5; 95% CI, 4.0-7.6) errors. Low health literacy was indirectly associated with adherence errors through comprehension errors. The association between plan complexity and comprehension errors was greater in parents with low (aOR, 8.3; 95% CI, 6.2-11.2) compared with adequate (aOR, 3.8; 95% CI, 2.2-6.5) health literacy (interaction term P = .004). Conclusions Parent health literacy and discharge plan complexity play key roles in comprehension and adherence errors. Future work will focus on the development of health literacy-informed interventions to promote discharge plan comprehension.\n\n\nJohfre, S. S., & Freese, J. (2021). Reconsidering the reference category. Sociological Methodology, 51(2), 253–269.\n\n\nLittleton, T., Freisthler, B., Boyd, R., Smith, A. M., & Barboza-Salerno, G. (2024). Historical redlining, neighborhood disadvantage, and reports of child maltreatment in a large urban county. Child Abuse & Neglect, 156, 107011.\n\n\nLivingston, M. D., & Haardörfer, R. (2019). A gentle introduction to mediation and moderation. The Journal of Pediatrics, 214, 246–248.\n\n\nMerlo, J., Chaix, B., Ohlsson, H., Beckman, A., Johnell, K., Hjerpe, P., Råstam, L., & Larsen, K. (2006). A brief conceptual tutorial of multilevel analysis in social epidemiology: Using measures of clustering in multilevel logistic regression to investigate contextual phenomena. Journal of Epidemiology & Community Health, 60(4), 290–297.\n\n\nMeshelemiah, J. C., Dellor, E., Karandikar, S., Munshi, A., Barboza-Salerno, G., & Steinke, H. R. (2024). Adverse childhood experiences, women who are sex trafficked, and social service utilization: Implications for social work. Social Work, swae024.\n\n\nQin, X. (2023). Sample size and power calculations for causal mediation analysis: A Tutorial and Shiny App. Behavior Research Methods, 56(3), 1738–1769. https://doi.org/10.3758/s13428-023-02118-0\n\n\nRazak, M. R. R. (2019). Child social welfare institution participation in the implementation of good governance.\n\n\nŠtiglic, G., Budler, L. C., & Watson, R. (2023). 15 running a confirmatory factor analysis in r: A step-by-step tutorial. In K. Č. Trifkovič, M. Lorber, N. M. Reljić, & G. Štiglic (Eds.), Education and research (pp. 207–222). De Gruyter. https://doi.org/doi:10.1515/9783110786088-015",
    "crumbs": [
      "**Additional Resources**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "ass1writeup.html",
    "href": "ass1writeup.html",
    "title": "Assignment 1 Write-up",
    "section": "",
    "text": "Dataset: Pregnancy Risk Assessment Monitoring System (PRAMS)\nThe data for this study were drawn from the Kentucky Pregnancy Risk Assessment Monitoring System (PRAMS), a state-based surveillance system that collects data on maternal behaviors and experiences before, during, and shortly after pregnancy. The dataset used in this study, KSPRAMS_SUB_WEIGHT_ANALYSIS.csv, included key variables such as maternal smoking during the first trimester (CIG_1TRI), history of abuse (Any_Abuse), Adverse Childhood Experiences (ACEs_Scale), perinatal depression (BPG_DEPRS8), and race/ethnicity (Race_Ethnicity). To ensure data integrity, cases with missing values were omitted, resulting in a final analytical sample of 5,172 participants.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Assignment 1 Write-up</span>"
    ]
  },
  {
    "objectID": "ass1writeup.html#bonus",
    "href": "ass1writeup.html#bonus",
    "title": "Assignment 1 Write-up",
    "section": "Bonus",
    "text": "Bonus\n\nAPHA Abstract\nThe APHA abstracts are due at the end of March. If the assumptions of this model were not violated we could submit an abstract based on these results. Here is my sample abstract (~250 words) based on the above write-up, and formatted for the conference.\n\nBackground\nMaternal smoking during pregnancy remains a significant public health concern, with implications for both maternal and child health. Psychosocial risk factors such as adverse childhood experiences (ACEs), a history of abuse, and perinatal depression may contribute to smoking behaviors. This study investigates the association between these factors and smoking during the first trimester of pregnancy while also examining racial/ethnic disparities.\n\n\nMethods\nData were drawn from the Kentucky Pregnancy Risk Assessment Monitoring System (PRAMS). The final analytical sample consisted of 5,172 participants. Linear regression models were used to examine the association between smoking during the first trimester and key psychosocial risk factors. Race/ethnicity was included to assess disparities. Diagnostic tests were performed to evaluate model assumptions, including multicollinearity, normality, and heteroscedasticity.\n\n\nResults\nA history of abuse was associated with a 2.29-unit increase in smoking (p &lt; 0.001). Each additional ACE was linked to a 0.44-unit increase (p &lt; 0.001), with a one standard deviation increase (1.41 points) predicting a 0.62-unit increase and an interquartile range increase (2 points) predicting a 0.89-unit increase. Perinatal depression was associated with a 1.04-unit increase in smoking (p &lt; 0.001). Mothers with a history of abuse smoked 1.85 more cigarettes per day than those without abuse. Hispanic mothers exhibited significantly lower smoking rates compared to Non-Hispanic Whites (p &lt; 0.001).\n\n\nConclusion\nPsychosocial factors play a crucial role in maternal smoking behaviors. Targeted interventions incorporating mental health and trauma-informed care are essential in reducing prenatal smoking rates, particularly among at-risk populations.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Assignment 1 Write-up</span>"
    ]
  },
  {
    "objectID": "assign2.html",
    "href": "assign2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Instructions\nAssignment 2 uses several datasets. Please read the instructions carefully. There are five questions. The first question asks you to perform a multiple linear regression analysis. The second question asks you to conduct a logistic regression. The third question is a latent class analysis. The fourth question is a factor analysis. And finally, a mediation, moderation, and mediated moderation (the last of which is optional).\n\n\nData\n\nQuestion 1: social2.sav\nQuestion 2: depress.sav\nQuestion 3: lca.csv\nQuestion 4: wiscsem.sav\nQuestion 5: employee.sav\n\n\n\nVideo\nAfter our review session, I will post the video here.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "final.html",
    "href": "final.html",
    "title": "Final Stats II Assignment",
    "section": "",
    "text": "Instructions\nLength: 2–3 double-spaced pages (not including tables, figures, or references)\nRequired Outputs: Two tables and one figure, the following analysis detailed below\nDue Date: Monday, April 28, 2025\nSubmission: Email to barboza-salerno.1@osu.edu\nSoftware: R, SPSS, JASP, or a combination.\nExample:\nSoftware Used: R (lavaan, mclust, psych), SPSS (PROCESS macro v4.2), JASP\nFor your final 2–3 page paper, you will conduct a statistical analysis using one of the datasets we’ve worked with in class (e.g., the Pregnancy Risk Assessment Monitoring System (PRAMS), Census/American Community Survey, the Well-Being of LGB Populations, etc.) OR you may use your own dataset with prior approval. This project gives you the opportunity to demonstrate mastery of one or more multivariate statistical techniques. You must select one of the following:\nYou must include two well-formatted tables and one figure illustrating your findings.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#instructions",
    "href": "final.html#instructions",
    "title": "Final Stats II Assignment",
    "section": "",
    "text": "Multiple linear regression\nLogistic regression\nModeration\nMediation\nConditional process modeling\nFactor analysis\nLatent class analysis (LCA)",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#dataset-and-variables-1-paragraph",
    "href": "final.html#dataset-and-variables-1-paragraph",
    "title": "Final Stats II Assignment",
    "section": "1. Dataset and Variables (1 paragraph)",
    "text": "1. Dataset and Variables (1 paragraph)\nDescribe the dataset and provide context—what is it, where did it come from, what does it measure, what years were the data collected? Be specific about your sample size, time frame, unit of analysis, and any relevant information. Then clearly define all variables used in your analysis, including your outcome, predictors, moderators, mediators, latent constructs, or class indicators. If you collapsed, transformed, or recoded any variables, explain why. Specify the research question, and the hypotheses you are testing.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#statistical-model-and-justification-23-paragraphs",
    "href": "final.html#statistical-model-and-justification-23-paragraphs",
    "title": "Final Stats II Assignment",
    "section": "2. Statistical Model and Justification (2–3 paragraphs)",
    "text": "2. Statistical Model and Justification (2–3 paragraphs)\nSpecify which statistical technique you used and why it fits your research question and data. If you selected a model based on the nature of your outcome (e.g., binary, continuous, or latent), explain this. Provide a conceptual diagram of your model. Also address the assumptions of your model, how you evaluated them, and any diagnostic checks performed.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#results-24-paragraphs",
    "href": "final.html#results-24-paragraphs",
    "title": "Final Stats II Assignment",
    "section": "3. Results (2–4 paragraphs)",
    "text": "3. Results (2–4 paragraphs)\nPresent your model results in a narrative that clearly communicates the key findings. Include:\n\nTable 1: Descriptive statistics (e.g., means, SDs, frequencies)\nTable 2: Model summary (e.g., regression table, factor loadings, odds ratios, or class-specific probabilities)\nFigure 1: A plot showing model results (e.g., interaction graph, path diagram, factor analysis diagram, etc.)",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#interpretation-and-assumptions-1-paragraph",
    "href": "final.html#interpretation-and-assumptions-1-paragraph",
    "title": "Final Stats II Assignment",
    "section": "4. Interpretation and Assumptions (1 paragraph)",
    "text": "4. Interpretation and Assumptions (1 paragraph)\nExplain what your results mean in theoretical or applied terms. Reflect on effect sizes, statistical significance, and implications. Discuss how assumptions were met or violated, and whether transformations or adjustments were necessary.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#model-specific-guidelines",
    "href": "final.html#model-specific-guidelines",
    "title": "Final Stats II Assignment",
    "section": "Model-Specific Guidelines",
    "text": "Model-Specific Guidelines\n\nMultiple Linear Regression\nUse when your outcome is continuous. Justify your inclusion of predictors and check assumptions including linearity, homoscedasticity, and multicollinearity. Report R², adjusted R², and residual diagnostics.\n\n\nLogistic Regression\nUse when the outcome is binary. Report odds ratios, confidence intervals, and predicted probabilities. Describe how you assessed model fit (i.e., sensitivity, specificity).\n\n\nModeration\nUse when you suspect the effect of a predictor on the outcome varies by another variable. Report interaction terms and simple effects (non-interaction terms). Use plots to illustrate interaction effects like we created using Excel, or in R.\n\n\nMediation\nUse to test indirect effects. Clearly define paths. Use bootstrapped CIs for indirect effects and report estimates.\n\n\nConditional Process Modeling\nUse when a mediator and moderator interact. Identify moderated paths, report conditional indirect effects, and include a conceptual diagram.\n\n\nFactor Analysis\nUse when identifying latent dimensions. Report KMO, eigenvalues, scree plot, factor loadings, variance explained, rotation method, and reliability.\n\n\nLatent Class Analysis (LCA)\nUse to uncover latent subgroups. Report number of classes tested, AIC, BIC, entropy, conditional probabilities, and class prevalence.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  }
]
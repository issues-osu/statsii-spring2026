[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics for Social Work",
    "section": "",
    "text": "Welcome to SW 8409: Statistics II\nThis book integrates statistical concepts with real-world applications, focusing on equitable data analysis and actionable insights. It is designed for social work researchers, activists, and students seeking to harness the power of data for transformative change.\n\n\n\n\n\n\nNote\n\n\n\nI created this list of some really cool datasets for you to review.\n\n\nThe book is built for my Stats II course in the College of Social Work at The Ohio State University.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistics for Social Work</span>"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus: Statistics for Social Work",
    "section": "",
    "text": "Miscellaneous Course Policies\nPlease download the OSU and CSW course policies that are incorporated by reference within this course.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Syllabus: Statistics for Social Work</span>"
    ]
  },
  {
    "objectID": "syllabus.html#course-information",
    "href": "syllabus.html#course-information",
    "title": "Syllabus: Statistics for Social Work",
    "section": "Course Information",
    "text": "Course Information\nCourse Title: Statistics II: Equity-Focused Data Analysis\nInstructor: Dr. Gia Elise Barboza-Salerno\nInstitution: College of Social Work, The Ohio State University\nTerm: Spring 2026",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Syllabus: Statistics for Social Work</span>"
    ]
  },
  {
    "objectID": "syllabus.html#contact-information",
    "href": "syllabus.html#contact-information",
    "title": "Syllabus: Statistics for Social Work",
    "section": "Contact Information",
    "text": "Contact Information\nOffice Hours: Mondays 2–4 PM, or by appointment.\nEmail: barboza-salerno@osu.edu",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Syllabus: Statistics for Social Work</span>"
    ]
  },
  {
    "objectID": "Assignments.html",
    "href": "Assignments.html",
    "title": "Assignments and Due Dates",
    "section": "",
    "text": "Schedule of Exercises and Due Dates\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nExercises and Deliverables\nDue Date\n\n\n\n\nWeek 1\nPre-Course Assessment\nComplete pre-course assessment.\nJanuary 13, 2026\n\n\nWeek 2\nIntroduction to the Course\nBegin thinking about how to use data to reclaim your story.\nJanuary 20, 2026\n\n\nWeek 3\nSimple Regression\nInteractive Escape Room Exercise. Data Makeover Challenge: Reimagine data using storytelling.\nJanuary 27, 2026\n\n\nWeek 4\nMultiple Regression\nHypothesis Auction: Justify chosen testable hypotheses. Explain regression results to argue for policy change. Assignment 1 Distributed.\nFebruary 3, 2026\n\n\nWeek 5\nEffect Sizes & Confidence Intervals\nDebate Exercise: Practical and legal significance of findings. Write an op-ed on significance.\nFebruary 10, 2026\n\n\nWeek 6\nAssumptions and Violations of Assumptions\nAssumption Diagnosis Clinic: Diagnose and “treat” assumption violations. Create a “prescription card” summarizing fixes.\nFebruary 17, 2026\n\n\nWeek 7\nHierarchical Regression & Dummy Variables\nRegression Battle: Build the best hierarchical model. Write a brief on ethical implications of dummy variable coding.\nFebruary 24, 2026\n\n\nWeek 8\nLogistic Regression\nPredictive Policy Game: Use predictions for interventions. Create a policy recommendation. Submit Assignment 1.\nMarch 3, 2026\n\n\nWeek 9\nMediation & Suppressor Variables\nData Detective Roleplay: Investigate intervention mechanisms. Examine a “case file” for mediation analysis. Assignment 2 Distributed.\nMarch 10, 2026\n\n\nWeek 10\nSpring Break\nN/A\nN/A\n\n\nWeek 11\nModeration in Regression\nBuild-a-Story Workshop: Narratives around moderation analysis. Create a 1-page illustrated story on moderation findings.\nMarch 24, 2026\n\n\nWeek 12\nExploratory Factor Analysis (EFA)\nFactor Scavenger Hunt: Interpret factor loadings. Create an infographic summarizing EFA findings.\nMarch 31, 2026\n\n\nWeek 13\nConfirmatory Factor Analysis (CFA)\nModel Critique Workshop: Propose refinements to a CFA model. Submit a report evaluating and refining the CFA model.\nApril 7, 2026\n\n\nWeek 14\nLatent Class Analysis (LCA)\nLatent Storytelling: Use LCA findings to understand group experiences. Create a “persona deck” illustrating latent group characteristics. Submit Assignment 2.\nApril 14, 2026\n\n\nWeek 15\nStudent Presentations and Review\nPresent Final Project. Review the course content.\nApril 21, 2026\n\n\nFinal Exam\nCreate, Validate, and Apply Scales\nTake Final Exam or Submit a Publishable Manuscript.\nApril 28, 2026",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignments and Due Dates</span>"
    ]
  },
  {
    "objectID": "01-introduction.html",
    "href": "01-introduction.html",
    "title": "Introduction to the Course",
    "section": "",
    "text": "Course Goals and Objectives\nThe course, Statistics II focuses on an equitable approach to data analysis. It aims to equip students with advanced statistical techniques while fostering critical thinking about how to apply those models to social work applications. I have tried to find a good balance of instruction, innovation, and hands-on learning. I want you to be excited about statistics and data; hence, I have tried to stucture the course in a way that encourages you to explore regression, measurement, and latent variable models in the context of social justice. By emphasizing storytelling and data interpretation, students will develop the skills needed to reclaim and communicate narratives of oppression, focusing on equity and systemic challenges. The course also focuses on practical applications, such as building models and interpreting statistical findings to support policy changes and advocate for marginalized communities.\nOne of the course’s primary objectives is to prepare students to use statistics as a tool for actionable change. Weekly sessions integrate technical skills, such as using R for data analysis and visualization, with real-world social work challenges. Activities like the “Data Makeover Challenge” and “Latent Storytelling” push students to think creatively about data, while assignments emphasize ethical implications and advocacy. My idea about writing an oped comes from the workshop I did in the summer of 2024, where I learned how to write one effectively. You can read it here.\nI have also tried very hard to make the course integrative. That is the reason for this website. There are (and will be) links between modules, readings, and assignments so that everything is connected as it should be. This is obviously a lot of work, so I appreciate your patience, and consideration.\nHopefully, by the end of the semester, students will have gained not only proficiency in statistical methods but also the confidence to apply them meaningfully to address pressing social issues.",
    "crumbs": [
      "**Course Overview**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introduction to the Course</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html",
    "href": "02-simple-regression.html",
    "title": "Introduction to Simple Linear Regression",
    "section": "",
    "text": "Week 3: January 27, 2026",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#todays-reading",
    "href": "02-simple-regression.html#todays-reading",
    "title": "Introduction to Simple Linear Regression",
    "section": "Today’s Reading",
    "text": "Today’s Reading\n\nDiez et al., Chapter 8, pp. 304-340. Intro to linear regression. Be sure to check out the embedded videos.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#simple-linear-regression-introduction-to-the-topic",
    "href": "02-simple-regression.html#simple-linear-regression-introduction-to-the-topic",
    "title": "Introduction to Simple Linear Regression",
    "section": "Simple Linear Regression – Introduction to the Topic",
    "text": "Simple Linear Regression – Introduction to the Topic\nThis week, we will delve into Simple Linear Regression, a foundational tool in statistical analysis that allows us to model relationships between two variables. Students will learn how to interpret the slope, intercept, and residuals, and use regression output to draw meaningful conclusions about data. Through this process, students will develop a deeper understanding of how regression can be used to predict outcomes and test hypotheses in social work research.\nIn this unit we will learn to quantify the relationship between two numerical variables, as well as modeling numerical response variables using a numerical or categorical explanatory variable.\n\n\nWhat will students learn this week?\n\nThe fundamental components of a simple linear regression model (slope, intercept, and residuals).\nHow to interpret regression output, including unstandardized and standardized coefficients.\nThe practical steps to fit a simple linear regression model in R using lm().\nHow to visualize regression results and residuals using ggplot2.\n\n\n\n\nWhy is this topic important?\nSimple Linear Regression serves as the building block for more advanced statistical methods, such as multiple regression, moderation, and mediation analysis. It allows social work researchers to identify relationships between variables, predict outcomes, and inform data-driven decision-making. Mastering this concept is essential for understanding more complex techniques later in the course.\n\n\n\nHow does it relate to previous or future content?\n\nTies to previous content: Builds upon last week’s review of descriptive statistics and introduces the concept of relationships between variables.\nPrepares for future topics: Provides a foundation for upcoming topics like multiple regression (Week 5), where we will expand from one predictor to multiple predictors, and interaction effects (Week 9), where regression will be used to explore moderating relationships.\n\n\nThis session emphasizes the practical and theoretical importance of regression analysis, helping students connect statistical techniques to real-world social work applications.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#class-files",
    "href": "02-simple-regression.html#class-files",
    "title": "Introduction to Simple Linear Regression",
    "section": "Class Files",
    "text": "Class Files\n\nLecture Notes\n\nToday’s Lecture Notes\n\n\n\nR Code\n\nIntroduction to R",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#resources",
    "href": "02-simple-regression.html#resources",
    "title": "Introduction to Simple Linear Regression",
    "section": "Resources",
    "text": "Resources\n\nHere is my annotated file for correlation and SLR\nHere is the data I used if you want to replicate it in SPSS",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#todays-reading-1",
    "href": "02-simple-regression.html#todays-reading-1",
    "title": "Introduction to Simple Linear Regression",
    "section": "Today’s Reading",
    "text": "Today’s Reading\n\nPrimary Reading: Simple Linear Regression\nOptional Reading: Extrapolatoin - an example of what not to do despite the potential publication in a highly regarded journal",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#r-lab-files",
    "href": "02-simple-regression.html#r-lab-files",
    "title": "Introduction to Simple Linear Regression",
    "section": "R Lab Files",
    "text": "R Lab Files\n\nLab Instructions\nLab Dataset\nThe Escape Room Exercise",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "02-simple-regression.html#additional-notes",
    "href": "02-simple-regression.html#additional-notes",
    "title": "Introduction to Simple Linear Regression",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nRemain calm",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html",
    "href": "03-multiple-regression.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Week 4: February 3, 2026",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#reading",
    "href": "03-multiple-regression.html#reading",
    "title": "Multiple Linear Regression",
    "section": "Reading",
    "text": "Reading\n\nDiez et al. Chapter 9: Multiple Regression, up through pp 371; sec. 9.5",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#week-4-multiple-linear-regression-introduction-to-the-topic",
    "href": "03-multiple-regression.html#week-4-multiple-linear-regression-introduction-to-the-topic",
    "title": "Multiple Linear Regression",
    "section": "Week 4: Multiple Linear Regression – Introduction to the Topic",
    "text": "Week 4: Multiple Linear Regression – Introduction to the Topic\nThis week, we will explore Multiple Linear Regression, a powerful extension of simple regression that allows us to analyze relationships between a dependent variable and multiple predictors. Students will learn how to specify, fit, and interpret multiple regression models, including how to assess their statistical significance and practical relevance. This week’s focus is on building and refining regression models that capture the complexity of real-world social work research.\n\n\nWhat will students learn this week?\n\nThe core components of multiple regression models, including F-tests, p-values, R², and adjusted R².\n\nHow to specify hypotheses in a multiple regression context.\n\nHow to fit and interpret multiple regression models in R using lm().\n\nTechniques to evaluate assumptions and diagnose issues in multiple regression models.\n\n\n\n\nWhy is this topic important?\nMultiple Linear Regression is one of the most widely used tools in statistical analysis. It enables social work researchers to: - Explore complex relationships between multiple predictors and outcomes. - Control for confounding variables and better isolate the effect of specific predictors. - Answer nuanced research questions that cannot be addressed with simple regression.\nBy mastering multiple regression, students gain the ability to analyze more realistic and multifaceted data, making their findings more robust and applicable to real-world settings.\n\n\n\nHow does it relate to previous or future content?\n\nTies to previous content: Builds on the foundation of Simple Linear Regression by introducing multiple predictors and exploring how they contribute to variance in outcomes.\n\nPrepares for future topics: Sets the stage for advanced methods like Effect Sizes and Confidence Intervals, Mediation Analysis, and Hierarchical Regression, where multiple predictors and their relationships play an even greater role.\n\n\nThis week’s topic bridges the gap between basic ## Class Files\n\n\nLecture Notes\n\nIntroduction to MLR\n\n\n\nR Code\n\nCorrelation and Regression\n\n\n\nData Sets\n\nPregnancy Risk Assessment Monitoring System Data file: Use this file to run correlate.R\nAnnotated JASP file for PRAMS data\nAnnotated JASP file (in lecture notes)\nGRE-GPA Example Data (in lecture notes)\nAdmissions Data (in lecture notes)",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#resources",
    "href": "03-multiple-regression.html#resources",
    "title": "Multiple Linear Regression",
    "section": "Resources",
    "text": "Resources\nI have put together a detailed explanation that explains correlation, partial correlation, semipartial correlation using the PRAMS dataset\nAlso check out the video on semi-partial correlations. This is a key idea behind regression",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#todays-reading",
    "href": "03-multiple-regression.html#todays-reading",
    "title": "Multiple Linear Regression",
    "section": "Today’s Reading",
    "text": "Today’s Reading\nA few years ago I wrote a paper examining classes of adversity and comparing the ACEs sum score across classes. Since the analyses we use today examine ACEs using the sum score, I thought it would be a good idea to have you reflect more about the methodology, and in particular how the choice of methodology can not only be not useful, it can be damaging. I will leave you to ask me about this so we can further talk about it from a social justice perspective.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "03-multiple-regression.html#additional-notes",
    "href": "03-multiple-regression.html#additional-notes",
    "title": "Multiple Linear Regression",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nKeep calm and be significant.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html",
    "href": "04-effect-sizes.html",
    "title": "Effect Sizes",
    "section": "",
    "text": "Week 5: February 10, 2026",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#introduction-to-the-topic",
    "href": "04-effect-sizes.html#introduction-to-the-topic",
    "title": "Effect Sizes",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we delve into the critical concepts of effect sizes and confidence intervals, two foundational elements in interpreting statistical results. These tools play a central role in assessing the strength of relationships and the precision of estimates, bridging the gap between raw statistical outputs and meaningful real-world insights.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#key-concepts",
    "href": "04-effect-sizes.html#key-concepts",
    "title": "Effect Sizes",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nEffect Sizes: Quantify the magnitude of a relationship or difference, providing context beyond mere statistical significance.\nConfidence Intervals (CIs): Represent the range within which a population parameter is likely to fall, offering a measure of result precision.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#relevance",
    "href": "04-effect-sizes.html#relevance",
    "title": "Effect Sizes",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to interpret and calculate effect sizes, understanding their role in evaluating practical significance.\nStudents will explore confidence intervals as tools for assessing the reliability and variability of parameter estimates.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#why-this-is-important",
    "href": "04-effect-sizes.html#why-this-is-important",
    "title": "Effect Sizes",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nEffect sizes complement p-values by answering how much rather than just if there is an effect.\nConfidence intervals provide critical information about the certainty of results, promoting better decision-making and interpretation.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#how-this-ties-into-the-overall-course",
    "href": "04-effect-sizes.html#how-this-ties-into-the-overall-course",
    "title": "Effect Sizes",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon last week’s exploration of hypothesis testing and statistical significance.\nPrepares students for future modules on meta-analysis and advanced modeling techniques, where effect sizes and confidence intervals are integral.\n\nBy the end of this week, students will have the skills to interpret effect sizes and confidence intervals confidently, ensuring they can evaluate research findings critically and apply these concepts to their own analyses.\n\nLecture Notes\n\nEffect Sizes, Confidence Intervals, Assumptions\n\n\n\nR Code\n\nSimple and Multiple Linear Regression\nCalculating Cohen’s D: The full explanation of the code is here. This file calculates Cohen’s D effect size with the added bones of also demonstrating how to download the Area Deprivation Index (ADI) which is frequently used in Social Work and Public Health. Even bettern there is a county-level map of the ADI! See Barboza-Salerno (2023).\n\n\n\nData Sets\n\nAdmissions Data (in lecture notes)\nGRE and graduate student GPA Data (in lecture notes)",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#resources",
    "href": "04-effect-sizes.html#resources",
    "title": "Effect Sizes",
    "section": "Resources",
    "text": "Resources\nI have put together a detailed explanation about simple and multiple linear regression in R.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#todays-reading",
    "href": "04-effect-sizes.html#todays-reading",
    "title": "Effect Sizes",
    "section": "Today’s Reading",
    "text": "Today’s Reading\nToday’s in class assignment is going to ask you to run a multiple linear regression using the National Survey of Child and Adolescent Well-Being (NSCAW I) survey. I used this data in a couple of manuscripts “Trajectories of post-traumatic stress and externalizing psychopathology among maltreated foster care youth: A parallel process latent growth curve model” Barboza et al. (2017) and “Longitudinal growth of post-traumatic stress and depressive symptoms following a child maltreatment allegation: An examination of violence exposure, family risk and placement type” See Barboza & Dominguez (2017).",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "04-effect-sizes.html#additional-notes",
    "href": "04-effect-sizes.html#additional-notes",
    "title": "Effect Sizes",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nKeep calm and DO NOT be normal.\n\n\n\n\n\nBarboza, G. E., & Dominguez, S. (2017). Longitudinal growth of post-traumatic stress and depressive symptoms following a child maltreatment allegation: An examination of violence exposure, family risk and placement type. Children and Youth Services Review, 81, 368–378.\n\n\nBarboza, G. E., Dominguez, S., & Pinder, J. (2017). Trajectories of post-traumatic stress and externalizing psychopathology among maltreated foster care youth: A parallel process latent growth curve model. Child Abuse & Neglect, 72, 370–382.\n\n\nBarboza-Salerno, G. E. (2023). The neighborhood deprivation gradient and child physical abuse and neglect: A bayesian spatial model. Child Abuse & Neglect, 146, 106501.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Effect Sizes</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html",
    "href": "05-assumptions.html",
    "title": "Regression Assumptions",
    "section": "",
    "text": "Week 6: February 17, 2026",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#introduction-to-the-topic",
    "href": "05-assumptions.html#introduction-to-the-topic",
    "title": "Regression Assumptions",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nToday we are finishing up last week’s discussion of effect sizes and regression assumptions. Then we will turn to an even more exciting topic: dummy variables. Regression assumptions are foundational principles that must be met for linear regression models to provide valid and reliable results. Understanding and testing these assumptions is essential for sound statistical inference.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#key-concepts",
    "href": "05-assumptions.html#key-concepts",
    "title": "Regression Assumptions",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nLinearity: The relationship between predictors and the outcome variable should be linear.\nIndependence: Observations should be independent of each other.\nHomoscedasticity: The variance of errors should be consistent across levels of predictors.\nNormality of Residuals: Residuals (errors) should follow a normal distribution.\nMulticollinearity: Predictors should not be highly correlated with each other.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#relevance",
    "href": "05-assumptions.html#relevance",
    "title": "Regression Assumptions",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to evaluate each regression assumption using diagnostic tests and visualizations.\nStudents will gain skills to address violations of assumptions, such as transforming variables or using robust regression methods.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#why-this-is-important",
    "href": "05-assumptions.html#why-this-is-important",
    "title": "Regression Assumptions",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nViolations of regression assumptions can lead to biased estimates, incorrect conclusions, and reduced model reliability.\nBy understanding these assumptions, students can ensure the validity of their regression analyses and effectively communicate findings.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#how-this-ties-into-the-overall-course",
    "href": "05-assumptions.html#how-this-ties-into-the-overall-course",
    "title": "Regression Assumptions",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon prior topics like linear regression by adding a deeper layer of model evaluation and diagnostics.\nPrepares students for advanced topics like generalized linear models and robust regression techniques, which relax some assumptions.\n\nBy the end of this week, students will be able to test and address regression assumptions, ensuring their models meet the necessary criteria for accurate and reliable results.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#dummy-variables",
    "href": "05-assumptions.html#dummy-variables",
    "title": "Regression Assumptions",
    "section": "Dummy Variables",
    "text": "Dummy Variables\nIn regression analysis, many predictors are categorical rather than numerical. However, standard regression models require numerical inputs. Dummy variables are a way to include categorical variables in a regression model by converting them into numerical representations.\n\nWhat are Dummy Variables?\nA dummy variable is a binary variable (0 or 1) that represents different categories of a categorical predictor. It allows regression models to account for group differences. We will learn how to recode variables in SPSS, and R, and include them in our models. This requires understanding how to select the reference category. Read this article for a social justice application of selecting reference variables in regression models. I used this idea to code trans man as the reference category in this paper .\n\nWhy Use Dummy Variables?\n\nThey quantify categorical differences in a regression model.\nThey allow us to compare groups while controlling for other factors.\nThey help capture interaction effects when combined with numerical predictors.\n\n\n\nExtending Dummy Variables:\n\nFor variables with more than two categories, we create multiple dummy variables (e.g., for “Region: North, South, West,” we need two dummy variables to represent three categories).\nReference category: One category is omitted to prevent multicollinearity, and all other categories are compared against it.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#class-files",
    "href": "05-assumptions.html#class-files",
    "title": "Regression Assumptions",
    "section": "Class Files",
    "text": "Class Files\n\nLecture Notes\n\nToday’s Lecture Notes\n\n\n\nR Code\n\nScript 1: CLT Application of Central Limit Theorem to A$AP Rocky’s case: Should he get a new trial?\nScript 2: CLT More CLT Fun\nDirected Acyclic Graph - DAGS And even more fun, check out how you can create diagrams, including DAGS, in R.\n\n\n\nData Sets\n\nNational Survey of Child and Adolescent Well-Being: We are going to examine the following research question using a subset of the dataset: Do children who are removed from the home have higher levels of post-traumatic stress controlling for demographic and exposure variables?\nInfluence, Outliers, and Leverage Part I, Part II, Part III, Part IV",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#r-lab-files",
    "href": "05-assumptions.html#r-lab-files",
    "title": "Regression Assumptions",
    "section": "R Lab Files",
    "text": "R Lab Files\n\nLab Instructions We are going to run some simple and multiple regressions using R with the NSCAW data.\nHere is a partially annotated data file to get us started.\nLab Dataset\nAnother practice assignment that we never got it. Check it out and see if you can answer the questions.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "05-assumptions.html#additional-notes",
    "href": "05-assumptions.html#additional-notes",
    "title": "Regression Assumptions",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nKeep calm and be influential.",
    "crumbs": [
      "**Regression Mechanics**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html",
    "href": "07-logistic-regression.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Week 7: February 24, 2026",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#reading",
    "href": "07-logistic-regression.html#reading",
    "title": "Logistic Regression",
    "section": "Reading",
    "text": "Reading\n\nDiez et al. Chapter 9: Logistic Regression, from pp 371; sec. 9.5\nSee resources",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#introduction-to-the-topic",
    "href": "07-logistic-regression.html#introduction-to-the-topic",
    "title": "Logistic Regression",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we focus on logistic regression, a statistical method used to model binary outcomes and predict probabilities. Logistic regression is a cornerstone technique in statistical modeling, particularly for research questions involving categorical dependent variables.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#key-concepts",
    "href": "07-logistic-regression.html#key-concepts",
    "title": "Logistic Regression",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nLogistic Regression Models: Analyze the relationship between independent variables and a binary dependent variable (e.g., success vs. failure).\nOdds Ratios: Interpret the effect of predictors on the likelihood of the outcome.\nModel Fit and Diagnostics: Evaluate the accuracy and robustness of logistic regression models.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#relevance",
    "href": "07-logistic-regression.html#relevance",
    "title": "Logistic Regression",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to build logistic regression models and interpret their results, including coefficients, odds ratios, and predicted probabilities.\nStudents will explore model evaluation techniques, such as goodness-of-fit measures and ROC curves.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#why-this-is-important",
    "href": "07-logistic-regression.html#why-this-is-important",
    "title": "Logistic Regression",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nLogistic regression is widely used in various fields, including social sciences, medicine, and marketing, to answer questions about classification and prediction.\nUnderstanding logistic regression provides the foundation for advanced modeling techniques like multinomial and ordinal regression.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#how-this-ties-into-the-overall-course",
    "href": "07-logistic-regression.html#how-this-ties-into-the-overall-course",
    "title": "Logistic Regression",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon previous weeks’ focus on linear regression and effect sizes, extending these concepts to binary outcomes.\nPrepares students for upcoming topics like machine learning classification models and survival analysis, where logistic regression plays a foundational role.\n\nBy the end of this week, students will be able to confidently apply logistic regression to real-world problems, interpret model outputs, and evaluate model performance for binary classification tasks.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#class-files",
    "href": "07-logistic-regression.html#class-files",
    "title": "Logistic Regression",
    "section": "Class Files",
    "text": "Class Files\n\nLecture Notes\n\nToday’s Lecture Notes and a review of risk and odds calculations using contingency tables\n\n\n\nR Code\n\nScript 1: Logistic Regression Application of Logistic Regression using R\n\n\n\nData Sets\n\nGPA-College Enrollment Example: In class example showing the mechanics of logistic regression?\nPredicting Probabilities with Logistic Regression Here is an excel file illustrating the math behind predicting probabilities\nAn annotated jasp file of logistic regression output including how to do the log-likelihood test\n\n\n\nResources\n\nThere are a million ways to recode variables in R\nNow that you are familiar with using R, check out this amazing book called R for Data Science which is written by the Hadley who co-authored the tidyverse suite.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "07-logistic-regression.html#additional-notes",
    "href": "07-logistic-regression.html#additional-notes",
    "title": "Logistic Regression",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nKeep calm and don’t be a dummy.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "06-mediation.html",
    "href": "06-mediation.html",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "",
    "text": "Week 8: March 3, 2026",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#reading",
    "href": "06-mediation.html#reading",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Reading",
    "text": "Reading\n\nHayes, Andrew. (2018). Introduction to Mediation, Moderation, and Conditional Process Analysis Chapters 1 - 4.\nHere is an applied paper in Social Work that you should be able to understand after going through this week’s materials.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#introduction-to-the-topic",
    "href": "06-mediation.html#introduction-to-the-topic",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we explore mediation analysis, a statistical approach used to understand the mechanisms through which an independent variable influences a dependent variable via a third variable, known as the mediator. Mediation analysis is essential for uncovering causal pathways in research.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#key-concepts",
    "href": "06-mediation.html#key-concepts",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nDirect Effects: The relationship between the independent variable and the dependent variable, excluding the mediator.\nIndirect Effects: The portion of the relationship explained through the mediator.\nTotal Effects: The combined impact of direct and indirect effects.\nBootstrapping: A resampling method for testing the significance of indirect effects.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#relevance",
    "href": "06-mediation.html#relevance",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to identify and test mediating variables in a causal framework. Make sure you review our discussion of confounding\nStudents will explore how to decompose total effects into direct and indirect components to better understand relationships among variables.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#why-this-is-important",
    "href": "06-mediation.html#why-this-is-important",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nMediation analysis allows researchers to move beyond simple relationships to uncover how and why effects occur.\nUnderstanding mediation is critical for testing theoretical models in fields like psychology, sociology, and public health.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#how-this-ties-into-the-overall-course",
    "href": "06-mediation.html#how-this-ties-into-the-overall-course",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon previous topics, such as regression and effect sizes, by extending these tools to explore causal pathways.\nPrepares students for advanced concepts like moderated mediation and structural equation modeling (SEM), where mediation analysis is a core component.\n\nBy the end of this week, students will be able to conduct mediation analyses, interpret direct and indirect effects, and evaluate the significance of mediators using bootstrapping methods.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#an-example-of-logistic-regression-from-last-week",
    "href": "06-mediation.html#an-example-of-logistic-regression-from-last-week",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "An example of logistic regression from last week",
    "text": "An example of logistic regression from last week\nWe ran out of time last week but I put together an example and write up of logistic regression. This uses the PRAMS dataset to inquire about whether stress during pregnancy predicts IPV exposure during pregnancy. Recall the variable measurements which we noted here. The JASP file is here and it is fully annotated.\n\nIn-Class Files and Data Sets",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#a-note-on-linear-transformations",
    "href": "06-mediation.html#a-note-on-linear-transformations",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "A Note on Linear Transformations",
    "text": "A Note on Linear Transformations\nLinear Transformations: We start class today with a quick example of how to transform variables when the model assumptions are violated. As I mentioned in class, this trick has almost never worked with the datasets I use. However, I was successful in transforming the dependent variable once, using a cultivated dataset on area deprivation, housing, and “child maltreatment” substantiations which can be accessed here. I have used these data often see Elise Barboza-Salerno (2024) for an example.\nThe cultivated dataset comes from many sources. The H+T index comes from this website. The ADI comes from the sociome package in R, and we saw an example when we learned how to quantify effect sizes with Cohen’s D. I calculated the distances to SNAP retail locations from home addresses based on information from the SNAP retail locator, which can be accessed here.\nTest yourself on partial mediation, full mediation, and supression: I created sample output for each effect, can you select the correct model that illustrates each mechanism?\nMediation: We will use a subset of the NSCAW I to examine whether symptoms of post-traumatic stress mediate the association between exposure to violence at Wave I and child externalizing behaviors at Wave III. Now DON’T LOOK at the model write-up until AFTER you have the analysis done. Then, and only then, can you take a gander at my write-up here",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#lab-files",
    "href": "06-mediation.html#lab-files",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Lab Files",
    "text": "Lab Files\nAfter we do the above example together, we have an in-class assessment to get a sense of how well you are comprehending the analyses. This includes some multiple choice questions along with an analysis of the Adolescent Health Survey Data which is a longitudinal dataset that has been collected since about 1995 when youth were 15 years of age. Please download the assessment here. See Elise Barboza & Siller (2021) for a similar analysis published in the Journal of Interpersonal Violence, or this paper Barboza (2020) that also used these data.\n\nLecture Notes\n\nDownload today’s slides here\n\n\n\nR Code\nI wrote the code to show you how to use PROCESS in R. Yes, R has a package that runs the same macro that SPSS can run. The example is based on the NSCAW dataset as well. Check it out here",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#resources",
    "href": "06-mediation.html#resources",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Resources",
    "text": "Resources\nThis is an amazing resources from UCLA on introduction to mediation, moderation and conditional process models. The website has a tutorial that I am strongly suggesting you do, and also additional powerpoint slides for Andrew Hayes’ book.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "06-mediation.html#additional-notes",
    "href": "06-mediation.html#additional-notes",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 1)",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay calm and do everything in moderation.\n\n\n\n\nBarboza, G. E. (2020). Child Maltreatment, Delinquent Behavior, and School Factors as Predictors of Depressive Symptoms from Adolescence to Adulthood: A Growth Mixture Model. Youth & Society, 52(1), 27–54. https://doi.org/10.1177/0044118X17721803Previous methodological approaches have not been flexible enough to model the heterogeneity of depressive symptoms or to identify variations between prototypical trajectories conditional on risk and protective factors. The current study examined latent class trajectories of depressive symptoms using data from 3,819 respondents of the Adolescent Health Survey. Four trajectory profiles of depressive symptoms were identified: low-stable, high-decreasing, low-increasing, and moderate-decreasing. A broad array of risk factors were included into the modeling procedure to identify predictors of group membership. Relative to the low-stable group, membership in one of the three symptomatic groups (i.e., heightened depressive symptoms) was predicted by poverty, low self-esteem, gender, drinking frequency, poor academic outcomes, delinquency, and child maltreatment type. This study contributes to our understanding about the longitudinal manifestations of depression and identifies a broad array of factors significantly related to pathways of resilience.\n\n\nElise Barboza, G., & Siller, L. A. (2021). Child Maltreatment, School Bonds, and Adult Violence: A Serial Mediation Model. Journal of Interpersonal Violence, 36(11-12), NP5839–NP5873. https://doi.org/10.1177/0886260518805763Physically abused youth are vulnerable to experiencing difficulties across multiple domains of school functioning. Most of the literature examining the relationship between child physical abuse (CPA) and adult violence has focused narrowly on academic outcomes rather than taking a broader view that explores the processes undergirding school engagement and connections. The present study adopted Connell?s model of school engagement, connectedness and outcomes within a social bond framework to examine (a) the link between CPA and school social bonds, (b) the link between CPA and adult violence persistence, and (c) the mediational (parallel, serial) effects of school bonds (engagement, connection, and achievement) on violence perpetration in adulthood. Consistent with previous research, results indicated that children who experience physical abuse have poorer academic performance, which, in turn, is related to future violent trajectories. We further found that the relationship between CPA and violence persistence is mediated by a process of bonding to school that begins with being actively engaged in school activities and ends with higher levels of academic achievement. In particular, some of the ?school achievement? effect found in previous research operates through behavioral and emotional manifestations and may be partly explained through physically abused children?s lessened ability to be engaged with and connected to school activities. We conclude with a discussion of the policy implications stemming from our findings.\n\n\nElise Barboza-Salerno, G. (2024). Material Hardship, Labor Market Characteristics and Substantiated Child Maltreatment: A Bayesian Spatiotemporal Analysis. Children and Youth Services Review, 157, 107371. https://doi.org/10.1016/j.childyouth.2023.107371Child maltreatment is a critical public health problem whose structural underpinnings underscore the need to move prevention efforts from individual-level risk factors to social policy. Despite previous studies exploring the evolution of child maltreatment risk in socially vulnerable contexts, little is known about how neighborhood level material deprivation and job market characteristics, beyond the employment context, impact substantiated maltreatment risk. The present analysis integrates multiple streams of data to explore the complexity of child maltreatment in the most populous county in New Mexico as a case-study. A geospatial model was used to produce posterior risk estimates and exceedance probabilities of substantiated child maltreatment derived from administrative records controlling for financial strength, economic inequality and hardship, educational attainment, housing and food insecurity and labor market characteristics. Findings showed that over the nine-year study period, the average relative risk of child maltreatment increased substantially, however, there was substantial regional and temporal heterogeneity. More specifically, substantiated child maltreatment risk became more highly concentrated into the most deprived 20% of neighborhoods over time. The results showed a very strong area deprivation effect such that: (1) the risk of maltreatment in the most deprived 20% of neighborhoods on financial strength was 130.78% higher compared to the least deprived 20% of neighborhoods; and (2) maltreatment rates in the bottom 20% of neighborhoods on economic inequality and hardship were 40.52% higher compared to the least deprived 20% of neighborhoods. Finally, substantiated child maltreatment was significantly associated with multiple labor market characteristics including commuting times to work, origin–destination job flows, and mode of transportation to work. From a policy perspective, the results of this study support structural interventions aimed at reducing neighborhood-level material hardship and labor market disadvantage as avenues to support parents so that children and families can thrive.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 1)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html",
    "href": "07-moderation.html",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "",
    "text": "Week 11: March 24, 2026",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#reading",
    "href": "07-moderation.html#reading",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Reading",
    "text": "Reading\n\nHayes, Andrew. (2018). Introduction to Mediation, Moderation, and Conditional Process Analysis Chapters 7 - 10.\nI have used these methods on several occasions, check out Barboza-Salerno & Meshelemiah (2024) and Elise Barboza & Siller (2021).\n\nBarboza-Salerno, G. E., & Meshelemiah, J. C. (2024). Associations between early child adversity and lifetime suicide attempts among gender diverse individuals: A moderated mediation. Child Abuse & Neglect, 149, 106705.\nBarboza, G., & Siller, L. A. (2021). Child Maltreatment, School Bonds, and Adult Violence: A Serial Mediation Model. Journal of Interpersonal Violence, 36(11–12), NP5839–NP5873. https://doi.org/10.1177/0886260518805763",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#introduction-to-the-topic",
    "href": "07-moderation.html#introduction-to-the-topic",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we explore moderation analysis, a statistical approach used to understand how the relationship between two variables changes depending on a third variable, known as the moderator. Unlike simple regression, where we assess a direct relationship between an independent and dependent variable, moderation analysis allows us to examine whether this relationship varies in strength or direction based on different levels of another variable.\nModeration is particularly useful in social sciences, public health, and policy research, where the effect of an intervention or exposure may differ depending on contextual factors such as age, gender, socioeconomic status, or environmental conditions. For example, in public health studies, we might investigate whether the relationship between neighborhood poverty and child maltreatment rates is moderated by community resources or green space availability.\nThroughout this week, we will discuss how to interpret interaction effects, visualize moderation using interaction plots, and apply these concepts using statistical software. By the end of the module, you will be able to identify when moderation is appropriate, test for moderation effects, and communicate findings effectively in research and policy contexts",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#key-concepts",
    "href": "07-moderation.html#key-concepts",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nDefinition: Moderation occurs when the strength or direction of the relationship between an independent variable X and a dependent variable Y depends on a third variable W, called the moderator.\nInteraction/Effect moderation: The key indicator of moderation is a statistically significant interaction term, X * W, in a regression model, suggesting that the effect of X on Y varies depending on W.\nVisualization: Simple slopes analysis and interaction plots help visualize and interpret moderation effects.\nProbing Interactions: This is an extremely useful technique in which you can detect statistically significant regions of the interaction. Super exciting!\nDistinguishing Moderation from Mediation:\n\nModeration affects the strength of the relationship between X and Y.\nMediation explains the mechanism through which X affects Y via an intermediate variable.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#relevance",
    "href": "07-moderation.html#relevance",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to use PROCESS in R and SPSS to test effect moderation to examine when or for whom an effect occurs (e.g., does the effect of stress on mental health differ based on social support?)\nStudents will begin to understand what conditional (i.e., moderation) indirect effects (i.e., mediation) are and how to use them to test innovative hypotheses in social work (i.e., moderated mediation).",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#why-this-is-important",
    "href": "07-moderation.html#why-this-is-important",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nMediation analysis, as we saw last week, allows researchers to move beyond simple relationships to uncover how and why effects occur.\nUnderstanding mediation is critical for testing theoretical models in fields like social work, psychology, sociology, and public health.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#how-this-ties-into-the-overall-course",
    "href": "07-moderation.html#how-this-ties-into-the-overall-course",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon previous topics, such as regression and effect sizes, by extending these tools to explore conditional effects.\nPrepares students for advanced concepts like moderated mediation and structural equation modeling (SEM), where interaction terms can be useful.\n\nBy the end of this week, students will be able to conduct moderation analyses, interpret conditional effects, and evaluate the significance of effect moderation using SPSS and R.\n\nIn-Class Files and Data Sets\nData sets: We will use datasets from Hayes on workplace related stress: estress.sav and presumed media influence on the intention to purchase: pmi.sav.\nMediation Extensions: First, are going to extend the simple mediation model we learned last time by incorporating multiple mediators. I have saved the SPSS output for several different examples:\n\nExample 1: Dichotomous Predictor, Simple Mediation, The PMI study\nExample 2: Continuous Predictor, Economic Stress Among Small Business Owners\nExample 3 Continuous Predictor with controls, Economic Stress Among Small Business Owners (same data set as above)\n\nNext, we extend the simple case using examples representing parallel, serial mediation and serial mediation with contrasts.\nModeration: Finally, we end today with an example of how to implement moderation. We will use these files:\n\nExample 1: Dichotomous Moderation Effect, Sexual Minority. I saved the SPSS output\nExample 2: Continuous Moderation Effect, NSCAW",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#lab-files",
    "href": "07-moderation.html#lab-files",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Lab Files",
    "text": "Lab Files\nMediation: You are going to do this lab using the NSCAW data to examine whether (1) children investigated for abuse or neglect who have witnessed severe violence at Wave 1 (EV_W1) are more likely to engage in externalizing behavior at Wave 3 (bcext3); and (2) post-traumatic stress at Wave 1 (tra1) is the mechanism violence exposure is linked to externalizing behavior.\nModeration: I have created some Excel output so you can learn how to take the output and visualize the results. One file plots the effect moderation for age on the association between post-traumatic stress and delinquent behaviors using a subset of the NSCAW. Now, you can use this file to practice making a similar chart using excel to answer the question: What is the effect moderation of sexual minority status on the association between post-traumatic stress and delinquent behavior?\n\nLecture Notes & Class Files\n\nDownload today’s slides here\nCheck out my annotated Word document interpreting parallel mediation (with sample write-up) here",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#resources",
    "href": "07-moderation.html#resources",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Resources",
    "text": "Resources\nThere are a number of mediation, moderation, and mediated moderation models that you can use to test various hypotheses. Once you have a basic familairity of the models they become intuitive. Model templates are located here.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07-moderation.html#additional-notes",
    "href": "07-moderation.html#additional-notes",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 2)",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay calm and remove interactions with toxic people.\n\n\n\n\nBarboza-Salerno, G. E., & Meshelemiah, J. C. (2024). Associations between early child adversity and lifetime suicide attempts among gender diverse individuals: A moderated mediation. Child Abuse & Neglect, 149, 106705.\n\n\nElise Barboza, G., & Siller, L. A. (2021). Child Maltreatment, School Bonds, and Adult Violence: A Serial Mediation Model. Journal of Interpersonal Violence, 36(11-12), NP5839–NP5873. https://doi.org/10.1177/0886260518805763Physically abused youth are vulnerable to experiencing difficulties across multiple domains of school functioning. Most of the literature examining the relationship between child physical abuse (CPA) and adult violence has focused narrowly on academic outcomes rather than taking a broader view that explores the processes undergirding school engagement and connections. The present study adopted Connell’s model of school engagement, connectedness and outcomes within a social bond framework to examine (a) the link between CPA and school social bonds, (b) the link between CPA and adult violence persistence, and (c) the mediational (parallel, serial) effects of school bonds (engagement, connection, and achievement) on violence perpetration in adulthood. Consistent with previous research, results indicated that children who experience physical abuse have poorer academic performance, which, in turn, is related to future violent trajectories. We further found that the relationship between CPA and violence persistence is mediated by a process of bonding to school that begins with being actively engaged in school activities and ends with higher levels of academic achievement. In particular, some of the “school achievement” effect found in previous research operates through behavioral and emotional manifestations and may be partly explained through physically abused children’s lessened ability to be engaged with and connected to school activities. We conclude with a discussion of the policy implications stemming from our findings.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 2)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html",
    "href": "07a-moderation.html",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "",
    "text": "Week 10: March 23, 2026",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#reading",
    "href": "07a-moderation.html#reading",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Reading",
    "text": "Reading\n\nHayes, Andrew. (2018). Introduction to Mediation, Moderation, and Conditional Process Analysis Chapters 7 - 10.\nI have used these methods on several occasions, check out Barboza-Salerno & Remillard (2023).\n\nBarboza-Salerno, G. E., & Remillard, A. (2023). Early child adversity and delinquent behavior in foster care youth: do future expectations and sexual identity moderate the mediating role of posttraumatic stress?. Journal of Child & Adolescent Trauma, 16(4), 945-957.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#introduction-to-the-topic",
    "href": "07a-moderation.html#introduction-to-the-topic",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week we continue to learn about advanced mediation models and effect moderation. To review, please see last week’s page\n\nIn-Class Files and Data Sets\nData sets:\n– Our first example uses the presumed media influence study: pmi.sav to estimate a serial mediation of article importance and PMI jointly. – Next, we are going to use PRAMS data to examine potential pathways by which intimate partner violence prior to pregnancy impacts poor birth outcomes, i.e., low birth weight in infants. Please note that this is not only a public health issue, low birth weight disproportionately effects persons on the basis of race, and so it qualifies as a civil rights issue.\nModeration: Finally, we will learn about moderation effects, which we did not get to last week. We will use these files:\n\nExample 1: Dichotomous Moderation Effect, Sexual Minority. I saved the SPSS output\nExample 2: Continuous Moderation Effect, NSCAW",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#lab-files",
    "href": "07a-moderation.html#lab-files",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Lab Files",
    "text": "Lab Files\nMediation: You are going to do this lab using the NSCAW data to examine whether (1) children investigated for abuse or neglect who have witnessed severe violence at Wave 1 (EV_W1) are more likely to engage in externalizing behavior at Wave 3 (bcext3); and (2) post-traumatic stress at Wave 1 (tra1) is the mechanism violence exposure is linked to externalizing behavior.\nModeration: I have created some Excel output so you can learn how to take the output and visualize the results. One file plots the effect moderation for age on the association between post-traumatic stress and delinquent behaviors using a subset of the NSCAW. Now, you can use this file to practice making a similar chart using excel to answer the question: What is the effect moderation of sexual minority status on the association between post-traumatic stress and delinquent behavior?\nModeration in R: I have written the code to show you how to implement moderation in R.\n\nLecture Notes & Class Files\n\nDownload today’s slides here\nI want us to assess our knowledge of mediation today",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#resources",
    "href": "07a-moderation.html#resources",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Resources",
    "text": "Resources\nThere are a number of mediation, moderation, and mediated moderation models that you can use to test various hypotheses. Once you have a basic familairity of the models they become intuitive. Model templates are located here.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "07a-moderation.html#additional-notes",
    "href": "07a-moderation.html#additional-notes",
    "title": "Mediation, Moderation, and Conditional Process Models (Part 3)",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay calm and BE BRAVE.\n\n\n\n\nBarboza-Salerno, G. E., & Remillard, A. (2023). Early child adversity and delinquent behavior in foster care youth: Do future expectations and sexual identity moderate the mediating role of posttraumatic stress? Journal of Child & Adolescent Trauma, 16(4), 945–957.",
    "crumbs": [
      "**Advanced Regression Techniques**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mediation, Moderation, and Conditional Process Models (Part 3)</span>"
    ]
  },
  {
    "objectID": "11-efa.html",
    "href": "11-efa.html",
    "title": "EFA",
    "section": "",
    "text": "Week 12: March 31, 2026",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#reading",
    "href": "11-efa.html#reading",
    "title": "EFA",
    "section": "Reading",
    "text": "Reading\n\nPituch et al. Chapter 9: Exploratory Factor Analysis, from pp 339\nHahs-Vaughn. Chapter 9: Applied Multivariate Statistical Concepts, from pp 362\nYong and Pearce - 2013 - A beginner’s guide to factor analysis",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#introduction-to-the-topic",
    "href": "11-efa.html#introduction-to-the-topic",
    "title": "EFA",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we focus on Exploratory Factor Analysis (EFA), a statistical method used to uncover the underlying structure of a set of observed variables. EFA is a critical tool for identifying latent constructs in datasets.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#key-concepts",
    "href": "11-efa.html#key-concepts",
    "title": "EFA",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nLatent Variables: Unobserved factors inferred from observed variables.\nFactor Loadings: The relationship between observed variables and underlying factors.\nEigenvalues and Scree Plots: Tools for determining the number of factors to retain.\nRotation Methods: Techniques (e.g., Varimax, Promax) to simplify factor structure.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#relevance",
    "href": "11-efa.html#relevance",
    "title": "EFA",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to conduct EFA to explore latent structures in data.\nStudents will gain skills to evaluate factor solutions and interpret factor loadings.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#why-this-is-important",
    "href": "11-efa.html#why-this-is-important",
    "title": "EFA",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nEFA helps researchers identify patterns and groupings in data without predefined hypotheses.\nIt is widely used in psychology, education, and social sciences to develop and validate measurement tools.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#how-this-ties-into-the-overall-course",
    "href": "11-efa.html#how-this-ties-into-the-overall-course",
    "title": "EFA",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon prior topics like correlations and covariance by introducing latent structures.\nPrepares students for Confirmatory Factor Analysis (CFA), where hypothesized factor structures are tested.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#lab-files",
    "href": "11-efa.html#lab-files",
    "title": "EFA",
    "section": "Lab Files",
    "text": "Lab Files\n\nSAQ-8: First, we illustrate factor analysis with a simple example from UCLA which you can read more about here. It uses the SAQ-8 to examine the latent structure of LOVING statistics.\nPIAAC: Then, we will use read data from the Program for the International Assessment of Adult Competencies (PIAAC) located here. From the website, the PIAAC survey seeks to answer the following policy questions:\n\nHow are skills distributed? A comparison of skill levels, skill requirements, investments in education and training across countries, investment mismatches across countries, as well as of investments and mismatches within countries, across demographic categories, regions, sectors of industry, levels and fields of schooling.\n\nWhy are skills important? The relation of skills to relevant labor market outcomes such as employment opportunities, earnings, job security, and skill utilization, as well as to other outcomes such as health, civic engagement, and social trust.\nWhat factors are related to skill acquisition and decline? The relation between various learning activities – education, training, informal learning activities – and skill acquisition. The relation of experiences at work, in education and everyday life to skill decline among older individuals.\n\nWe are using a subsetted spss file from the USA that you can download here and I also created a JASP file of the same data that is fully annotated here. The final, reduced model output with the variables that did not load highly on the factors is here in case you are interested.\n\nGenerations: A Study of the Life and Health of LGB People in a Changing Society: We will conduct a full FA using a dataset called Generations:A Study of the Life and Health of LGB People in a Changing Society We will use these data wo explore the factor structure of an ethnic identity scale and differences in the structure across race. The analysis is based on a paper by Johnson et al. (2022) that you can download here called The Group-Based Law Enforcement Mistrust Scale: Psychometric Properties of an Adapted Scale and Implications for Public Health and Harm Reduction Research\n\nTHE IN-CLASS EXAMPLE is located here and then you can study how this same analysis can be performed using R here\n\nLecture Notes\n\nDownload today’s slides here",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#resources",
    "href": "11-efa.html#resources",
    "title": "EFA",
    "section": "Resources",
    "text": "Resources",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "11-efa.html#additional-notes",
    "href": "11-efa.html#additional-notes",
    "title": "EFA",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay calm and and let your life unfold one factor at a time.\n\n\n\n\nJohnson, L. M., Devereux, P. G., & Wagner, K. D. (2022). The group-based law enforcement mistrust scale: Psychometric properties of an adapted scale and implications for public health and harm reduction research. Harm Reduction Journal, 19(1), 60.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>EFA</span>"
    ]
  },
  {
    "objectID": "efa_R.html",
    "href": "efa_R.html",
    "title": "EFA in R",
    "section": "",
    "text": "Prelims\nBefore interpreting the results of an exploratory factor analysis (EFA), it is essential to consider whether the assumptions underlying the method are reasonably met. One key assumption is that the observed variables are continuous and approximately normally distributed. While EFA is somewhat robust to violations of normality, particularly when using large sample sizes or estimation methods like principal axis factoring, violations can still impact the accuracy of factor loadings and model fit statistics. In this study, the six racial/ethnic identity items (RE1–RE6) were measured on a 5-point Likert scale, which, although technically ordinal, can often be treated as continuous in practice—especially when items have five or more categories and exhibit approximately symmetric distributions.\nAnother important assumption is multivariate normality, especially when using estimation methods such as maximum likelihood (ML), which relies on normality to produce unbiased estimates and valid fit indices. Although ML estimation was used in this analysis, the relatively large sample size may mitigate concerns about non-normality. If substantial departures from normality were present, alternative estimation methods—such as principal axis factoring or robust maximum likelihood—could offer more reliable results.\nIn addition to distributional assumptions, EFA assumes that the variables included are conceptually coherent and intercorrelated, such that they are likely to reflect common latent constructs. This assumption is supported in the present analysis, as the six items were explicitly designed to capture theoretically distinct but related dimensions of racial/ethnic identity. Prior research supports a multidimensional structure of racial and ethnic identity, particularly models that distinguish between exploration (active engagement in learning about one’s racial or ethnic group) and commitment or affirmation (a sense of belonging or attachment). These dual processes are foundational in Phinney’s (1992) Multigroup Ethnic Identity Measure (MEIM) and further validated by studies that replicate two-factor or higher-order factor structures across diverse racial/ethnic groups (Roberts et al., 1999; Yip, 2005). Theoretical and empirical support for these dimensions provides a strong rationale for modeling racial/ethnic identity as multifactorial and reinforces the construct validity of the current EFA findings.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>EFA in R</span>"
    ]
  },
  {
    "objectID": "efa_R.html#introduction",
    "href": "efa_R.html#introduction",
    "title": "EFA in R",
    "section": "Introduction",
    "text": "Introduction\nAcross multiple studies, ethnic identity (EI) has consistently been conceptualized as a multidimensional construct encompassing both affective and behavioral components. While specific factor labels varied, each study identified two primary dimensions: one reflecting a sense of affirmation, belonging, or identification with one’s ethnic group, and the other capturing exploration, participation, or engagement in ethnic behaviors. Roberts et al., Spencer et al., and Yancey et al. all found support for this two-factor structure among adolescents, reinforcing the view that EI involves both internalized group attachment and active efforts to understand and engage with one’s cultural background.\nThis analysis explores the underlying structure of six race/ethnic identity items from the Multigroup Ethnic Identity Measure using the Life and Health of LGBT People Study. These items are measured on a 5-point Likert scale ranging from 1 (“Strongly disagree”) to 5 (“Strongly agree”) and include:\n\nExploration\nThese items reflect behavioral and cognitive efforts to learn more about one’s racial/ethnic background:\n\nRE1: I have spent time trying to find out more about my race/ethnic group, such as its history, traditions, and customs.\nRE4: I have often done things that will help me understand my race/ethnic background better.\nRE5: I have often talked to other people in order to learn more about my race/ethnic group.\n\n\n\nCommitment/Belonging\nThese items express a sense of attachment, emotional connection, or identification with the group:\n\nRE2: I have a strong sense of belonging to my own race/ethnic group.\nRE3: I understand pretty well what my race/ethnic group membership means to me.\nRE6: I feel a strong attachment towards my own race/ethnic group.\n\nThese items reflect cognitive, behavioral, and emotional dimensions of racial/ethnic identity exploration and commitment.\nBased on their content and alignment with established ethnic identity frameworks such as Phinney’s MEIM, the six items should be categorized into two dimensions: Exploration and Commitment/Belonging. This categorization is consistent with empirical studies that distinguish between active engagement in learning about one’s ethnicity (Exploration) and emotional or attitudinal connection to the group (Commitment/Belonging).\n\n# Load dataset\ndata_path &lt;- \"C:/Users/barboza-salerno.1/Downloads/life and health of lgbt people study.sav\"\ndf &lt;- read_sav(data_path)\n\nre_items &lt;- df %&gt;%\n  select(RE1, RE2, RE3, RE4, RE5, RE6) \n\n\nsummary(re_items)\n\n      RE1             RE2             RE3             RE4       \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:3.000   1st Qu.:2.000  \n Median :4.000   Median :3.000   Median :4.000   Median :3.000  \n Mean   :3.355   Mean   :3.205   Mean   :3.722   Mean   :3.253  \n 3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :15      NA's   :19      NA's   :19      NA's   :22     \n      RE5             RE6       \n Min.   :1.000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :3.000  \n Mean   :3.179   Mean   :3.097  \n 3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.000  \n NA's   :18      NA's   :18     \n\n\n\ncolSums(is.na(re_items))\n\nRE1 RE2 RE3 RE4 RE5 RE6 \n 15  19  19  22  18  18 \n\n\n\n# Select the six RE variables\nre_items &lt;- re_items %&gt;%\n   drop_na()  # Remove rows with missing values\n\n\n\nKMO and Bartlett’s Test\n\n# Check correlation matrix and Bartlett’s test\ncor_matrix &lt;- cor(re_items, use = \"pairwise.complete.obs\")\nKMO(cor_matrix)\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = cor_matrix)\nOverall MSA =  0.82\nMSA for each item = \n RE1  RE2  RE3  RE4  RE5  RE6 \n0.86 0.77 0.88 0.81 0.82 0.81 \n\ncortest.bartlett(cor_matrix, n = nrow(re_items))\n\n$chisq\n[1] 4215.477\n\n$p.value\n[1] 0\n\n$df\n[1] 15\n\n\n\nNote: All MSA’s here were acceptable. If they were not, you would want to eliminate those variables with MSA’s below a certain value, perhaps .50 at minimum. You can do this easily as follows:\n\n\nmydat &lt;- cor_matrix[, KMO(cor_matrix)$MSAi&gt;0.50] \n\n\nNote: Bartlett’s test compares the correlation matrix to the identity matrix and the null hypothesis is:\n\n\\[H_0: I_{mat} = Corr_{mat}\\] #### Determine the number of Factors to Extract This is the most important determination for EFA. The goal is to examine the latent structure for a certain number of variables that are coherent, or highly correlated. Therefore, we want to find factors that explain a substantial proportion of variation within the data. Recall there are numerous ways to make such a determination, and none of them are wrong. However, some are more correct than others, and the gold standard is to use parallel analysis as demonstrated below:\n\nfa.parallel(re_items, fa = \"fa\", n.iter = 100, show.legend = TRUE)\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n\n\nLovely, we don’t have to guess, according to the code, we should select 2 factors.\n\n\nExtract (and rotate) factors\nUnless the correlation between factors is low, we want use oblique rotation. Oblique rotations will provide a correlation matrix that describes the relationships between factors. There are two primary selections: Oblique option 1: promax - Promax rotation is better able to handle large datasets and results in greater correlation values between factors.\nOblique option 2: oblimin The direct oblimin rotation approach is less efficient with large datasets, but produces a simpler factor structure.\n\n# Suppose parallel analysis suggests 2 factors\nefa_result &lt;- fa(re_items, nfactors = 2, rotate = \"oblimin\", fm = \"ml\")  # or \"pa\"\nprint(efa_result, sort = TRUE)\n\nFactor Analysis using method =  ml\nCall: fa(r = re_items, nfactors = 2, rotate = \"oblimin\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n    item   ML1   ML2   h2   u2 com\nRE4    4  0.85  0.03 0.76 0.24 1.0\nRE5    5  0.84  0.00 0.70 0.30 1.0\nRE1    1  0.74 -0.01 0.54 0.46 1.0\nRE2    2 -0.07  0.95 0.82 0.18 1.0\nRE6    6  0.18  0.66 0.62 0.38 1.2\nRE3    3  0.16  0.52 0.40 0.60 1.2\n\n                       ML1  ML2\nSS loadings           2.13 1.70\nProportion Var        0.36 0.28\nCumulative Var        0.36 0.64\nProportion Explained  0.56 0.44\nCumulative Proportion 0.56 1.00\n\n With factor correlations of \n    ML1 ML2\nML1 1.0 0.6\nML2 0.6 1.0\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  2.84 with Chi Square =  4215.48\ndf of  the model are 4  and the objective function was  0.02 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  1487 with the empirical chi square  9.41  with prob &lt;  0.052 \nThe total n.obs was  1487  with Likelihood Chi Square =  27.13  with prob &lt;  1.9e-05 \n\nTucker Lewis Index of factoring reliability =  0.979\nRMSEA index =  0.062  and the 90 % confidence intervals are  0.041 0.086\nBIC =  -2.09\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.94 0.94\nMultiple R square of scores with factors          0.88 0.88\nMinimum correlation of possible factor scores     0.75 0.75\n\n\n\n# Extract the factor loadings (2 factors)\nload &lt;- as.matrix(efa_result$loadings[, 1:2])\n\n# Assign variable names as rownames if they are missing\nrownames(load) &lt;- colnames(re_items)\n\n# Plot the loadings\nplot(load, type = \"n\", xlab = \"Factor 1\", ylab = \"Factor 2\", main = \"Factor Loading Plot\")\ntext(load, labels = rownames(load), cex = 0.8)\n\n\n\n\n\n\n\n\n\nfa.diagram(efa_result, simple = FALSE, digits = 2)\n\n\n\n\n\n\n\n\n\n\nColumn Definitions\n\nML1 and ML2: Standardized factor loadings on Factor 1 and Factor 2, respectively.\nh2 (Communality): Proportion of each item’s variance explained by the two factors combined.\nu2 (Uniqueness): Proportion of each item’s variance not explained by the factors (i.e., residual variance).\n\n\n\nInterpretation of Each Item\n\nFactor 1 (ML1): Ethnic Identity Exploration\n\nRE4 (“…help me understand my race/ethnic background better”) loads very strongly (0.85) on ML1, suggesting this item taps into active exploration.\nRE5 (“…talked to other people…”) loads very strongly (0.84) on ML1—again, an exploratory behavior.\nRE1 (“…find out more about my race/ethnic group…”) loads strongly (0.74) on ML1 and near-zero on ML2, reinforcing its alignment with exploration.\n\n\nThese three items all reflect actions taken to explore racial/ethnic identity, justifying labeling this factor Exploration.\n\nFactor 2 (ML2): Ethnic Identity Commitment/Belonging\n\nRE2 (“…strong sense of belonging…”) loads very strongly (0.95) on ML2 and has virtually no loading on ML1, indicating it is a strong indicator of commitment or attachment.\nRE6 (“…strong attachment…”) loads moderately on ML2 (0.66) and weakly on ML1 (0.18), suggesting it primarily reflects commitment but with some overlap.\nRE3 (“…understand what race/ethnic group membership means…”) loads moderately on ML2 (0.52), weakly on ML1 (0.16), suggesting a somewhat conceptual but still committed aspect.\n\n\nTogether, these items reflect commitment, attachment, and clarity of identity, aligning factor 2 with Commitment/Belonging to racial identity.\n\n\nCommunalities and Uniqueness\n\nHighest communality: RE2 (0.82) — well-explained by the factors.\nLowest communality: RE3 (0.40) — less well-explained, possibly more complex or ambiguous in meaning.\nUniqueness is highest for RE3 (0.60), suggesting additional variance not captured by the two-factor model (possibly due to conceptual ambiguity or measurement noise).",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>EFA in R</span>"
    ]
  },
  {
    "objectID": "efa_R.html#summary-of-factor-structure",
    "href": "efa_R.html#summary-of-factor-structure",
    "title": "EFA in R",
    "section": "Summary of Factor Structure",
    "text": "Summary of Factor Structure\nThe exploratory factor analysis revealed a clear two-factor solution, aligning with theoretical models of racial/ethnic identity development. The first factor, which we interpret as Exploration, includes items RE1, RE4, and RE5. These items reflect active efforts to learn about one’s racial or ethnic background, such as seeking out cultural knowledge, engaging in learning activities, and conversing with others to deepen understanding. The second factor, labeled Commitment/Belonging, comprises items RE2, RE6, and RE3. These items center on emotional attachment, a sense of belonging, and internal clarity regarding one’s racial or ethnic identity.\nThis factor structure supports a multidimensional model of racial/ethnic identity, consistent with developmental frameworks such as Phinney’s model. These models conceptualize identity as composed of both exploratory behaviors and a stable sense of affiliation or commitment, recognizing these as distinct yet interrelated domains. The presence of both factors in the data provides empirical support for treating racial/ethnic identity as more than a unidimensional construct.\n\nAre the factors correlated?\n\n(efa_result$Phi)\n\n          ML1       ML2\nML1 1.0000000 0.5957431\nML2 0.5957431 1.0000000\n\n\nThe use of oblique rotation in the factor analysis was both theoretically and statistically appropriate, as the constructs of exploration and commitment are expected to be correlated. In practice, individuals who engage in active exploration of their racial or ethnic heritage may also develop stronger feelings of attachment and belonging, reflecting the developmental trajectory of identity formation. The factor correlation matrix confirms this relationship: the correlation between the two factors was 0.60, indicating a moderate positive association. This supports the conceptualization of exploration and commitment as distinct yet meaningfully related dimensions of racial/ethnic identity.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>EFA in R</span>"
    ]
  },
  {
    "objectID": "efa_R.html#reliability",
    "href": "efa_R.html#reliability",
    "title": "EFA in R",
    "section": "Reliability",
    "text": "Reliability\nThe next logical question is: How good are these factors? We are interested in whether the variables in each factor form a coherent whole when used together. In other words, are the variances internally consistent between variables in a factor?\nOne of the most commonly used measures of reliability is Cronbach’s alpha (α), which assesses the internal consistency among a set of items—that is, how closely related the items are as a group. While it is not necessary to conduct an exploratory factor analysis (EFA) in order to calculate Cronbach’s alpha, EFA provides a useful context for introducing this concept. After identifying factors through EFA, Cronbach’s alpha can be used to evaluate the reliability of each factor by assessing how consistently the items within that factor measure the same underlying construct. This helps ensure that the grouped items form a coherent and reliable scale.\nTo run alpha on your factors you will first need to specify which variables belong to each factor.\n\nf1 &lt;- re_items %&gt;% select(RE1, RE4, RE5)\nf2 &lt;- re_items %&gt;% select(RE2, RE3, RE6)\n\nSo, we simply created two objects corresponding to each of our factors, \\(f1\\) and \\(f2\\) with the variables that loaded on each.\nCronbach’s alpha ranges between zero and 1.0. To evaluate the level of reliability, you are looking for values &gt; 0.70 at a minimum. Values between 0.70 and 0.80 are adequate to fair, between 0.80 and 0.90 are good and above .90 are considered excellent.\n\npsych::alpha(f1)\n\n\nReliability analysis   \nCall: psych::alpha(x = f1)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean sd median_r\n      0.85      0.85     0.8      0.66 5.8 0.0067  3.3  1     0.64\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.84  0.85  0.86\nDuhachek  0.84  0.85  0.86\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nRE1      0.84      0.84    0.72      0.72 5.2   0.0083    NA  0.72\nRE4      0.76      0.76    0.61      0.61 3.2   0.0124    NA  0.61\nRE5      0.78      0.78    0.64      0.64 3.6   0.0113    NA  0.64\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nRE1 1487  0.86  0.86  0.73   0.68  3.4 1.2\nRE4 1487  0.89  0.90  0.83   0.76  3.2 1.1\nRE5 1487  0.89  0.89  0.81   0.74  3.2 1.2\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nRE1 0.10 0.18 0.18 0.36 0.18    0\nRE4 0.08 0.18 0.30 0.31 0.13    0\nRE5 0.09 0.23 0.22 0.32 0.14    0\n\n\n\npsych::alpha(f2)\n\n\nReliability analysis   \nCall: psych::alpha(x = f2)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.81      0.81    0.75      0.58 4.1 0.0085  3.3 0.94     0.55\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.79  0.81  0.82\nDuhachek  0.79  0.81  0.82\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nRE2      0.65      0.66    0.50      0.50 2.0   0.0174    NA  0.50\nRE3      0.82      0.82    0.69      0.69 4.5   0.0095    NA  0.69\nRE6      0.70      0.71    0.55      0.55 2.4   0.0151    NA  0.55\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean   sd\nRE2 1487  0.89  0.88  0.81   0.73  3.2 1.15\nRE3 1487  0.78  0.80  0.63   0.57  3.7 0.97\nRE6 1487  0.88  0.86  0.77   0.68  3.1 1.20\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nRE2 0.08 0.20 0.30 0.29 0.14    0\nRE3 0.03 0.08 0.23 0.46 0.20    0\nRE6 0.11 0.19 0.32 0.23 0.14    0\n\n\n\nInterpretation\nWe are concerned with the “raw-alpha” value for the entire factor. This is what is reported in manuscripts as “Cronbach’s α.” That tells us how consistent a set of variables are in generaly. In this case, we are exploring item consistency within each factor. Here, the reliability coefficient (i.e., Cronbach’s α) for Factor 1 (f1) is 0.851 and for f2 its 0.805. This means that the variables that load onto each factor have excellent internally consistency.\nThe next thing to consider is how internal consistency might change after removing any single variable. To better understand this, we focus on the column titled “raw_alpha” under “Reliability if an iterm is dropped.” For example, the consistency of variables loading on f2 would be higher if we removed RE3 - the effect would be to increase alpha to 0.817. In this case, there is no need to remove a variable to increase reliability because reliability is good with the variable included.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>EFA in R</span>"
    ]
  },
  {
    "objectID": "13-lca.html",
    "href": "13-lca.html",
    "title": "LCA",
    "section": "",
    "text": "Week 14: April 14, 2026",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#introduction-to-the-topic",
    "href": "13-lca.html#introduction-to-the-topic",
    "title": "LCA",
    "section": "Introduction to the Topic",
    "text": "Introduction to the Topic\nThis week, we dive into Latent Class Analysis (LCA), a method used to identify subgroups or classes within a population based on observed data. LCA is essential for uncovering hidden heterogeneity in data.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#key-concepts",
    "href": "13-lca.html#key-concepts",
    "title": "LCA",
    "section": "Key Concepts:",
    "text": "Key Concepts:\n\nLatent Classes: Unobserved subgroups identified through patterns in the data.\nClass Membership Probabilities: The likelihood that an individual belongs to a specific class.\nModel Fit: Using tools like BIC and AIC to determine the optimal number of classes.\nInterpreting Profiles: Understanding differences between identified classes.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#relevance",
    "href": "13-lca.html#relevance",
    "title": "LCA",
    "section": "Relevance:",
    "text": "Relevance:\n\nStudents will learn how to use LCA to identify meaningful subgroups in their data.\nStudents will explore applications of LCA in areas like health disparities, education, and consumer behavior.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#why-this-is-important",
    "href": "13-lca.html#why-this-is-important",
    "title": "LCA",
    "section": "Why This Is Important:",
    "text": "Why This Is Important:\n\nLCA provides insights into population heterogeneity, allowing researchers to identify distinct subgroups with unique characteristics.\nIt is a powerful tool for tailoring interventions and understanding diverse outcomes.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#how-this-ties-into-the-overall-course",
    "href": "13-lca.html#how-this-ties-into-the-overall-course",
    "title": "LCA",
    "section": "How This Ties Into the Overall Course:",
    "text": "How This Ties Into the Overall Course:\n\nBuilds upon prior topics like EFA by extending latent variable modeling to categorical data.\nPrepares students for advanced mixture modeling techniques and combining LCA with SEM.\n\nBy the end of this week, students will be able to perform LCA, interpret latent class solutions, and use these insights to answer research questions about population heterogeneity.\n\nClass files\n\nDownload today’s slides here\nDownload the data for today from the National Child Health Survey (NCHS) in SPSS and CSV to import into JASP.\nHere is my example excel file to create a chart of the conditional item probabilities",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "13-lca.html#additional-notes",
    "href": "13-lca.html#additional-notes",
    "title": "LCA",
    "section": "Additional Notes",
    "text": "Additional Notes\nStay Calm… This is the Last Latent Class.\nWe’ve reached model convergence. The entropy is high. The fit is good. And yes… this is the final class.\nFor some of you (and for me), the fun is over. For others, the fun is just beginning. If that’s true, we’ve officially detected a latent subgroup of students.\nLet’s hope the class proportions are:\n\nClass 1 – “Loved Every Minute”: 99.1%\nClass 2 – “Thrilled It’s Over”: 0.9%\n\nModel fit? Impeccable. Classification? Accurate. Emotion? Mixed. But this… this was a class worth identifying.",
    "crumbs": [
      "**Measurement & Factor Analysis**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>LCA</span>"
    ]
  },
  {
    "objectID": "14-final-project.html",
    "href": "14-final-project.html",
    "title": "Final Project",
    "section": "",
    "text": "Week 15: April 21, 2026",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Final Project</span>"
    ]
  },
  {
    "objectID": "14-final-project.html#final-project-presentations",
    "href": "14-final-project.html#final-project-presentations",
    "title": "Final Project",
    "section": "Final Project Presentations",
    "text": "Final Project Presentations",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Final Project</span>"
    ]
  },
  {
    "objectID": "assignment.html",
    "href": "assignment.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Install libraries\nThis assignment uses the PRAMS data file that is fully described here\nThe assignment assumes the following packages have been installed:\nlibrary(emoji)\nlibrary(emoji)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(officer)\nlibrary(flextable)\nlibrary(ppcor)\nlibrary(ggcorrplot)\nlibrary(fastDummies)\nlibrary(emmeans)\nlibrary(gtsummary)\nlibrary(flextable)\nlibrary(performance)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#data-preparation-and-descriptive-statistics",
    "href": "assignment.html#data-preparation-and-descriptive-statistics",
    "title": "Assignment 1",
    "section": "1. Data Preparation and Descriptive Statistics",
    "text": "1. Data Preparation and Descriptive Statistics\n\n1.1 Load and Clean the Data\n\ndata &lt;- read.csv(\"C:/Users/barboza-salerno.1/Downloads/KSPRAMS_SUB_WEIGHT_ANALYSIS.csv\")\n\n# Selecting relevant variables \ndata &lt;- data %&gt;% dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale, Race_Ethnicity) \n\nBefore removing the missing data, let’s get a sense of the missingness across race & ethnicity. What is the distribution of missing respondents by race? Are there any implications?\n\n# Select only rows with missing data\ndf_missing &lt;- data[!complete.cases(data), ]\ndf_missing |&gt; tbl_summary(include = c(Race_Ethnicity))\n\n\n\n1.2 Missing Data Analysis\nHow many cases are missing? Calculate the number of omitted cases due to missing values:\n\ndata &lt;- data %&gt;% na.omit()\nnum_omitted &lt;- nrow(read.csv(\"C:/Users/barboza-salerno.1/Downloads/KSPRAMS_SUB_WEIGHT_ANALYSIS.csv\")) - nrow(data)\ncat(\"Number of omitted cases:\", num_omitted, \"\\n\")",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#correlation-analysis",
    "href": "assignment.html#correlation-analysis",
    "title": "Assignment 1",
    "section": "2. Correlation Analysis",
    "text": "2. Correlation Analysis\n\n2.1 Which variables are significantly correlated?\n\n\n2.2 Why are we using Spearman and not Pearson Correlaion?\n\n\n2.3 What variable changes the least after partialing out the other variables?\n\n# Compute correlation matrix\ncor_matrix &lt;- cor(data %&gt;% dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale), use = \"complete.obs\", method = \"spearman\")\n\nggplot_correlation &lt;- ggcorrplot(cor_matrix, lab = TRUE, title = \"Correlation Matrix\")\nprint(ggplot_correlation)\n\n\n\n\n\n\n\nprint(cor_matrix)\n# Compute partial correlations\npartial_corrs &lt;- pcor(data %&gt;% dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale))\nprint(partial_corrs)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#creating-dummy-variables-for-categorical-data",
    "href": "assignment.html#creating-dummy-variables-for-categorical-data",
    "title": "Assignment 1",
    "section": "3. Creating Dummy Variables for Categorical Data",
    "text": "3. Creating Dummy Variables for Categorical Data\n\n3.1 Frequency of Race/Ethnicity Categories\nWhat is the distribution by race?\n\ntable(data$Race_Ethnicity)\n\n\n\n3.2 Creating Dummy Variables\nRace/Ethnicity is categorical. We need to create dummies to include them into the model. The best way to do this is by using fastDummies. Follow this below. Describe exactly what this line of code is doing, word by word.\n\ndata &lt;- dummy_cols(data, select_columns = \"Race_Ethnicity\", remove_first_dummy = TRUE)\n\nExplanation: This function converts categorical Race_Ethnicity into binary variables while removing the first level as a reference category.\n\n\n3.3 Re-leveling Race/Ethnicity\nSometimes its nice to re-level the variable. The original variable distribution is given above.\n\ndata$Race_Ethnicity &lt;- relevel(factor(data$Race_Ethnicity), ref = \"NH White\")\n\nThis reorders the levels so that “NH White” is the reference category in our regression model.\n\ndata &lt;- dummy_cols(data, select_columns = \"Race_Ethnicity\", remove_first_dummy = TRUE)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#running-regression-models",
    "href": "assignment.html#running-regression-models",
    "title": "Assignment 1",
    "section": "4. Running Regression Models",
    "text": "4. Running Regression Models\nWe are predicting cigartette use during pregnancy by whether the pregnant person experienced any abuse during pregnancy, ACEs, is depressed (BPG_DEPRS8), and by race/ethnicity. Fit progressively more complex models: starting with Any_Abuse, etc…\n\nmodel0 &lt;- lm(CIG_1TRI ~ Any_Abuse, data = data)\nmodel1 &lt;- lm(CIG_1TRI ~ Any_Abuse + ACEs_Scale, data = data)\nmodel2 &lt;- lm(CIG_1TRI ~ Any_Abuse + ACEs_Scale + BPG_DEPRS8, data = data)\nmodel3 &lt;- lm(CIG_1TRI ~ Any_Abuse + ACEs_Scale + BPG_DEPRS8 + Race_Ethnicity_Hispanic + `Race_Ethnicity_NH Black` + Race_Ethnicity_Other, data = data)\n\nsummary(model3)\n\nWhat variable is omitted, and why? How much more of the variance is explained by ACEs_Scale, BPG_DEPRS8, and Race_Ethnicity compared to just Any_Abuse?",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#model-diagnostics",
    "href": "assignment.html#model-diagnostics",
    "title": "Assignment 1",
    "section": "5. Model Diagnostics",
    "text": "5. Model Diagnostics\nThe performance package is a very cool package in R. It facilitates model diagnostics. Then, plots it. Follow along.\n\n5.1 Checking Assumptions\n\ncheck_collinearity(model3)\ncheck_heteroscedasticity(model3)\ncheck_normality(model3)\ncheck_outliers(model3)\n\n\n\n5.2 Visualizing Diagnostic Plots\n\ndiagnostic_plots &lt;- plot(check_model(model3, panel = FALSE))\n\n# Display plots\nprint(diagnostic_plots[[2]]) # Q-Q plot\n\n\n\n\n\n\n\nprint(diagnostic_plots[[3]]) # Residuals vs Fitted plot\n\n\n\n\n\n\n\nprint(diagnostic_plots[[4]]) # Scale-location plot\n\n\n\n\n\n\n\nprint(diagnostic_plots[[5]]) # Cook’s distance",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#post-hoc-analysis-using-estimated-marginal-means-emms",
    "href": "assignment.html#post-hoc-analysis-using-estimated-marginal-means-emms",
    "title": "Assignment 1",
    "section": "6. Post-Hoc Analysis Using Estimated Marginal Means (EMMs)",
    "text": "6. Post-Hoc Analysis Using Estimated Marginal Means (EMMs)\nThe emmeans package allows us to predict cigarette use by any variable, here race/ethnicity. Then, we can use the confint to get confidence intervals.\n\nemm &lt;- emmeans(model3, pairwise ~ Race_Ethnicity_Hispanic)\nprint(emm)\nconfint(emm, level = 0.95)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#saving-results-to-a-word-document",
    "href": "assignment.html#saving-results-to-a-word-document",
    "title": "Assignment 1",
    "section": "7. Saving Results to a Word Document",
    "text": "7. Saving Results to a Word Document\nCreate a structured report including tables and regression results:\n\ndata %&gt;%\n  dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale, Race_Ethnicity) %&gt;%\n  tbl_summary(include = c(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale, Race_Ethnicity)) %&gt;%\n  as_flex_table() %&gt;%\n  print()\n\n\ndoc &lt;- read_docx()\n\ndoc1 &lt;- doc %&gt;%\n  body_add_par(\"Descriptive Statistics\", style = \"heading 1\") %&gt;%\n  body_add_flextable(\n    data %&gt;%\n      dplyr::select(CIG_1TRI, BPG_DEPRS8, Any_Abuse, ACEs_Scale, Race_Ethnicity) %&gt;%\n      tbl_summary(\n        type = all_continuous() ~ \"continuous2\",\n        statistic = all_continuous() ~ c(\n          \"{N_nonmiss}\",\n          \"{median} ({p25}, {p75})\",\n          \"{min}, {max}\"\n        ),\n        missing = \"no\"\n      ) %&gt;%\n      as_flex_table()\n  ) %&gt;%\n  body_add_par(\"Regression Model Summary\", style = \"heading 1\") %&gt;%\n  body_add_flextable(\n    tbl_regression(model3) %&gt;%  # Corrected function placement\n      add_global_p() %&gt;%\n      as_flex_table()\n  ) %&gt;%\n  body_add_par(\"Correlation Analysis\", style = \"heading 1\") %&gt;%\n  body_add_gg(ggplot_correlation)\n\nprint(doc1, target = \"C:/Users/barboza-salerno.1/Downloads/Regression_Report_FINAL.docx\")",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#write-up-guidelines",
    "href": "assignment.html#write-up-guidelines",
    "title": "Assignment 1",
    "section": "7. Write-Up Guidelines",
    "text": "7. Write-Up Guidelines\n\nWrite a report that includes:\n\nIntroduction: Briefly describe the purpose of the analysis.\nData Description: Briefly explain the data set and key variables used, including how they were coded and re-coded as applicable.\nStatistical Analysis: Describe the analytic approach taken. This includes descriptive statistics, regression analysis, diagnostic assessment, and marginal means.\nDescriptive Statistics: Present summary statistics and missing data analysis (Table 1 in Word). Correlation analysis (Figure 1).\nRegression Models: Interpret key findings from each model. Describe how the models change. Present final model (Table 2 in Word).\nModel Assumption Checks: Discuss the model’s validity based on assumption checks. Include plots as appendix.\nPost-Hoc Analysis: Interpret estimated marginal means. Create a table of the estimated marginal means for smoking by Race/Ethnicity (By hand - Table 3).\nConclusion: Summarize key insights and possible limitations. Suggest two policy recommendations for addressing smoking during pregnancy.",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#submission-instructions",
    "href": "assignment.html#submission-instructions",
    "title": "Assignment 1",
    "section": "Submission Instructions:",
    "text": "Submission Instructions:\n\nSubmit both the .R script and the Word document.\nEnsure all tables and plots are properly formatted.\nAssignment due by email by end of Week 9.",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "assignment.html#grading-criteria",
    "href": "assignment.html#grading-criteria",
    "title": "Assignment 1",
    "section": "Grading Criteria:",
    "text": "Grading Criteria:\n\n\n\nSection\nPoints\n\n\n\n\nData Cleaning & Preparation\n20\n\n\nDescriptive Statistics\n20\n\n\nRegression Models\n20\n\n\nModel Diagnostics\n20\n\n\nWrite-Up & Interpretation\n20\n\n\nTotal\n100\n\n\n\nGood luck with your analysis!\nSee my sample write-up",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "slides/inclass.html",
    "href": "slides/inclass.html",
    "title": "In Class Assignment",
    "section": "",
    "text": "In Class assignment – Simple Linear Regression Mechanics\nThis file uses data from the 2021 BRFSS that is available for download here\nFor this assignment, download the subsetted SPSS file I created, and follow these steps:",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>In Class Assignment</span>"
    ]
  },
  {
    "objectID": "slides/inclass.html#in-class-assignment-simple-linear-regression-mechanics",
    "href": "slides/inclass.html#in-class-assignment-simple-linear-regression-mechanics",
    "title": "In Class Assignment",
    "section": "",
    "text": "The BRFSS data contains information on 11 separate ACEs. The file codes them as follows 1 = the respondent endorsed the ACE; 2 = the respondent did not endorse the ACE. Create a scale that ranges from 0 (No ACEs) to 11 (ALL ACEs) representing the ACEs sum score (i.e. cumulative risk).\nReport the mean, range and standard deviation of your ACEs scale.\nReport the correlations between all ACEs except for the three sexual abuse/assault variables (note how these variables are measured)\nRun a simple linear regression that predicts 1) the number of days the respondent reported being in poor mental health in the past 30 days; 2) the number of days the respondent reported being in poor physical health in the past 30 days; and 3) binge drinking. Then answer the following questions\n\n\nHow many days on average did Respondents with no ACEs report having poor mental health?\nHow many days on average did Respondents with no ACEs report having poor mental health?\nHow many days on average did the respondent report binge drinking?\nInterpret the slope parameter for each model. What is the null hypothesis. Comment on the statistical significance of the slope parameter.\nHow much of the variation in mental health, physical health and binge drinking is explained by ACEs for each model respectively. What factors should be considered when interpreting R square?",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>In Class Assignment</span>"
    ]
  },
  {
    "objectID": "slides/medmod/mediationR.html",
    "href": "slides/medmod/mediationR.html",
    "title": "Simple Mediation",
    "section": "",
    "text": "The conceptual model\nMediation analysis can be conducted using the processR package. We will only examine the most simple model, Hayes Model 4.\nI will use the same dataset when we get to [moderation]. First, we will test whether the variable associated with symptoms of post-traumatic stress (tra1) mediates the association between experiencing child sexual abuse (sexab) and delinquent behaviors, which is slightly different from the question that we examined in class.\nRemove missingness (na)\nThe conceptual model that illustrates those relationships is provided below. For the simple mediation model, both conceptual and statistical diagrams are the same. NOTE that I changed the model number from 1 to 4, see the Hayes macro template I provided to you in the lecture.\nlabels=list(X=\"Sexual\\nAbuse\",M=\"PTSS\",Y=\"DELIN\")\nNotice I used the option rady to increase the y dimension of the box so that the words “Sex Abuse” will fit. Try running the code without the option to demonstrate the difference in output.\nNote m use of the package processR below.\nprocessR::pmacroModel(4,labels=labels, rady = 0.07)\nprocessR::statisticalDiagram(4,labels=labels, rady = 0.07)\nNote that we must remove missing values before the model will run. This is part of the ‘trial and error’ common in R programming.\nBelow is the same code we used before to mean center the variable for PTSS (tra1).\nmediation_example$tra1_mean &lt;- \n  mediation_example$tra1 - mean(mediation_example$tra1, na.rm = T)\nBelow is a quick plot using Base R to visualize the variables.\nplot(y=mediation_example$bcdel1, \n     x=mediation_example$tra1_mean,\n     xlab = \"PTSS\", ylab = \"DELINQ\")\ncor(mediation_example$tra1_mean, mediation_example$bcdel1)\n\n[1] 0.1356008\nresult &lt;- process(\n  data = mediation_example, \n  y = \"bcdel1\", \n  x = \"sexab\", \n  m = \"tra1\", \n  total = 1, \n  normal = 1, \n  model = 4, \n  seed = 31216)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Simple Mediation</span>"
    ]
  },
  {
    "objectID": "slides/medmod/mediationR.html#the-conceptual-model",
    "href": "slides/medmod/mediationR.html#the-conceptual-model",
    "title": "Simple Mediation",
    "section": "",
    "text": "Note\n\n\n\nNote that by including the \\n between the space in the word “Sexual Abuse” I am telling R to mimic a hard carriage return so that the words appear on different lines.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel 4 Results\n\n\n\n\n\nModel 4 Effects",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Simple Mediation</span>"
    ]
  },
  {
    "objectID": "logistic.html",
    "href": "logistic.html",
    "title": "Logistic Regression Example",
    "section": "",
    "text": "The Dataset\nThe data is a mixed variable dataset containing 14 variables of 297 patients for their heart disease diagnosis. The data comes in an R package called kmed which you can read about on your own. Patients were diagnosed with heart disease in four classes. We will used this dataset to illustrate how multiple risk factors are related to a heart disease diagnosis, such as age (years), sex (FALSE = female; TRUE = male), chest pain (1 = typical angina, 2 = atypical angina, 3 = non-anginal pain, and 4 = asymptomatic) and thalach (max heart rate achieved).\n\nlibrary(kmed)\ndat &lt;- heart\n\n\n# select variables\nlibrary(dplyr)\ndat &lt;- dat %&gt;%\n  dplyr::select(\n    age,\n    sex,\n    cp,\n    thalach,\n    class\n  )\n# print dataset's structure\nstr(dat)\n\n'data.frame':   297 obs. of  5 variables:\n $ age    : num  63 67 67 37 41 56 62 57 63 53 ...\n $ sex    : logi  TRUE TRUE TRUE TRUE FALSE TRUE ...\n $ cp     : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 4 4 3 2 2 4 4 4 4 ...\n $ thalach: num  150 108 129 187 172 178 160 163 147 155 ...\n $ class  : int  0 2 1 0 0 0 3 0 2 1 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:6] 88 167 193 267 288 303\n  ..- attr(*, \"names\")= chr [1:6] \"88\" \"167\" \"193\" \"267\" ...\n\n\n\n# rename variables\ndat &lt;- dat %&gt;%\n  dplyr::rename(\n    chest_pain = cp,\n    max_heartrate = thalach,\n    heart_disease = class\n  )\n\n\n# recode sex\ndat$sex &lt;- factor(dat$sex,\n  levels = c(FALSE, TRUE),\n  labels = c(\"female\", \"male\")\n)\n\n\n# recode chest_pain\ndat$chest_pain &lt;- factor(dat$chest_pain,\n  levels = 1:4,\n  labels = c(\"typical angina\", \"atypical angina\", \"non-anginal pain\", \"asymptomatic\")\n)\n\n\n# recode heart_disease into 2 classes\ndat$heart_disease &lt;- ifelse(dat$heart_disease == 0,\n  0,\n  1\n)\n\n\n# set labels for heart_disease\ndat$heart_disease &lt;- factor(dat$heart_disease,\n  levels = c(0, 1),\n  labels = c(\"no disease\", \"disease\")\n)\n\n\nlevels(dat$heart_disease)\n\n[1] \"no disease\" \"disease\"   \n\n\n\n# save model\nm1 &lt;- glm(heart_disease ~ age,\n  data = dat,\n  family = \"binomial\"\n)\n\n\nsummary(m1)\n\n\nCall:\nglm(formula = heart_disease ~ age, family = \"binomial\", data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.05122    0.76862  -3.970  7.2e-05 ***\nage          0.05291    0.01382   3.829 0.000128 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 394.25  on 295  degrees of freedom\nAIC: 398.25\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n# OR for age\nexp(coef(m1)[\"age\"])\n\n     age \n1.054331 \n\n\n\n# prob(heart disease) for age = 0\nexp(coef(m1)[1]) / (1 + exp(coef(m1)[1]))\n\n(Intercept) \n 0.04516478 \n\n\n\n# 95% CI for the OR for age\nexp(confint(m1,\n  parm = \"age\"\n))\n\n   2.5 %   97.5 % \n1.026699 1.083987 \n\n\n\n# predict probability to develop heart disease\npred &lt;- predict(m1,\n  newdata = data.frame(age = c(30)),\n  type = \"response\"\n)\n\n\npred\n\n        1 \n0.1878525 \n\n\n\n# predict probability to develop heart disease\npred &lt;- predict(m1,\n  newdata = data.frame(age = c(30)),\n  type = \"response\",\n  se = TRUE\n)\n\n\npred$fit\n\n        1 \n0.1878525 \n\n\n\n# 95% confidence interval for the prediction\nlower &lt;- pred$fit - (qnorm(0.975) * pred$se.fit)\nupper &lt;- pred$fit + (qnorm(0.975) * pred$se.fit)\nc(lower, upper)\n\n         1          1 \n0.07873357 0.29697138 \n\n\n\n# 95% confidence interval for the prediction\nlower &lt;- pred$fit - (1.96 * pred$se.fit)\nupper &lt;- pred$fit + (1.96 * pred$se.fit)\nc(lower, upper)\n\n         1          1 \n0.07873156 0.29697339 \n\n\n\nlibrary(sjPlot)\n\nInstall package \"strengejacke\" from GitHub (`devtools::install_github(\"strengejacke/strengejacke\")`) to load all sj-packages at once!\n\nlibrary(ggplot2)\n\n\n# plot\nplot_model(m1,\n  type = \"pred\",\n  terms = \"age\"\n) +\n  labs(y = \"Prob(heart disease)\") + theme_bw()\n\n\n\n\n\n\n\n\n\n# levels for sex\nlevels(dat$sex)\n\n[1] \"female\" \"male\"  \n\n\n\n# save model\nm2 &lt;- glm(heart_disease ~ sex,\n  data = dat,\n  family = \"binomial\"\n)\n\n\nsummary(m2)\n\n\nCall:\nglm(formula = heart_disease ~ sex, family = \"binomial\", data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.0438     0.2326  -4.488 7.18e-06 ***\nsexmale       1.2737     0.2725   4.674 2.95e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 386.12  on 295  degrees of freedom\nAIC: 390.12\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nexp(coef(m2)[\"sexmale\"])\n\n sexmale \n3.573933 \n\n\n\n# prob(disease) for sex = female\nexp(coef(m2)[1]) / (1 + exp(coef(m2)[1]))\n\n(Intercept) \n  0.2604167 \n\n\n\nchisq.test(table(dat$heart_disease, dat$sex))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(dat$heart_disease, dat$sex)\nX-squared = 21.852, df = 1, p-value = 2.946e-06\n\n\n\n# predict probability to develop heart disease\npred &lt;- predict(m2,\n  newdata = data.frame(sex = c(\"male\")),\n  type = \"response\"\n)\npred\n\n        1 \n0.5572139 \n\n\n\n# plot\nplot_model(m2,\n  type = \"pred\",\n  terms = \"sex\"\n) +\n  labs(y = \"Prob(heart disease)\")\n\n\n\n\n\n\n\n\n\n# create data frame of new patient\nnew_patient &lt;- data.frame(\n  age = 32,\n  sex = \"female\"\n)\n\n\nm3 &lt;- glm(heart_disease ~ sex + age,\n  data = dat,\n  family = \"binomial\"\n)\n# predict probability to develop heart disease\npred &lt;- predict(m3,\n  newdata = new_patient,\n  type = \"response\"\n)\n# print prediction\npred\n\n         1 \n0.06224456 \n\n\n\n# 1. age, sex and chest pain on prob of disease\nplot_model(m3,\n  type = \"pred\",\n  terms = c(\"age\",  \"sex\"),\n  ci.lvl = NA # remove confidence bands\n) +\n  labs(y = \"Prob(heart disease)\")\n\nData were 'prettified'. Consider using `terms=\"age [all]\"` to get smooth\n  plots.\n\n\n\n\n\n\n\n\n\n\ntab_model(m3, m2,\n  show.ci = FALSE, # remove CI\n  show.aic = TRUE, # display AIC\n  p.style = \"numeric_stars\" # display p-values and stars\n)\n\n\n\n\n \nheart disease\nheart disease\n\n\nPredictors\nOdds Ratios\np\nOdds Ratios\np\n\n\n(Intercept)\n0.01 ***\n&lt;0.001\n0.35 ***\n&lt;0.001\n\n\nsex [male]\n4.47 ***\n&lt;0.001\n3.57 ***\n&lt;0.001\n\n\nage\n1.07 ***\n&lt;0.001\n\n\n\n\nObservations\n297\n297\n\n\nR2 Tjur\n0.142\n0.078\n\n\nAIC\n370.435\n390.118\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\nlibrary(pROC)\n\n\n# save roc object\nres &lt;- roc(heart_disease ~ fitted(m3),\n  data = dat\n)\n# plot ROC curve\nggroc(res, legacy.axes = TRUE)\n\n\n\n\n\n\n\n\n\nres$auc\n\nArea under the curve: 0.713\n\n\n\n# plot ROC curve with AUC in title\nggroc(res, legacy.axes = TRUE) +\n  labs(title = paste0(\"AUC = \", round(res$auc, 2)))\n\n\n\n\n\n\n\n\n\nlibrary(gtsummary)\n\n\n# print table of results\ntbl_regression(m3, exponentiate = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n    female\n—\n—\n\n\n\n\n    male\n4.47\n2.57, 8.05\n&lt;0.001\n\n\nage\n1.07\n1.04, 1.10\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\n\nlibrary(finalfit)\n# set variables\ndependent &lt;- \"heart_disease\"\nindependent &lt;- c(\"age\", \"sex\")\nindependent_final &lt;- c(\"age\", \"sex\", \"chest_pain\")\n\ndat %&gt;% or_plot(dependent, independent,\n  table_text_size = 3.5 # reduce text size\n)",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Logistic Regression Example</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html",
    "href": "slides/moderation/moderation.html",
    "title": "Moderation Analysis",
    "section": "",
    "text": "Prelims\ninstall.packages(c(“haven”, “interactions”, “ggplot2”, “jtools”))\n# Load libraries\nlibrary(haven)         # For reading SPSS files\nlibrary(ggplot2)       # For plotting\nlibrary(jtools)        # For interaction and J-N plot\n\nWarning: package 'jtools' was built under R version 4.3.3\n\nlibrary(interactions)  # For Johnson-Neyman analysis\n\nWarning: package 'interactions' was built under R version 4.3.3\n\n# Load the data\ndata &lt;- read_sav(\"../../slides/medmod2/sexmin_pts_delinq.sav\")\n# Check variable types\nstr(data)\n\ntibble [126 × 3] (S3: tbl_df/tbl/data.frame)\n $ sexmin: num [1:126] 0 1 0 0 0 0 0 1 0 0 ...\n  ..- attr(*, \"format.spss\")= chr \"F1.0\"\n $ delinq: num [1:126] 0 0 2 4 5 0 0 0 0 0 ...\n  ..- attr(*, \"format.spss\")= chr \"F2.0\"\n $ ptss  : num [1:126] 2 2 2 2 2 3 3 3 4 4 ...\n  ..- attr(*, \"format.spss\")= chr \"F2.0\"",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html#data-types",
    "href": "slides/moderation/moderation.html#data-types",
    "title": "Moderation Analysis",
    "section": "Data types",
    "text": "Data types\nSexual minority is binary coded as 0/1. This does not make for a nice plot, but the JN method does not accept factor variables. So, for plotting, you can convert sexmin to factor and use labels (i.e., “Sexual Minority” “Not a Sexual Minority”), otherwise skip it. Try it yourself to see what happens.\n\ndata$sexmin1 &lt;- as.factor(data$sexmin)\ndata$sexmin1 &lt;- ifelse(data$sexmin1 == 1, \"Sexual Minority\", \"Not a Sexual Minority\")",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html#the-linear-regression-model",
    "href": "slides/moderation/moderation.html#the-linear-regression-model",
    "title": "Moderation Analysis",
    "section": "The Linear Regression Model",
    "text": "The Linear Regression Model\n\n# Fit moderation model\nmod &lt;- lm(delinq ~ ptss * sexmin, data = data)\n\n# Summary of model\nsummary(mod)\n\n\nCall:\nlm(formula = delinq ~ ptss * sexmin, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8245 -1.7327 -0.7327  1.4922 11.4534 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.13733    0.61912   3.452 0.000767 ***\nptss        -0.04496    0.06167  -0.729 0.467336    \nsexmin      -0.72060    1.39755  -0.516 0.607066    \nptss:sexmin  0.25795    0.12457   2.071 0.040517 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.511 on 121 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.1406,    Adjusted R-squared:  0.1193 \nF-statistic: 6.599 on 3 and 121 DF,  p-value: 0.0003623\n\n\n\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\nTable 1. Regression Coefficients\n\n\n\n\n\n\n\n\n\n\nPredictor\nEstimate\nStd..Error\nt.value\np.value\nSignificance\n\n\n\n\nIntercept\n2.137\n0.619\n3.452\n0.001\n***\n\n\nPTSS\n-0.045\n0.062\n-0.729\n0.467\n\n\n\nSexual Minority (vs. non-minority)\n-0.721\n1.398\n-0.516\n0.607\n\n\n\nPTSS × Sexual Minority\n0.258\n0.125\n2.071\n0.041\n*\n\n\n\n\n\nThis should look familiar. The model predicts delinquent behavior using PTSS, sexual minority status, and their interaction as predictors.\nREVIEW:\n\nIntercept (2.14): This is the expected value of the outcome when PTSS = 0 and the individual is not a sexual minority.\nPTSS (-0.045): Among non-sexual minority individuals, PTSS is not significantly associated with the outcome (p = 0.467).\nSexual Minority main effect (-0.721): Among individuals with PTSS = 0, being a sexual minority is not significantly associated with the outcome (p = 0.607).\nPTSS × Sexual Minority interaction (0.258): This term is statistically significant (p = 0.041), indicating that the association between PTSS and the outcome differs by sexual minority status. Specifically, PTSS has a stronger positive effect on the outcome for sexual minority individuals.\n\n\nReminder: All model assumptions (?) must be met, unfortunately.\n\n# Visualize interaction effect\ninteract_plot(mod,\n              pred = ptss,\n              modx = sexmin,\n              plot.points = F,\n              interval = TRUE,\n              int.width = 0.95,\n              main.title = \"Moderation of PTSS and Sexual Minority Status on Delinquency\",\n              legend.main = \"Identity\",\n              x.label = \"PTSS\",\n              y.label = \"Delinquency\")",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html#interpretation",
    "href": "slides/moderation/moderation.html#interpretation",
    "title": "Moderation Analysis",
    "section": "Interpretation",
    "text": "Interpretation\nThis plot shows how post-traumatic stress symptoms (PTSS) predict delinquency, and how this relationship differs by sexual minority status.\nSolid Line (sexmin = 1) → Sexual minority individuals\n\nThe slope is positive, indicating that as PTSS increases, delinquency increases for sexual minority youth.\nThis relationship is statistically significant. Note that you can assess significance from the plot because the confidence band (shaded area) does not cross zero\n\nDashed Line (sexmin = 0) → Non-sexual minority individuals\n\nThe slope is slightly negative, mostly flat, suggesting that PTSS is not associated with delinquency in this group.\n\nInteraction effect: The effect of PTSS on delinquency depends on sexual minority status. More PTSS = More delinquency for sexual minority youth, more PTSS has no effect for youth who do not identify as a sexual minority.\n\n# Johnson-Neyman technique\njohnson_neyman(mod, pred = sexmin, modx = ptss)\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen ptss is OUTSIDE the interval [-164.38, 7.60], the slope of sexmin is p\n&lt; .05.\n\nNote: The range of observed values of ptss is [2.00, 17.00]",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "slides/moderation/moderation.html#interpretation-of-the-johnson-neyman-plot-j-n",
    "href": "slides/moderation/moderation.html#interpretation-of-the-johnson-neyman-plot-j-n",
    "title": "Moderation Analysis",
    "section": "Interpretation of the Johnson-Neyman Plot (J-N)",
    "text": "Interpretation of the Johnson-Neyman Plot (J-N)\nThis J-N plot shows how the effect of sexual minority status on delinquency changes depending on the level of PTSS.\nKey Interpretation: - The red shade shows where the effect of sexual minority status on delinquency is not statistically significant (p &gt; .05). - The blue shade shows where the effect *is** statistically significant (p &lt; .05). - The dashed vertical line marks the (J-N — the *threshold of PTSS** where the effect of sexmin becomes significant. - The black horizontal bar along the x-axis shows the *observed range of PTSS in the data**.\n\nRegions of significance\nFor individuals with PTSS scores below ~8, the difference in delinquency between sexual minority and non-minority youth is not statistically significant. However, when PTSS exceeds ~8, sexual minority youth show significantly higher delinquency compared to their peers.\n\n\nLink to policy and practice\nI have several published articles using this type of methodology. In one article Barboza-Salerno & Remillard (2023) we examined the impact of future orientation in buffering the effect of early child adversity on delinquent behavior. Read it, you should be able to write the paper now.\n\n\n\n\nBarboza-Salerno, G. E., & Remillard, A. (2023). Early child adversity and delinquent behavior in foster care youth: Do future expectations and sexual identity moderate the mediating role of posttraumatic stress? Journal of Child & Adolescent Trauma, 16(4), 945–957.",
    "crumbs": [
      "**Applications**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Moderation Analysis</span>"
    ]
  },
  {
    "objectID": "infant_mortality.html",
    "href": "infant_mortality.html",
    "title": "Infant Mortality Example",
    "section": "",
    "text": "Odds and Risk ratios\nRisk ratios are tricky because they are invariant, but odds ratios are not. By using risk ratios, the data can show BOTH gross disparities of infant mortality by race and also show no racial disparities at the same time. The reason comes down to the invariance property.\nOdds ratios and risk ratios are both measures used in statistics to compare the likelihood of an event occurring between two groups. However, they have different properties when it comes to interpretation.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Infant Mortality Example</span>"
    ]
  },
  {
    "objectID": "infant_mortality.html#mortality-rates-per-1000-births",
    "href": "infant_mortality.html#mortality-rates-per-1000-births",
    "title": "Infant Mortality Example",
    "section": "Mortality Rates per 1,000 births",
    "text": "Mortality Rates per 1,000 births\nThe interpretation is: in California, there are about 3.04 infant deaths per 1,000. What is going on with Indiana?\n\n(df$inf_mort_white_1000 &lt;- (\n  df$white_infant_deaths/df$white_births)*1000\n )\n\n[1] 3.047175 3.522871 2.247074 6.016995 3.653389 5.047984 5.131467 4.275928\n\n\n\nknitr::kable(\n  df[, c(1,8)],  \n  col.names = c(\n    'State', \n    'White Infant Mortality per 1,000'\n    ), \n  align = \"lc\"\n  )\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nState\nWhite Infant Mortality per 1,000\n\n\n\n\nCalifornia\n3.047175\n\n\nColorado\n3.522871\n\n\nConnecticut\n2.247074\n\n\nIndiana\n6.016995\n\n\nMaryland\n3.653389\n\n\nMichigan\n5.047984\n\n\nOhio\n5.131467\n\n\nPennsylvania\n4.275928\n\n\n\n\n\nThe infant mortality rate for Black infants is substantially higher. In Michigan, there are 14.2 Black infants who die for every 1,000 births.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Infant Mortality Example</span>"
    ]
  },
  {
    "objectID": "infant_mortality.html#mortality-ratios",
    "href": "infant_mortality.html#mortality-ratios",
    "title": "Infant Mortality Example",
    "section": "Mortality Ratios",
    "text": "Mortality Ratios\n\n(df$inf_mort_black_1000 &lt;- (\n  df$black_infant_deaths/df$black_births)*1000\n )\n\n[1]  9.066566 11.713521  8.951113 11.710539  9.584821 14.162292 13.206092\n[8] 10.747552\n\n\n\nknitr::kable(\n  df[, c(1,9)],  \n  col.names = c(\n    'State', \n    'Black Infant Mortality per 1,000'\n    ), \n  align = \"lc\"\n  )\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nState\nBlack Infant Mortality per 1,000\n\n\n\n\nCalifornia\n9.066566\n\n\nColorado\n11.713521\n\n\nConnecticut\n8.951113\n\n\nIndiana\n11.710539\n\n\nMaryland\n9.584821\n\n\nMichigan\n14.162292\n\n\nOhio\n13.206092\n\n\nPennsylvania\n10.747552\n\n\n\n\n\nBelow, I calculate the relative risk ratio for Black infants compared to Whites. You can see very large disparities. For example, in California the relative risk of death for Black infants is almost three times higher than for White infants (2.975)\n\n(df$RR_mort_black_white &lt;- \n   df$inf_mort_black_1000/df$inf_mort_white_1000)\n\n[1] 2.975401 3.324993 3.983454 1.946244 2.623542 2.805535 2.573551 2.513502",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Infant Mortality Example</span>"
    ]
  },
  {
    "objectID": "infant_mortality.html#survivorship-ratios",
    "href": "infant_mortality.html#survivorship-ratios",
    "title": "Infant Mortality Example",
    "section": "Survivorship Ratios",
    "text": "Survivorship Ratios\nLet’s calculate the survivorship ratio\n\ndf$inf_surv_white &lt;- \n  df$white_births - df$white_infant_deaths\ndf$inf_surv_black  &lt;- \n   df$black_births - df$black_infant_deaths\n\ndf$inf_surv_white_1000 &lt;- \n    (df$white_births/df$inf_surv_white)*1000\ndf$inf_surv_black_1000 &lt;- \n    (df$black_births/df$inf_surv_black)*1000\n\n\n(df$RR_surv_black_white &lt;- \n   df$inf_surv_black_1000/df$inf_surv_white_1000)\n\n[1] 1.006074 1.008288 1.006765 1.005761 1.005989 1.009245 1.008183 1.006542\n\n\n\nggplot(\n  df, \n  aes(x = as.factor(Location), \n      y = RR_mort_black_white, \n      group = 1)\n) +\n  geom_line() +\n  ylim(0, 4) +\n  labs(\n    title = \"Relative Risk of Infant Mortality: Black - White\",\n    x = \"Location\",\n    y = \"Relative Risk\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(\n  df, \n  aes(x = as.factor(Location), \n      y = RR_surv_black_white, \n      group = 1)\n) +\n  geom_line() +\n  ylim(0, 1.1) +\n  labs(\n    title = \"Relative Risk of Infant Survival: Black - White\",\n    x = \"Location\",\n    y = \"Relative Risk\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipGGthemes\n\n\n\nWe can make nicer charts with the add-on package called ggthemes. Let’s install it and see if we can make prettier charts. install.packages(ggthemes) then library(ggthemes)\n\n\n\nPlotting the differences\nBelow, I am selecting the theme called theme_stata which makes the output look like a stata graph.\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.3.3\n\nggplot(df, \n  aes(x=as.factor(Location), \n  y=RR_surv_black_white, group=1))  + \n  geom_line(color = \"midnightblue\") + \n  ylim(0, 1.1) + \n  theme_stata() +\n  labs(title = \"Black-White Survivorship\", x = \"Location\", y = \"Relative Risk\")\n\n\n\n\n\n\n\nggplot(df, \n  aes(x=as.factor(Location), \n  y=RR_mort_black_white, group=1))  + \n  geom_line(color = \"darkred\") + \n  ylim(1, 4) + \n  theme_stata() +\n  labs(\n    title = \"Black-White Mortality\", \n    x = \"Location\", \n    y = \"Relative Risk\"\n    )\n\n\n\n\n\n\n\n\n\nYour tasks\nIt is very reasonable to examine these data further.\n\nWhat research questions would you propose to examine infant mortality disparities across states?\nWould the research question be the same if you were examining survivorship versus mortality?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Infant Mortality Example</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html",
    "href": "PRAMS_Correlation_Analysis.html",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "",
    "text": "Dataset Description\nThe Pregnancy Risk Assessment Monitoring System (PRAMS) Phase 8 dataset collects data on maternal behaviors and experiences before, during, and after pregnancy. The sample is drawn from birth certificate records across multiple jurisdictions, covering 81% of U.S. live births. I would provide the link to the data but of course it is now gone due to the censorship happening with our government currently, which has substantial implications for the reproductive health of women and other persons regardless of their pregnancy status.\nThis analysis uses the data from Kansas. These data were used because I wanted to focus on associations between ACEs, maternal education, parenting stress, and intimate partner violence. Each state administers its own modules, and for some reason Kansas asked these. If you would like to read a summary of the findings from these data, check out this website.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#introduction",
    "href": "PRAMS_Correlation_Analysis.html#introduction",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Introduction",
    "text": "Introduction\nUnderstanding how early-life adversity, maternal education, and stress during pregnancy interact is crucial for maternal and child health research. This analysis examines the relationships between Adverse Childhood Experiences (ACEs), Stress During Pregnancy (STRESS), and Maternal education (Meduc) using partial and semi-partial correlation techniques. The goal is to determine whether maternal education during pregnancy influences stress levels beyond what can be explained by prior adverse experiences (ACEs).",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#research-question",
    "href": "PRAMS_Correlation_Analysis.html#research-question",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Research Question",
    "text": "Research Question\n\nDoes Maternal Education predict Stress During Pregnancy after controlling for Adverse Childhood Experiences (ACEs)?\nDoes dverse Childhood Experiences (ACEs) predict Stress During Pregnancy after controlling for Maternal Education?\nHow does the relationship between ACEs and Stress change when we control for education in both variables (Partial Correlation) vs. when we remove the effect of education only from Stress (Semi-Partial Correlation)?\n\n\nData and Variables\nClick here for the dataset used in the analysis.\nClick here for the R script for which this example is based.\nThe table below provides an overview of the key variables used in this analysis:\n\n\nWarning: package 'knitr' was built under R version 4.3.3\n\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\nPRAMS Phase 8 Variable Descriptions\n\n\n\n\n\n\n\nVariable_Name\nLabel\nRecodes\n\n\n\n\nNEED_TRAN\nAccess to Basic Needs - Affordable Transportation\nMaterial Hardship\n\n\nNEED_FOOD\nBasic Needs - Food Insecurity\nMaterial Hardship\n\n\nNEED_SHOUS\nBasic Needs - Safe Housing\nMaterial Hardship\n\n\nNEED_CHOUS\nBasic Needs - Consistent Housing\nMaterial Hardship\n\n\nNEED_CROWD\nBasic Needs - Crowded Housing\nMaterial Hardship\n\n\nNEED_UTIL\nBasic Needs - Utilities\nMaterial Hardship\n\n\nNEED_PHON\nBasic Needs - Phone Access\nMaterial Hardship\n\n\nNEED_OTH\nBasic Needs - Other Unmet Needs\nMaterial Hardship\n\n\nHDP_SAF\nPartner Threatened Safety\nIntimate Partner Violence\n\n\nHDP_ANGR\nPartner Anger/Threats\nIntimate Partner Violence\n\n\nHDP_CTRL\nPartner Control of Activities\nIntimate Partner Violence\n\n\nHDP_SEX\nPartner Forced Sexual Activity\nIntimate Partner Violence\n\n\nSTRS_FM3\nClose Family Member Hospitalized\nSocial Stressor\n\n\nSTRS_DV3\nDivorce or Separation\nSocial Stressor\n\n\nSTRS_MOV\nMoved to a New Address\nSocial Stressor\n\n\nSTRSHOME\nHomelessness\nSocial Stressor\n\n\nSTRS_JOB\nPartner Lost Job\nSocial Stressor\n\n\nSTRS_WRK\nLost Job Despite Wanting to Work\nSocial Stressor\n\n\nSTRS_PAY\nCut in Work Hours or Pay\nSocial Stressor\n\n\nSTRS_AWY\nSeparated from Partner Due to Deployment/Travel\nSocial Stressor\n\n\nSTRS_ARG\nFrequent Arguments with Partner\nSocial Stressor\n\n\nSTRS_PG\nPartner Did Not Want Pregnancy\nSocial Stressor\n\n\nSTRS_BIL\nProblems Paying Rent/Mortgage\nSocial Stressor\n\n\nSTRS_DRG\nClose Person Had a Drug or Alcohol Problem\nSocial Stressor\n\n\nSTRS_DH3\nClose Person Died\nAdverse Childhood Experiences\n\n\nCDHD_DVRC\nParent or Guardian Divorced/Separated\nAdverse Childhood Experiences\n\n\nCDHD_HOUS\nMoved Due to Rent/Mortgage Issues\nAdverse Childhood Experiences\n\n\nCDHD_FOOD\nWent Hungry Due to Food Insecurity\nAdverse Childhood Experiences\n\n\nCDHD_JAIL\nParent or Guardian Involved in Legal System\nAdverse Childhood Experiences\n\n\nCDHD_SUBS\nParent or Guardian Had Substance Use Issues\nAdverse Childhood Experiences\n\n\nCDHD_FSTR\nExperience in Foster Care\nAdverse Childhood Experiences\n\n\nCIG_1TRI\nCigarettes Smoked Daily - 1st Trimester\nCigarettes Smoked Daily - 1st Trimester\n\n\nMAT_ED\nMaternal Years of Education\nMaternal Education",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#explanation-of-correlation-types",
    "href": "PRAMS_Correlation_Analysis.html#explanation-of-correlation-types",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Explanation of Correlation Types",
    "text": "Explanation of Correlation Types\n\nCorrelation\nDefinition: Measures the direct (linear) relationship between two variables without controlling for other influences.\n\nWhat does it ask? “How strongly are two variables associated?” “When one variable increases, does the other also increase (positive correlation), decrease (negative correlation), or are the variables not linearly related?”\nWhy does this matter?\n\n\nIdentifies basic associations: Helps determine whether two variables have a relationship worth further investigation.\nGuides hypothesis development: Provides an initial understanding before applying more complex statistical techniques like partial correlation or regression.\nDoes not imply causation: A strong correlation does not mean one variable causes changes in the other; it simply indicates they move together.\n\n\nExample Interpretation: If ACEs and Stress During Pregnancy have a positive correlation, it suggests that individuals with higher adverse childhood experiences tend to experience more stress during pregnancy. However, other factors (e.g., education, income) could be influencing this relationship.\nPositive values indicate a direct relationship (when one increases, the other also increases).\nNegative values indicate an inverse relationship (when one increases, the other decreases).\nValues closer to 0 suggest a weak or no linear association between the variables. This DOES NOT mean that no relationship exists.\n\n\n\nPartial Correlation\nDefinition: Measures the direct relationship between two variables while controlling for the effect of a third variable.\n\nWhat does it ask? “What is the association between Maternal Education and Stress During Pregnancy, after removing the effect of ACEs from both?”\n\nWhy does this matter? If the correlation remains significant, this suggests that education independently contributes to stress beyond what can be explained by early-life adversity.\n\n\n\nSemi-Partial (Part) Correlation\nDefinition: Measures the relationship between two variables while controlling for a third variable’s effect on just one of them.\n\nWhat does it ask? “What is the association between Maternal Education and Stress During Pregnancy, after removing the effect of ACEs only from Stress During Pregnancy?”\nWhy does this matter? If the relationship weakens, it suggests that ACEs account for some of the variance in how education affects stress. Another way to think about this is that ACEs partly explain how education effects stress. And, yet another ‘connect-the-dots’ moment is that tf the relationship weakens, then ACEs mediate some of the observed effects of education on stress",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#data-import-and-preprocessing",
    "href": "PRAMS_Correlation_Analysis.html#data-import-and-preprocessing",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Data Import and Preprocessing",
    "text": "Data Import and Preprocessing\n\nlibrary(tidyverse)\nlibrary(ppcor) # For partial and semi-partial correlation\n\n# Load dataset\ndf &lt;- read.csv(\"data/KSPRAMS_SUB_COR.csv\")\n\n# Select relevant columns\ndata_subset &lt;- df %&gt;% \n  dplyr::select(ACEs, STRESS, Meduc) %&gt;% \n  na.omit()\n\n# Check summary statistics\nsummary(data_subset)\n\n      ACEs           STRESS           Meduc      \n Min.   :0.000   Min.   : 0.000   Min.   :1.000  \n 1st Qu.:0.000   1st Qu.: 0.000   1st Qu.:3.000  \n Median :0.000   Median : 1.000   Median :4.000  \n Mean   :1.043   Mean   : 1.892   Mean   :3.916  \n 3rd Qu.:2.000   3rd Qu.: 3.000   3rd Qu.:5.000  \n Max.   :6.000   Max.   :14.000   Max.   :5.000  \n\n\n\n\n\n\n\n\nWarning\n\n\n\nPlease pay particular attention to the handling of missing data in R. There are many ways to handle missing data with significant implications for your analysis. For some good guides to handling missing data in R see How does R handle missing data from UCLA and Missing data tutorial in R from Princeton University.\n\n\n\n# Compute Pearson correlation matrix\ncor_matrix &lt;- cor(data_subset, method = \"pearson\")\n\n# Print correlation matrix\nprint(cor_matrix)\n\n             ACEs     STRESS      Meduc\nACEs    1.0000000  0.3411429 -0.2399357\nSTRESS  0.3411429  1.0000000 -0.2105974\nMeduc  -0.2399357 -0.2105974  1.0000000\n\n\n\nComputed Correlation Matrix\nThe table below presents Pearson correlation coefficients between ACEs (Adverse Childhood Experiences), STRESS (Stress During Pregnancy), and Meduc (Maternal Education Level). Each correlation value ranges from -1 to 1.\nBelow is the Pearson correlation matrix for the selected variables:\n\n\n\nVariable\nACEs\nSTRESS\nMeduc\n\n\n\n\nACEs\n1.00\n0.341\n-0.239\n\n\nSTRESS\n0.341\n1.00\n-0.210\n\n\nMeduc\n-0.239\n-0.210\n1.00\n\n\n\nInterpretation of Results:\n\nACEs and STRESS ( r = 0.341 ):\n\n\nThere is a moderate positive correlation between adverse childhood experiences and stress during pregnancy.\nThis suggests that individuals who report more childhood adversity tend to experience higher stress levels during pregnancy.\n\n\nACEs and Meduc ( r = -0.239 ):\n\n\nThere is a moderate negative correlation between ACEs and maternal education.\nThis indicates that individuals with higher levels of childhood adversity tend to have lower levels of educational attainment.\n\n\nSTRESS and Meduc ( r = -0.210 ):\n\n\nA moderate negative correlation exists between stress and maternal education.\nThis suggests that individuals with lower educational attainment tend to experience higher stress levels during pregnancy.\n\n\n\nSummary & Implications\nWomen with more Adverse Childhood Experiences (ACEs) tend to experience higher levels of stress during pregnancy and have lower education levels. Higher maternal education is linked to lower stress, potentially due to greater access to resources, stability, or support systems. This is important. When interpreting results, it is very important to go back to the original operationalization of the variables so we are on the same page. How is stress defined here? And, what may be some limitations both methodologicall and conceptually? Whereas we know this analysis is not causal, we can begin linking the results to some important policy implications See Barboza-Salerno (2020) here .",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#compute-partial-and-semi-partial-correlations",
    "href": "PRAMS_Correlation_Analysis.html#compute-partial-and-semi-partial-correlations",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Compute Partial and Semi-Partial Correlations",
    "text": "Compute Partial and Semi-Partial Correlations\n\n# Compute Partial Correlation (controlling for ACEs)\npartial_corr &lt;- pcor(data_subset)\nprint(\"Partial Correlation Matrix:\")\n\n[1] \"Partial Correlation Matrix:\"\n\nprint(partial_corr$estimate)\n\n             ACEs     STRESS      Meduc\nACEs    1.0000000  0.3062254 -0.1829213\nSTRESS  0.3062254  1.0000000 -0.1410824\nMeduc  -0.1829213 -0.1410824  1.0000000\n\n# Compute Semi-Partial Correlation (controlling for ACEs only in STRESS)\nsemi_partial_corr &lt;- spcor(data_subset)\nprint(\"Semi-Partial Correlation Matrix:\")\n\n[1] \"Semi-Partial Correlation Matrix:\"\n\nprint(semi_partial_corr$estimate)\n\n             ACEs     STRESS      Meduc\nACEs    1.0000000  0.2972802 -0.1719481\nSTRESS  0.2993577  1.0000000 -0.1326190\nMeduc  -0.1788189 -0.1369612  1.0000000",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#correlation-analysis",
    "href": "PRAMS_Correlation_Analysis.html#correlation-analysis",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Correlation Analysis",
    "text": "Correlation Analysis\nWe computed three types of correlation matrices:\n\nZero-Order (Regular) Correlation: The direct correlation between variables.\nPartial Correlation: The correlation between two variables while controlling for a third variable (Meduc).\nSemi-Partial Correlation: The correlation between two variables while controlling for a third variable’s influence on just one of them.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#results-and-interpretation",
    "href": "PRAMS_Correlation_Analysis.html#results-and-interpretation",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Results and Interpretation",
    "text": "Results and Interpretation\n\nRegular (Zero-Order) Correlation from above\n\n\n\nVariable\nACEs\nSTRESS\nMeduc\n\n\n\n\nACEs\n1.00\n0.341\n-0.239\n\n\nSTRESS\n0.341\n1.00\n-0.210\n\n\nMeduc\n-0.239\n-0.210\n1.00\n\n\n\n\nACEs and STRESS: ( r = 0.341 ) → A moderate positive correlation, indicating that individuals with higher ACEs tend to experience higher stress levels during pregnancy.\nACEs and Meduc: ( r = -0.239 ) → A negative correlation, suggesting that individuals with more childhood adversity tend to have lower educational attainment.\nSTRESS and Meduc: ( r = -0.210 ) → A negative correlation, implying that lower maternal education is linked to higher stress.\n\n\n\n\nPartial Correlation\n\n\n\nVariable\nACEs\nSTRESS\nMeduc\n\n\n\n\nACEs\n1.00\n0.306\n-0.182\n\n\nSTRESS\n0.306\n1.00\n-0.141\n\n\nMeduc\n-0.182\n-0.141\n1.00\n\n\n\n\nACEs and STRESS controlling (partialing out) Meduc: ( r = 0.306 ) → The correlation remains positive but slightly decreases compared to the zero-order correlation ( r = 0.341 ), indicating that while education partly explains the relationship, ACEs still have a significant effect on stress.\nACEs and Meduc controlling ACEs: ( r = -0.182 ) → The correlation between ACEs and education weakens slightly after controlling for stress.\nSTRESS and Meduc controlling for STRESS: ( r = -0.141 ) → The relationship between stress and education is weaker when controlling for ACEs.\n\n\n\nImplication of Partial Correlation\nBy controlling for maternal education, we isolate the direct effect of ACEs on stress. The reduction in correlation values suggests that education contributes to stress, but ACEs continue to have a strong independent effect.\n\n\n\nSemi-Partial Correlation (Controlling for Meduc Only in STRESS)\n\n\n\nVariable\nACEs\nSTRESS\nMeduc\n\n\n\n\nACEs\n1.00\n0.297\n-0.171\n\n\nSTRESS\n0.299\n1.00\n-0.132\n\n\nMeduc\n-0.178\n-0.136\n1.00\n\n\n\n\nACEs and STRESS: ( r = 0.297 ) → A slight decrease in the strength of the relationship compared to the partial correlation (( r = 0.306 )), meaning that education explains a small part of the ACEs-stress relationship. In other words, it’s the correlation between ACEs and the part of STRESS that is independent of Meduc.\nACEs and Meduc: ( r = -0.171 ) → The correlation weakens slightly after accounting for stress.\nSTRESS and Meduc: ( r = -0.132 ) → A marginal decrease in the strength of the relationship.\n\n\n\nImplication of Semi-Partial Correlation\nThe semi-partial correlations examine how each independent variable uniquely contributes to the dependent variable while removing the effect of the control variable only from the dependent variable. Since the values remain similar to the partial correlations, this suggests that maternal education influences stress, but ACEs still have an independent impact.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#key-takeaways",
    "href": "PRAMS_Correlation_Analysis.html#key-takeaways",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nACEs are a strong predictor of stress during pregnancy, even after controlling for maternal education.\nMaternal education partially explains the relationship between ACEs and stress, but ACEs continue to have an independent effect.\nHigher maternal education is associated with lower stress, but its effect is weaker when ACEs are accounted for.\nThe semi-partial correlation results confirm that maternal education plays a role, but ACEs have an independent impact on stress, highlighting the importance of addressing childhood adversity in maternal mental health interventions.\n\nThese results suggest that public health interventions should target both early-life adversity (ACEs) and educational opportunities to reduce stress during pregnancy, which may have long-term effects on maternal and child health outcomes.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "PRAMS_Correlation_Analysis.html#conclusion",
    "href": "PRAMS_Correlation_Analysis.html#conclusion",
    "title": "Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis demonstrates how Maternal Education, Stress During Pregnancy, and ACEs interact within a structured correlation framework. Using partial and semi-partial correlations, we disentangle the direct and indirect effects of early-life adversity on maternal stress, providing insights for interventions aimed at reducing stress-related health disparities. If ACEs remains a significant predictor of stress after controlling for education, interventions targeting early life adversity may help alleviate psychosocial stress during pregnancy, improving both maternal and child health outcomes.\n\n\n\n\nBarboza-Salerno, G. E. (2020). Cognitive readiness to parent, stability and change in postpartum parenting stress and social-emotional problems in early childhood: A second order growth curve model. Children and Youth Services Review, 113, 104958.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Partial and Semi-Partial Correlation Analysis with PRAMS 8 Data</span>"
    ]
  },
  {
    "objectID": "cohensd.html",
    "href": "cohensd.html",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "",
    "text": "Introduction\nThis analysis examines the Area Deprivation Index (ADI) across U.S. counties. The goal is to assess disparities between areas of high- and low-deprivation (by county) and quantify the effect size using Cohen’s d.\nThe ADI provides a measure of socioeconomic disadvantage, with higher values indicating greater deprivation. We also map ADI values across counties and exclude non-contiguous U.S. states and territories.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#data-collection-preparation",
    "href": "cohensd.html#data-collection-preparation",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "Data Collection & Preparation",
    "text": "Data Collection & Preparation\n\n# Install and load required packages\n# install.packages(\"sociome\")\n# install.packages(\"ggplot2\")\n# install.packages(\"dplyr\")\n# install.packages(\"sf\")\n# install.packages(\"tigris\")\n# install.packages(\"effectsize\")\n\nlibrary(sociome)     # For ADI data\nlibrary(ggplot2)     # For visualization\nlibrary(dplyr)       # For data manipulation\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(sf)          # For mapping spatial data\n\nLinking to GEOS 3.11.2, GDAL 3.7.2, PROJ 9.3.0; sf_use_s2() is TRUE\n\nlibrary(tigris)      # For county boundaries\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nlibrary(effectsize)  # For Cohen's d calculation\n\nWarning: package 'effectsize' was built under R version 4.3.3\n\n\nWe first retrieve the ADI data for 2020 at the county level.\n\n# --- Step 1: Get ADI Data by County ---\nadi_data &lt;- get_adi(year = 2020, geography = \"county\")\n\n# Extract GEOID, county name, and ADI\nadi_data &lt;- adi_data %&gt;%\n  dplyr::select(GEOID, NAME, ADI)\n\n\nExcluding Non-Contiguous U.S. States and Territories\nTo focus on the contiguous U.S., we exclude: - Alaska (02) & Hawaii (15) - U.S. territories: Puerto Rico, Guam, American Samoa, Northern Mariana Islands, U.S. Virgin Islands.\n\n# List of FIPS codes for non-contiguous states/territories\nnon_contiguous_fips &lt;- c(\"02\", \"15\", \"60\", \"66\", \"69\", \"72\", \"78\")  \n\n# Load county boundaries and exclude non-contiguous areas\ncounties &lt;- counties(cb = TRUE, resolution = \"20m\", year = 2020) %&gt;%\n  filter(!STATEFP %in% non_contiguous_fips)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |=================================                                     |  46%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |======================================================================| 100%\n\n# Merge ADI data with county geometries\nadi_map_data &lt;- counties %&gt;%\n  left_join(adi_data, by = c(\"GEOID\" = \"GEOID\"))",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#mapping-adi-by-county",
    "href": "cohensd.html#mapping-adi-by-county",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "Mapping ADI by County",
    "text": "Mapping ADI by County\nThe following map visualizes area deprivation across the contiguous U.S.. Darker areas represent higher deprivation levels.\nYou should play around with ggplot to get used to its functionality.\n\nlibrary(ggplot2)\nggplot(adi_map_data) +\n  geom_sf(aes(fill = ADI), color = NA) +\n  scale_fill_viridis_c(option = \"plasma\", name = \"ADI\") +\n  labs(\n    title = \"Area Deprivation by County (Contiguous U.S., ADI Data 2020)\",\n    subtitle = \"Excludes Alaska, Hawaii, & U.S. Territories\",\n    caption = \"Source: Sociome package ADI 2020\"\n  ) +\n  theme_void()",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#adi-disparities-effect-size-cohens-d",
    "href": "cohensd.html#adi-disparities-effect-size-cohens-d",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "ADI Disparities & Effect Size (Cohen’s d)",
    "text": "ADI Disparities & Effect Size (Cohen’s d)\nWe divide counties into low-deprivation (least disadvantaged, bottom 25%) and high-deprivation (most disadvantaged, top 25%) groups. The income differences between these groups are quantified using Cohen’s d, a measure of standardized effect size.\n\n# Define thresholds: Top 25% (most deprived) vs. Bottom 25% (least deprived)\nquantiles &lt;- quantile(adi_data$ADI, probs = c(0.25, 0.75), na.rm = TRUE)\nlow_deprivation &lt;- adi_data %&gt;% filter(ADI &lt;= quantiles[1])\nhigh_deprivation &lt;- adi_data %&gt;% filter(ADI &gt;= quantiles[2])\n\n# Compute Cohen's d\ncohens_d_value &lt;- cohens_d(high_deprivation$ADI, low_deprivation$ADI)\n\n# Print Cohen's d result\nprint(cohens_d_value)",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#interpretation-of-cohens-d-results",
    "href": "cohensd.html#interpretation-of-cohens-d-results",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "Interpretation of Cohen’s d Results",
    "text": "Interpretation of Cohen’s d Results\nCohen’s d tells us how large the difference in ADI between low- and high-deprivation counties:\n\n( d = 0.2 ) → Small effect\n( d = 0.5 ) → Medium effect\n( d = 0.8+ ) → Large effect\n\nIf the result is negative, it means that high-deprivation counties have significantly higher ADI scores than low-deprivation counties. The absolute value of d still represents the effect size.\n\nKey Findings\n🔹 A large Cohen’s d suggests significant deprivation disparities between counties with low and high deprivation.\n🔹 This reinforces the need for economic policies addressing regional deprivation.\n🔹 Mapping ADI allows for geographically targeted interventions to reduce socioeconomic inequalities.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "cohensd.html#conclusion",
    "href": "cohensd.html#conclusion",
    "title": "Analysis of Area Deprivation Disparities Using Cohen’s D",
    "section": "Conclusion",
    "text": "Conclusion\nThe effect size tells us that the ADI in low-deprivation counties is 3.39 standard deviations higher than in high-deprivation counties. Since Cohen’s d is standardized, this means the deprivation difference is very large in relative terms. This analysis confirms that county-level deprivation is strongly associated with huge disparities in ADI, with high-deprivation counties having more economic inequaltity, low educational attainment, and less financial strength. Future research could associate some outcome across levels of ADI.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Analysis of Area Deprivation Disparities Using Cohen's D</span>"
    ]
  },
  {
    "objectID": "admissions_R_ex.html",
    "href": "admissions_R_ex.html",
    "title": "Admissions Data Analysis",
    "section": "",
    "text": "Introduction\nThis code analyzes admissions data, focusing on predicting SAT Math scores using SAT Verbal scores and high school class size. The analysis employs linear regression models, including simple linear regression, multiple linear regression, correlation assessments, and visualizations to explore the relationships between these variables.\nHere is the admissions data and you can download the script to run in R here\n\n\nLoad Necessary Libraries\n\nlibrary(foreign)    # For reading .sav files\nlibrary(ggplot2)    # For visualization\nlibrary(dplyr)      # For data manipulation\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(gtsummary)  # For creating regression tables\nlibrary(officer)    # For exporting to Word\nlibrary(flextable)  # For table formatting\n\n\nAttaching package: 'flextable'\n\n\nThe following object is masked from 'package:gtsummary':\n\n    continuous_summary\n\n\n\n\nLoad and Inspect Data\n\nadmissions &lt;- read.spss(\"data/admissions.sav\", to.data.frame = TRUE)\nhead(admissions) # Display first few rows\n\n  row_number paiddeposit scholarship_yes_no Type_of_scholarship_offered Female\n1          7           1                  0                                  0\n2         12           0                  0                                  0\n3         19           1                  0                                  0\n4         23           1                  0                                  0\n5         25           0                  0                                  0\n6         28           0                  0                                  1\n             Race HS_rank HS_class_size HS_Quintile HS_CODE\n1 white               190           281        4/5   392835\n2 white               111           223        3/5   393655\n3 white               109           371        2/5    51830\n4 Asian                88           266        2/5   390527\n5 white                NA            NA              390870\n6 white                59           382        1/5   392655\n                  HS_NAME SAT_verbal ACT Honors_college_eligible\n1 FRANKLIN_REGIONAL_SR_HI        560  NA                     no \n2 CENTRAL_CATHOLIC_HIGH_S        600  NA                     no \n3 WESTCHESTER_HIGH_SCHOOL        550  NA                     no \n4 CEDAR_CLIFF_HIGH_SCHOOL        520  NA                     no \n5 HOLY_GHOST_PREPARATORY         650  NA                     no \n6 PENN_MANOR_HIGH_SCHOOL         460  20                     no \n  distancefromPitt state Number_of_family_alumni father_alumni grand_alumni\n1        14.228946    PA                       0             0            0\n2         7.162134    PA                       0             0            0\n3       232.363382    PA                       0             0            0\n4       163.462296    PA                       0             0            0\n5       261.534151    PA                       0             0            0\n6       192.493359    PA                       0             0            0\n  mother_alumni sibling_alumni step_parent_alumni other_family_alumni\n1             0              0                  0                   0\n2             0              0                  0                   0\n3             0              0                  0                   0\n4             0              0                  0                   0\n5             0              0                  0                   0\n6             0              0                  0                   0\n  SAT_composite ACT_as_SAT Max_Test_Score Training from_PA\n1          1180         NA           1180        0       1\n2          1150         NA           1150        0       1\n3          1190         NA           1190        0       1\n4          1140         NA           1140        0       1\n5          1200         NA           1200        0       1\n6           940        950            950        0       1\n               alumniYN SAT_math\n1 Family is not an alum      620\n2 Family is not an alum      550\n3 Family is not an alum      640\n4 Family is not an alum      620\n5 Family is not an alum      550\n6 Family is not an alum      480\n\n\n\n\nData Preprocessing\n\nadmissions_clean &lt;- admissions %&gt;% \n  dplyr::select(SAT_math, SAT_verbal, HS_class_size) %&gt;% \n  na.omit()\n\n\n\nSimple Linear Regression: SAT Math ~ SAT Verbal\n\nsimple_model &lt;- lm(SAT_math ~ SAT_verbal, data = admissions_clean)\nsummary(simple_model) # Regression summary\n\n\nCall:\nlm(formula = SAT_math ~ SAT_verbal, data = admissions_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-168.125  -43.568   -1.667   41.119  188.462 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 329.24934   19.49133   16.89   &lt;2e-16 ***\nSAT_verbal    0.45572    0.03448   13.22   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61.42 on 689 degrees of freedom\nMultiple R-squared:  0.2023,    Adjusted R-squared:  0.2011 \nF-statistic: 174.7 on 1 and 689 DF,  p-value: &lt; 2.2e-16\n\n\n\nInterpretation:\n\nSAT Verbal has a positive effect on SAT Math scores (Estimate = 0.45572, p &lt; 0.001).\nModel explains ~20.2% of variance in SAT Math scores (Adjusted R² = 0.2011), meaning SAT Verbal alone is a moderate predictor.\nResiduals appear reasonably distributed, suggesting no major violations of normality assumptions.\n\n\n\n\nCompute Fitted Values and Residuals\n\nadmissions_clean$fitted_simple &lt;- fitted(simple_model)\nadmissions_clean$residuals_simple &lt;- residuals(simple_model)\n\n\n\nCompute Standardized Values\n\nadmissions_clean$std_fitted_simple &lt;- scale(admissions_clean$fitted_simple)\nadmissions_clean$std_residuals_simple &lt;- scale(admissions_clean$residuals_simple)\n\n\n\nVisualization: Residuals vs. Fitted\n\nggplot(admissions_clean, aes(x = std_fitted_simple, y = std_residuals_simple)) +\n  geom_point(color = \"blue\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Standardized Residuals vs. Standardized Fitted Values (Simple Model)\",\n       x = \"Standardized Fitted Values\", y = \"Standardized Residuals\")\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nResiduals are fairly symmetrically distributed around zero, suggesting the linear model is appropriate.\nNo major patterns in residuals indicate homoscedasticity.\n\n\n\n\nHistogram of Residuals\n\nggplot(admissions_clean, aes(x = residuals_simple)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals (Simple Model)\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nResiduals follow a normal-like distribution, supporting the assumption of normality.\n\n\n\n\nCorrelation Analysis\n\ncor(admissions_clean[, c(\"SAT_math\", \"SAT_verbal\", \"fitted_simple\", \"residuals_simple\")], use = \"complete.obs\")\n\n                  SAT_math    SAT_verbal fitted_simple residuals_simple\nSAT_math         1.0000000  4.497305e-01  4.497305e-01     8.931643e-01\nSAT_verbal       0.4497305  1.000000e+00  1.000000e+00    -5.014076e-16\nfitted_simple    0.4497305  1.000000e+00  1.000000e+00    -1.828283e-15\nresiduals_simple 0.8931643 -5.014076e-16 -1.828283e-15     1.000000e+00\n\n\n\nInterpretation:\n\nStrong positive correlation between SAT Math and SAT Verbal (r ≈ 0.45).\nFitted values highly correlate with SAT Verbal, confirming its predictive power.\n\n\n\n\nMultiple Linear Regression: SAT Math ~ SAT Verbal + HS Class Size\n\nmultiple_model &lt;- lm(SAT_math ~ SAT_verbal + HS_class_size, data = admissions_clean)\nsummary(multiple_model)\n\n\nCall:\nlm(formula = SAT_math ~ SAT_verbal + HS_class_size, data = admissions_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-165.924  -44.589   -1.418   40.825  197.261 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   314.14654   19.47735  16.129  &lt; 2e-16 ***\nSAT_verbal      0.44864    0.03401  13.192  &lt; 2e-16 ***\nHS_class_size   0.06030    0.01295   4.656 3.88e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 60.52 on 688 degrees of freedom\nMultiple R-squared:  0.2266,    Adjusted R-squared:  0.2244 \nF-statistic: 100.8 on 2 and 688 DF,  p-value: &lt; 2.2e-16\n\n\n\nInterpretation:\n\nHS Class Size has a small but significant positive effect (Estimate = 0.06030, p &lt; 0.001).\nExplained variance increases to 22.4%, showing a slight improvement over the simple model.\n\n\n\n\nVisualization of SAT Verbal Effect\n\nggplot(admissions_clean, aes(x = SAT_verbal, y = SAT_math)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", col = \"blue\") +\n  labs(title = \"Effect of SAT Verbal on SAT Math\", x = \"SAT Verbal\", y = \"SAT Math\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nGenerate Regression Summary Table\n\nmlr_table &lt;- multiple_model %&gt;% \n  tbl_regression(label = list(SAT_verbal = \"SAT Verbal Score\", HS_class_size = \"High School Class Size\")) %&gt;%\n  modify_caption(\"Table 1: Multiple Linear Regression Results\") %&gt;%\n  add_n()\n\n\n\nSave Table to Word\n\nmlr_flextable &lt;- as_flex_table(mlr_table)\ndoc &lt;- read_docx()\ndoc &lt;- body_add_flextable(doc, value = mlr_flextable)\nprint(doc, target = \"MLR_Results.docx\")\n\n\n\nConclusion\n\nKey Findings:\n\nSAT Verbal scores significantly predict SAT Math scores, explaining ~20% of the variance.\nAdding HS Class Size improves the model slightly, raising the explained variance to 22.4%.\nBoth models suggest a linear relationship, with residuals showing normality and no major violations.\n\n\n\nImplications:\n\nSchools aiming to improve SAT Math scores may focus on strengthening verbal skills.\nClass size appears to play a small but relevant role in performance.\nFurther research could explore additional predictors (e.g., socioeconomic factors, study habits).",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Admissions Data Analysis</span>"
    ]
  },
  {
    "objectID": "nscaw.html",
    "href": "nscaw.html",
    "title": "NSCAW I In-Class Exercise",
    "section": "",
    "text": "Introduction\nThis exercise explores child aggression and trauma using the NSCAW I dataset. Because this is designed for you to do, I supressed all of the output. The chunks of code give you a hints regarding the code that will answer each question. Create an R script and answer each question below. Cut and paste the chunk of code into your script, and fill it in so that it runs.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-1-load-the-data",
    "href": "nscaw.html#step-1-load-the-data",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 1: Load the Data",
    "text": "Step 1: Load the Data\nMake sure all of these libraries are installed or you will not be able to run the code. Also, make sure that your data set is in a subdirectory called data in the same directory as the one in which your R script is saved.\n\n# Load necessary libraries\nlibrary(foreign)    # For reading SPSS files\nlibrary(dplyr)      # For data manipulation\nlibrary(ggplot2)    # For visualization\nlibrary(gtsummary)  # For creating regression tables\nlibrary(officer)    # For exporting tables to Word\nlibrary(flextable)  # For table formatting\n\n# Load NSCAW I dataset\nnscaw &lt;- read.spss(\"data/nscaw.sav\", to.data.frame = TRUE)\n\n# Inspect the first few rows\nhead(nscaw)\n\nQuestion: What type of variables are included in the dataset?\nTo get a sense of the variables in the dataset click here.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-2-select-variables-handle-missing-data",
    "href": "nscaw.html#step-2-select-variables-handle-missing-data",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 2: Select Variables & Handle Missing Data",
    "text": "Step 2: Select Variables & Handle Missing Data\n\n# Select relevant variables\nnscaw_clean &lt;- nscaw %&gt;% \n  dplyr::select(FILL THE VARIABLES IN HERE) \n\n# Remove missing values\nnscaw_clean &lt;- na.omit(nscaw_clean)\n\n# View summary statistics\nsummary(nscaw_clean)\n\nHint: Look at the summary statistics—do any variables have extreme values?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-3-compute-correlations",
    "href": "nscaw.html#step-3-compute-correlations",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 3: Compute Correlations",
    "text": "Step 3: Compute Correlations\n\n# Compute correlation matrix\ncor(nscaw_clean, use = \"complete.obs\")\n\nQuestion: Which variables are most strongly correlated? Does the direction make sense?\n\nRun the regression of child aggression on trauma score and age",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-4-run-a-multiple-regression-model",
    "href": "nscaw.html#step-4-run-a-multiple-regression-model",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 4: Run a Multiple Regression Model",
    "text": "Step 4: Run a Multiple Regression Model\n\n# Run regression: Predict aggression using trauma score and age\nreg_model &lt;- lm(WRITE THE CODE TO RUN THE REGRESSION)\n\n# Display model summary\nsummary(reg_model)\n\nHint: Examine the coefficients and p-values. Is trauma a significant predictor of aggression?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-5-compute-fitted-values-residuals",
    "href": "nscaw.html#step-5-compute-fitted-values-residuals",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 5: Compute Fitted Values & Residuals",
    "text": "Step 5: Compute Fitted Values & Residuals\n\n# Compute fitted values and residuals\nnscaw_clean$fitted &lt;- fitted(PROVIDE THE CODE HERE)\nnscaw_clean$residuals &lt;- residuals(reg_model)\n\n# Compute standardized residuals\nnscaw_clean$std_residuals &lt;- PROVIDE THE CODE HERE(nscaw_clean$residuals)\n\nQuestion: Why do we standardize residuals? What does this help us understand?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-6-visualize-residuals",
    "href": "nscaw.html#step-6-visualize-residuals",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 6: Visualize Residuals",
    "text": "Step 6: Visualize Residuals\n\n# Plot histogram of residuals\nggplot(nscaw_clean, aes(x = residuals)) +\n  PROVIDE THE CODE HERE(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\nHint: Look for skewness—are residuals normally distributed?\n\n\n# Plot standardized residuals vs. predicted values\nggplot(nscaw_clean, aes(x = fitted, y = std_residuals)) +\n  geom_point(PROVIDE THE CODE HERE) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(PROVIDE THE CODE HERE)\n\nHint: If you see patterns in the residuals, what assumption may be violated?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#step-7-create-export-regression-table",
    "href": "nscaw.html#step-7-create-export-regression-table",
    "title": "NSCAW I In-Class Exercise",
    "section": "Step 7: Create & Export Regression Table",
    "text": "Step 7: Create & Export Regression Table\n\n# Generate regression summary table\nreg_table &lt;- reg_model %&gt;% \n  tbl_regression(\n    label = list(tra1 = \"PTS Score\", bcagg1 = \"Aggressive Behavior\", ageY = \"Age\")\n  ) %&gt;% \n  modify_caption(\"Table 1: Regression Results for Aggression\")\n\n# Convert to flextable and export to Word\nreg_flextable &lt;- as_flex_table(reg_table)\ndoc &lt;- read_docx()\ndoc &lt;- body_add_flextable(doc, value = reg_flextable)\nprint(doc, target = \"Regression_Results.docx\")\n\nHint: Where does the p-value appear in the regression table? How does it inform significance?",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#deliverables",
    "href": "nscaw.html#deliverables",
    "title": "NSCAW I In-Class Exercise",
    "section": "Deliverables",
    "text": "Deliverables\nDiscuss the following:\n\nCorrelation matrix output\nRegression model summary\nHistogram of residuals\nResiduals vs. fitted plot\nRegression results table (Word document)",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "nscaw.html#discussion-questions",
    "href": "nscaw.html#discussion-questions",
    "title": "NSCAW I In-Class Exercise",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nBased on your results, does trauma significantly predict aggression?\nHow does child age influence the relationship between trauma and aggression?\nAre the residuals normally distributed? If not, what would you do differently?\nIf the p-value for trauma is significant, what does that imply in real-world terms?\nHow could you improve this model?\n\nFinal Thought: This exercise helps you develop a deeper understanding of how trauma influences child behavior. Future analyses could incorporate more variables (e.g., social support, environment) for better predictions.",
    "crumbs": [
      "**Case Studies & Data Applications**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>NSCAW I In-Class Exercise</span>"
    ]
  },
  {
    "objectID": "reading.html",
    "href": "reading.html",
    "title": "Required Course Materials",
    "section": "",
    "text": "Required Texts",
    "crumbs": [
      "**Additional Resources**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Required Course Materials</span>"
    ]
  },
  {
    "objectID": "reading.html#required-software",
    "href": "reading.html#required-software",
    "title": "Required Course Materials",
    "section": "Required Software",
    "text": "Required Software\n\nOpen Source Software\n\nJASP (Just Another Statistics Program)\n\nWe will use JASP to perform some analyses that SPSS does not. JASP is free, open source software available for both Mac, Linux and Windows platforms. To download this software please visit https://jasp-stats.org/download\n\n\n\nProcess for SPSS\n\nAn SPSS macro that runs dozens of mediation, moderation and conditional process models written by Andrew Hayes. Download the macro here https://www.processmacro.org/download.html and follow the installation instructions.\n\n\n\n\nProprietary\n\nSPSS",
    "crumbs": [
      "**Additional Resources**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Required Course Materials</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Reading List",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "references.html#reading-list",
    "href": "references.html#reading-list",
    "title": "References",
    "section": "",
    "text": "Linear Regression\n\nThis paper Razak (2019) provides an example of Simple Linear Regression.\nThis paper Littleton et al. (2024) provides an example of using Historic Redlining Scores to understand higher rates of child welfare reporting.\nPenn State has a nice tutorial with examples on how to conduct linear regression in R\n\n\n\nLogistic Regression\n\nThis paper uses the glm function to model the presence of fictional fantastic characters Corlatti (2021). Super cool.\nWhile we do not cover it here, this paper explains how to use multilevel modeling with a categorical dependent variable: Merlo et al. (2006).\nA recent co-authored manuscript used logistic regression, you can read it: Meshelemiah et al. (2024)\n\n\n\nMediation and Moderation\n\nThis paper Livingston & Haardörfer (2019) should be read together with Glick et al. (2019).\nThis paper is a tutorial on how to use the SPSS PROCESS macro by Hayes Clement & Bradley-Garcia (2022)\nI have used moderation and mediation in several papers, here is one example: Barboza-Salerno & Meshelemiah (2024)\n\n\n\nFactor Analysis\n\nThis paper has some cool visualizations: Štiglic et al. (2023) and I downloaded it here\nI have used factor analytic techniques in many papers, here is one example: Elise Barboza & Siller (2021)\n\n\n\nPower Analysis\nThis paper is good to follow if you need to calculate power for causal models Qin (2023)\n\n\nDummy Variable Coding\nThis paper is a must read Johfre & Freese (2021)\n\n\nSocial Justice Applications",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "references.html#while-not-directly-stating-it-in-this-paper-barboza2020cognitive-i-found-increases-in-post-partum-parenting-stress-is-linked-to-poor-socio-emotional-adjustment-in-children.-my-examination-of-the-prams-data-set-suggests-that-psychosocial-stressors-during-pregnancy-a-vulnerable-period-for-many-increases-the-risk-of-intimate-partner-violence.",
    "href": "references.html#while-not-directly-stating-it-in-this-paper-barboza2020cognitive-i-found-increases-in-post-partum-parenting-stress-is-linked-to-poor-socio-emotional-adjustment-in-children.-my-examination-of-the-prams-data-set-suggests-that-psychosocial-stressors-during-pregnancy-a-vulnerable-period-for-many-increases-the-risk-of-intimate-partner-violence.",
    "title": "References",
    "section": "While not directly stating it, in this paper Barboza-Salerno (2020) I found increases in post-partum parenting stress is linked to poor socio-emotional adjustment in children. My examination of the PRAMS data set suggests that psychosocial stressors during pregnancy, a vulnerable period for many, increases the risk of intimate partner violence.",
    "text": "While not directly stating it, in this paper Barboza-Salerno (2020) I found increases in post-partum parenting stress is linked to poor socio-emotional adjustment in children. My examination of the PRAMS data set suggests that psychosocial stressors during pregnancy, a vulnerable period for many, increases the risk of intimate partner violence.\n\n\n\n\nBarboza-Salerno, G. E. (2020). Cognitive readiness to parent, stability and change in postpartum parenting stress and social-emotional problems in early childhood: A second order growth curve model. Children and Youth Services Review, 113, 104958.\n\n\nBarboza-Salerno, G. E., & Meshelemiah, J. C. (2024). Associations between early child adversity and lifetime suicide attempts among gender diverse individuals: A moderated mediation. Child Abuse & Neglect, 149, 106705.\n\n\nClement, L. M., & Bradley-Garcia, M. (2022). A step-by-step tutorial for performing a moderated mediation analysis using PROCESS. The Quantitative Methods for Psychology, 18(3), 258–271.\n\n\nCorlatti, L. (2021). Regression Models, Fantastic Beasts, and Where to Find Them: A Simple Tutorial for Ecologists Using R. Bioinformatics and Biology Insights, 15, 11779322211051522. https://doi.org/10.1177/11779322211051522Regression modeling is a workhorse of statistical ecology that allows to find relationships between a response variable and a set of explanatory variables. Despite being one of the fundamental statistical ideas in ecological curricula, regression modeling can be complex and subtle. This paper is intended as an applied protocol to help students understand the data, select the most appropriate models, verify assumptions, and interpret the output. Basic ecological questions are tackled using data from a fictional series, ?Fantastic beasts and where to find them,? with the aim to show how statistical thinking can foster curiosity, creativity and imagination in ecology, from the formulation of hypotheses to the interpretation of results.\n\n\nElise Barboza, G., & Siller, L. A. (2021). Child maltreatment, school bonds, and adult violence: A serial mediation model. Journal of Interpersonal Violence, 36(11-12), NP5839–NP5873.\n\n\nGlick, A. F., Farkas, J. S., Mendelsohn, A. L., Fierman, A. H., Tomopoulos, S., Rosenberg, R. E., Dreyer, B. P., Melgar, J., Varriano, J., & Yin, H. S. (2019). Discharge Instruction Comprehension and Adherence Errors: Interrelationship Between Plan Complexity and Parent Health Literacy. The Journal of Pediatrics, 214, 193–200.e3. https://doi.org/10.1016/j.jpeds.2019.04.052Objective To examine associations between parent health literacy, discharge plan complexity, and parent comprehension of and adherence to inpatient discharge instructions. Study design This was a prospective cohort study of English/Spanish-speaking parents (n = 165) of children \\(\\leq\\)12 years discharged on \\(\\geq\\)1 daily medication from an urban, public hospital. Outcome variables were parent comprehension (survey) of and adherence (survey, in-person dosing assessment, chart review) to discharge instructions. Predictor variables included low parent health literacy (Newest Vital Sign score 0-3) and plan complexity. Generalized estimating equations were used to account for the assessment of multiple types of comprehension and adherence errors for each subject, adjusting for ethnicity, language, child age, length of stay, and chronic disease status. Similar analyses were performed to assess for mediation and moderation. Results Error rates were highest for comprehension of medication side effects (50%), adherence to medication dose (34%), and return precaution (78%) instructions. Comprehension errors were associated with adherence errors (aOR, 8.7; 95% CI, 5.9-12.9). Discharge plan complexity was associated with comprehension (aOR, 7.0; 95% CI, 5.4-9.1) and adherence (aOR, 5.5; 95% CI, 4.0-7.6) errors. Low health literacy was indirectly associated with adherence errors through comprehension errors. The association between plan complexity and comprehension errors was greater in parents with low (aOR, 8.3; 95% CI, 6.2-11.2) compared with adequate (aOR, 3.8; 95% CI, 2.2-6.5) health literacy (interaction term P = .004). Conclusions Parent health literacy and discharge plan complexity play key roles in comprehension and adherence errors. Future work will focus on the development of health literacy-informed interventions to promote discharge plan comprehension.\n\n\nJohfre, S. S., & Freese, J. (2021). Reconsidering the reference category. Sociological Methodology, 51(2), 253–269.\n\n\nLittleton, T., Freisthler, B., Boyd, R., Smith, A. M., & Barboza-Salerno, G. (2024). Historical redlining, neighborhood disadvantage, and reports of child maltreatment in a large urban county. Child Abuse & Neglect, 156, 107011.\n\n\nLivingston, M. D., & Haardörfer, R. (2019). A gentle introduction to mediation and moderation. The Journal of Pediatrics, 214, 246–248.\n\n\nMerlo, J., Chaix, B., Ohlsson, H., Beckman, A., Johnell, K., Hjerpe, P., Råstam, L., & Larsen, K. (2006). A brief conceptual tutorial of multilevel analysis in social epidemiology: Using measures of clustering in multilevel logistic regression to investigate contextual phenomena. Journal of Epidemiology & Community Health, 60(4), 290–297.\n\n\nMeshelemiah, J. C., Dellor, E., Karandikar, S., Munshi, A., Barboza-Salerno, G., & Steinke, H. R. (2024). Adverse childhood experiences, women who are sex trafficked, and social service utilization: Implications for social work. Social Work, swae024.\n\n\nQin, X. (2023). Sample size and power calculations for causal mediation analysis: A Tutorial and Shiny App. Behavior Research Methods, 56(3), 1738–1769. https://doi.org/10.3758/s13428-023-02118-0\n\n\nRazak, M. R. R. (2019). Child social welfare institution participation in the implementation of good governance.\n\n\nŠtiglic, G., Budler, L. C., & Watson, R. (2023). 15 running a confirmatory factor analysis in r: A step-by-step tutorial. In K. Č. Trifkovič, M. Lorber, N. M. Reljić, & G. Štiglic (Eds.), Education and research (pp. 207–222). De Gruyter. https://doi.org/doi:10.1515/9783110786088-015",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "ass1writeup.html",
    "href": "ass1writeup.html",
    "title": "Assignment 1 Write-up",
    "section": "",
    "text": "Dataset: Pregnancy Risk Assessment Monitoring System (PRAMS)\nThe data for this study were drawn from the Kentucky Pregnancy Risk Assessment Monitoring System (PRAMS), a state-based surveillance system that collects data on maternal behaviors and experiences before, during, and shortly after pregnancy. The dataset used in this study, KSPRAMS_SUB_WEIGHT_ANALYSIS.csv, included key variables such as maternal smoking during the first trimester (CIG_1TRI), history of abuse (Any_Abuse), Adverse Childhood Experiences (ACEs_Scale), perinatal depression (BPG_DEPRS8), and race/ethnicity (Race_Ethnicity). To ensure data integrity, cases with missing values were omitted, resulting in a final analytical sample of 5,172 participants.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Assignment 1 Write-up</span>"
    ]
  },
  {
    "objectID": "ass1writeup.html#bonus",
    "href": "ass1writeup.html#bonus",
    "title": "Assignment 1 Write-up",
    "section": "Bonus",
    "text": "Bonus\n\nAPHA Abstract\nThe APHA abstracts are due at the end of March. If the assumptions of this model were not violated we could submit an abstract based on these results. Here is my sample abstract (~250 words) based on the above write-up, and formatted for the conference.\n\nBackground\nMaternal smoking during pregnancy remains a significant public health concern, with implications for both maternal and child health. Psychosocial risk factors such as adverse childhood experiences (ACEs), a history of abuse, and perinatal depression may contribute to smoking behaviors. This study investigates the association between these factors and smoking during the first trimester of pregnancy while also examining racial/ethnic disparities.\n\n\nMethods\nData were drawn from the Kentucky Pregnancy Risk Assessment Monitoring System (PRAMS). The final analytical sample consisted of 5,172 participants. Linear regression models were used to examine the association between smoking during the first trimester and key psychosocial risk factors. Race/ethnicity was included to assess disparities. Diagnostic tests were performed to evaluate model assumptions, including multicollinearity, normality, and heteroscedasticity.\n\n\nResults\nA history of abuse was associated with a 2.29-unit increase in smoking (p &lt; 0.001). Each additional ACE was linked to a 0.44-unit increase (p &lt; 0.001), with a one standard deviation increase (1.41 points) predicting a 0.62-unit increase and an interquartile range increase (2 points) predicting a 0.89-unit increase. Perinatal depression was associated with a 1.04-unit increase in smoking (p &lt; 0.001). Mothers with a history of abuse smoked 1.85 more cigarettes per day than those without abuse. Hispanic mothers exhibited significantly lower smoking rates compared to Non-Hispanic Whites (p &lt; 0.001).\n\n\nConclusion\nPsychosocial factors play a crucial role in maternal smoking behaviors. Targeted interventions incorporating mental health and trauma-informed care are essential in reducing prenatal smoking rates, particularly among at-risk populations.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Assignment 1 Write-up</span>"
    ]
  },
  {
    "objectID": "assign2.html",
    "href": "assign2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Instructions\nAssignment 2 uses several datasets. Please read the instructions carefully. There are five questions. The first question asks you to perform a multiple linear regression analysis. The second question asks you to conduct a logistic regression. The third question is a latent class analysis. The fourth question is a factor analysis. And finally, a mediation, moderation, and mediated moderation (the last of which is optional).\n\n\nData\n\nQuestion 1: social2.sav\nQuestion 2: depress.sav\nQuestion 3: lca.csv\nQuestion 4: wiscsem.sav\nQuestion 5: employee.sav\n\n\n\nVideo\nAfter our review session, I will post the video here.",
    "crumbs": [
      "**Assignments**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "final.html",
    "href": "final.html",
    "title": "Final Stats II Assignment",
    "section": "",
    "text": "Instructions\nLength: 2–3 double-spaced pages (not including tables, figures, or references)\nRequired Outputs: Two tables and one figure, the following analysis detailed below\nDue Date: Monday, April 28, 2025\nSubmission: Email to barboza-salerno.1@osu.edu\nSoftware: R, SPSS, JASP, or a combination.\nExample:\nSoftware Used: R (lavaan, mclust, psych), SPSS (PROCESS macro v4.2), JASP\nFor your final 2–3 page paper, you will conduct a statistical analysis using one of the datasets we’ve worked with in class (e.g., the Pregnancy Risk Assessment Monitoring System (PRAMS), Census/American Community Survey, the Well-Being of LGB Populations, etc.) OR you may use your own dataset with prior approval. This project gives you the opportunity to demonstrate mastery of one or more multivariate statistical techniques. You must select one of the following:\nYou must include two well-formatted tables and one figure illustrating your findings.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#instructions",
    "href": "final.html#instructions",
    "title": "Final Stats II Assignment",
    "section": "",
    "text": "Multiple linear regression\nLogistic regression\nModeration\nMediation\nConditional process modeling\nFactor analysis\nLatent class analysis (LCA)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#dataset-and-variables-1-paragraph",
    "href": "final.html#dataset-and-variables-1-paragraph",
    "title": "Final Stats II Assignment",
    "section": "1. Dataset and Variables (1 paragraph)",
    "text": "1. Dataset and Variables (1 paragraph)\nDescribe the dataset and provide context—what is it, where did it come from, what does it measure, what years were the data collected? Be specific about your sample size, time frame, unit of analysis, and any relevant information. Then clearly define all variables used in your analysis, including your outcome, predictors, moderators, mediators, latent constructs, or class indicators. If you collapsed, transformed, or recoded any variables, explain why. Specify the research question, and the hypotheses you are testing.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#statistical-model-and-justification-23-paragraphs",
    "href": "final.html#statistical-model-and-justification-23-paragraphs",
    "title": "Final Stats II Assignment",
    "section": "2. Statistical Model and Justification (2–3 paragraphs)",
    "text": "2. Statistical Model and Justification (2–3 paragraphs)\nSpecify which statistical technique you used and why it fits your research question and data. If you selected a model based on the nature of your outcome (e.g., binary, continuous, or latent), explain this. Provide a conceptual diagram of your model. Also address the assumptions of your model, how you evaluated them, and any diagnostic checks performed.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#results-24-paragraphs",
    "href": "final.html#results-24-paragraphs",
    "title": "Final Stats II Assignment",
    "section": "3. Results (2–4 paragraphs)",
    "text": "3. Results (2–4 paragraphs)\nPresent your model results in a narrative that clearly communicates the key findings. Include:\n\nTable 1: Descriptive statistics (e.g., means, SDs, frequencies)\nTable 2: Model summary (e.g., regression table, factor loadings, odds ratios, or class-specific probabilities)\nFigure 1: A plot showing model results (e.g., interaction graph, path diagram, factor analysis diagram, etc.)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#interpretation-and-assumptions-1-paragraph",
    "href": "final.html#interpretation-and-assumptions-1-paragraph",
    "title": "Final Stats II Assignment",
    "section": "4. Interpretation and Assumptions (1 paragraph)",
    "text": "4. Interpretation and Assumptions (1 paragraph)\nExplain what your results mean in theoretical or applied terms. Reflect on effect sizes, statistical significance, and implications. Discuss how assumptions were met or violated, and whether transformations or adjustments were necessary.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "final.html#model-specific-guidelines",
    "href": "final.html#model-specific-guidelines",
    "title": "Final Stats II Assignment",
    "section": "Model-Specific Guidelines",
    "text": "Model-Specific Guidelines\n\nMultiple Linear Regression\nUse when your outcome is continuous. Justify your inclusion of predictors and check assumptions including linearity, homoscedasticity, and multicollinearity. Report R², adjusted R², and residual diagnostics.\n\n\nLogistic Regression\nUse when the outcome is binary. Report odds ratios, confidence intervals, and predicted probabilities. Describe how you assessed model fit (i.e., sensitivity, specificity).\n\n\nModeration\nUse when you suspect the effect of a predictor on the outcome varies by another variable. Report interaction terms and simple effects (non-interaction terms). Use plots to illustrate interaction effects like we created using Excel, or in R.\n\n\nMediation\nUse to test indirect effects. Clearly define paths. Use bootstrapped CIs for indirect effects and report estimates.\n\n\nConditional Process Modeling\nUse when a mediator and moderator interact. Identify moderated paths, report conditional indirect effects, and include a conceptual diagram.\n\n\nFactor Analysis\nUse when identifying latent dimensions. Report KMO, eigenvalues, scree plot, factor loadings, variance explained, rotation method, and reliability.\n\n\nLatent Class Analysis (LCA)\nUse to uncover latent subgroups. Report number of classes tested, AIC, BIC, entropy, conditional probabilities, and class prevalence.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Final Stats II Assignment</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html",
    "href": "Monitoring-the-future-example.html",
    "title": "Lab 1: Monitoring the Future",
    "section": "",
    "text": "Overview\nThis analysis examines the relationship between high school football participation and concussion history using data from the Monitoring the Future (MTF) 2023 survey, a nationally representative study of adolescent behaviors and attitudes. Specifically, we investigate whether students who played competitive football in the past 12 months had higher rates of concussion diagnosis compared to their non-football-playing peers.",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#neighborhood-school-safety",
    "href": "Monitoring-the-future-example.html#neighborhood-school-safety",
    "title": "Lab 1: Monitoring the Future",
    "section": "Neighborhood & School Safety",
    "text": "Neighborhood & School Safety\nV8477 - Drug activity in neighborhood\n“During the past 12 months, how often have you seen people selling illegal drugs in your neighborhood?”\n\n1 = Never\n2 = A few times a year\n3 = Once or twice a month\n4 = At least once a week\n5 = Almost every day\n\nV7535 - Feeling unsafe traveling to/from school\n“How often do you feel unsafe going to or from school?”\n\n1 = Never\n2 = Rarely\n3 = Some days\n4 = Most days\n5 = Every day\n\nV7536 - School absence due to safety concerns\n“During the last 4 weeks, how many days did you not go to school because you felt unsafe at school or on your way to or from school?”\n\n1 = 0 days\n2 = 1 day\n3 = 2 or 3 days\n4 = 4 or more days",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#behavioral-indicators",
    "href": "Monitoring-the-future-example.html#behavioral-indicators",
    "title": "Lab 1: Monitoring the Future",
    "section": "Behavioral Indicators",
    "text": "Behavioral Indicators\nV8517 - Group fight participation\n“During the last 12 months, how often have you taken part in a group fight where your friends were against another group?”\n\n1 = Not at all\n2 = Once\n3 = Twice\n4 = 3 or 4 times\n5 = 5 or more times\n\nV8516 - Serious fights at school/work\n“During the last 12 months, how often have you gotten into a serious fight in school or at work?”\n\n1 = Not at all\n2 = Once\n3 = Twice\n4 = 3 or 4 times\n5 = 5 or more times",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#key-variables-of-interest",
    "href": "Monitoring-the-future-example.html#key-variables-of-interest",
    "title": "Lab 1: Monitoring the Future",
    "section": "Key Variables of Interest",
    "text": "Key Variables of Interest\nV7389 - Football participation\n“In which competitive sports (if any) did you participate during the last 12 months?”\n\n0 = Not marked (did not play football)\n1 = Marked (played football)\n\nV7639 - Concussion history (recoded)\nOriginal variable recoded into binary format:\n\n0 = Never had a concussion\n1 = Ever had a concussion (once or multiple times)",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#academic-demographic-variables",
    "href": "Monitoring-the-future-example.html#academic-demographic-variables",
    "title": "Lab 1: Monitoring the Future",
    "section": "Academic & Demographic Variables",
    "text": "Academic & Demographic Variables\nV7221 - Average grades this school year\n\n9 = A (93–100)\n8 = A– (90–92)\n7 = B+ (87–89)\n6 = B (83–86)\n5 = B– (80–82)\n4 = C+ (77–79)\n3 = C (73–76)\n2 = C– (70–72)\n1 = D (69 or below)\n\nV1252 - Age classification\n\n1 = Younger than 16\n2 = 16 years of age or older\n\nV7202 - Sex\n\n1 = Male\n2 = Female\n3 = Other\n4 = Prefer not to answer\n\nV1070 - Race/ethnicity (recoded)\n\n1 = Black or African American\n2 = White (Caucasian)\n3 = Hispanic\nOther/multiple responses coded as missing\n\nV7215 - Father’s education level\nV7216 - Mother’s education level\n\n1 = Grade school or less\n2 = Some high school\n3 = Completed high school\n4 = Some college\n5 = Completed college\n6 = Graduate or professional school\n7 = Don’t know / Does not apply",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#creating-the-concussion-variable",
    "href": "Monitoring-the-future-example.html#creating-the-concussion-variable",
    "title": "Lab 1: Monitoring the Future",
    "section": "Creating the Concussion Variable",
    "text": "Creating the Concussion Variable\nThe original concussion variable (V7639) was recoded into a binary indicator:\n\n\nCode\n# Recode concussion as binary: 0 = No, 1 = Ever had a concussion\ndf$Concussion_Ever &lt;- ifelse(\n  df$V7639 == 1, 0,           # Code 1 = Never → 0\n  ifelse(df$V7639 %in% c(2,3), 1, NA)  # Codes 2,3 = Ever → 1\n)\n\n# Verify recoding\ntable(df$Concussion_Ever, useNA = \"ifany\")\n\n\n\n    0     1  &lt;NA&gt; \n 4471  1112 11768",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#variable-distributions",
    "href": "Monitoring-the-future-example.html#variable-distributions",
    "title": "Lab 1: Monitoring the Future",
    "section": "Variable Distributions",
    "text": "Variable Distributions\n\n\nFrequency tables for all variables\n# Generate frequency tables for all variables\nfor (v in names(df)) {\n  cat(\"\\n-----------------------------------------\\n\")\n  cat(\"Variable:\", v, \"\\n\")\n  print(table(df[[v]], useNA = \"ifany\"))\n}",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#key-variables-football-and-concussion",
    "href": "Monitoring-the-future-example.html#key-variables-football-and-concussion",
    "title": "Lab 1: Monitoring the Future",
    "section": "Key Variables: Football and Concussion",
    "text": "Key Variables: Football and Concussion\n\n\nCode\n# Football participation\ncat(\"Football Participation (V7389):\\n\")\n\n\nFootball Participation (V7389):\n\n\nCode\ntable(df$V7389, useNA = \"ifany\")\n\n\n\n    0     1  &lt;NA&gt; \n 4559   961 11831 \n\n\nCode\n# Concussion history\ncat(\"\\n\\nConcussion History (Recoded):\\n\")\n\n\n\n\nConcussion History (Recoded):\n\n\nCode\ntable(df$Concussion_Ever, useNA = \"ifany\")\n\n\n\n    0     1  &lt;NA&gt; \n 4471  1112 11768",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#cross-tabulation",
    "href": "Monitoring-the-future-example.html#cross-tabulation",
    "title": "Lab 1: Monitoring the Future",
    "section": "Cross-Tabulation",
    "text": "Cross-Tabulation\n\n\nCode\n# Create cross-tabulation\ntab &lt;- table(df$V7389, df$Concussion_Ever)\n\n# Display raw counts\ncat(\"Cross-tabulation (Raw Counts):\\n\")\n\n\nCross-tabulation (Raw Counts):\n\n\nCode\ncat(\"Rows: Football Participation | Columns: Concussion Ever\\n\\n\")\n\n\nRows: Football Participation | Columns: Concussion Ever\n\n\nCode\ntab\n\n\n   \n       0    1\n  0 3733  818\n  1  673  285\n\n\nCode\n# Display percentages by row (% within each football participation group)\ncat(\"\\n\\nRow Percentages (% within football participation status):\\n\")\n\n\n\n\nRow Percentages (% within football participation status):\n\n\nCode\nround(prop.table(tab, margin = 1) * 100, 2)\n\n\n   \n        0     1\n  0 82.03 17.97\n  1 70.25 29.75\n\n\n\n\n\n\n\n\nImportantKey Findings from Cross-Tabulation\n\n\n\nAmong students who did NOT play football:\n818 out of 4,551 (18.0%) reported ever having a concussion\nAmong students who DID play football:\n285 out of 958 (29.7%) reported ever having a concussion\nFootball participants had a 11.7 percentage point higher rate of concussion history.",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#statistical-test-chi-square-analysis",
    "href": "Monitoring-the-future-example.html#statistical-test-chi-square-analysis",
    "title": "Lab 1: Monitoring the Future",
    "section": "Statistical Test: Chi-Square Analysis",
    "text": "Statistical Test: Chi-Square Analysis\n\n\nCode\n# Perform chi-square test of independence\nchi_result &lt;- chisq.test(tab)\nchi_result\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tab\nX-squared = 67.796, df = 1, p-value &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNoteStatistical Significance\n\n\n\nThe chi-square test yielded a highly significant result (p &lt; 0.001), indicating that football participation and concussion history are not independent—there is a statistically significant association between playing football and having experienced a concussion.",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "Monitoring-the-future-example.html#odds-ratio-calculation",
    "href": "Monitoring-the-future-example.html#odds-ratio-calculation",
    "title": "Lab 1: Monitoring the Future",
    "section": "Odds Ratio Calculation",
    "text": "Odds Ratio Calculation\n\n\nCode\n# Calculate odds ratio manually\nodds_football &lt;- tab[2,2] / tab[2,1]      # 285/673\nodds_no_football &lt;- tab[1,2] / tab[1,1]   # 818/3733\n\nodds_ratio &lt;- odds_football / odds_no_football\n\ncat(\"Odds of concussion among football players:\", round(odds_football, 3), \"\\n\")\n\n\nOdds of concussion among football players: 0.423 \n\n\nCode\ncat(\"Odds of concussion among non-football players:\", round(odds_no_football, 3), \"\\n\")\n\n\nOdds of concussion among non-football players: 0.219 \n\n\nCode\ncat(\"\\nOdds Ratio:\", round(odds_ratio, 2), \"\\n\")\n\n\n\nOdds Ratio: 1.93 \n\n\n\n\n\n\n\n\nWarningInterpretation of Odds Ratio\n\n\n\nThe odds ratio of 1.93 indicates that students who reported playing football had approximately 1.9 times the odds of having been diagnosed with a concussion compared to students who did not play football.\nIn simpler terms: The odds of concussion were nearly twice as high among football participants.",
    "crumbs": [
      "Case Studies & Data Applications",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Lab 1: Monitoring the Future</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html",
    "href": "MTF-solution.html",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "",
    "text": "Research Question\nDo students who feel unsafe going to/from school have higher rates of school absence due to safety concerns? Research has consistently documented that students’ perceptions of safety during their commute to and from school are influenced by exposure to violence and crime in their neighborhoods. Studies have found that children often feel unsafe during morning travel to school, with nearly a quarter of students experiencing a reduction in perceived safety immediately upon leaving their homes (Wiebe et al., 2013). Both children and parents report concerns about routes through high-crime neighborhoods, which can impact students’ willingness to travel to school (Meyer & Astor, 2002). Middle school students’ safety perceptions are shaped by environmental factors such as the presence of adults, traveling in groups, proximity to schools, and daylight conditions (Sweeney & Von Hagen, 2015). Recent spatial analyses have revealed the extent of gun violence exposure along walkable routes to schools, with some schools having shootings within a 5-minute walking distance and students potentially encountering multiple incidents during their commute (G. Barboza-Salerno et al., 2024; G. E. Barboza-Salerno & Meshelemiah, 2023). These findings underscore the importance of understanding how feelings of unsafety translate into actual behavioral responses such as school avoidance.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html#recode-v7535-feeling-unsafe",
    "href": "MTF-solution.html#recode-v7535-feeling-unsafe",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "Recode V7535 (Feeling Unsafe)",
    "text": "Recode V7535 (Feeling Unsafe)\n\n# Original variable V7535: 1=Never, 2=Rarely, 3=Some days, 4=Most days, 5=Every day\n# Goal: Create binary variable where 0=Never, 1=Ever feel unsafe\n\ndf$Feel_Unsafe &lt;- ifelse(\n  df$V7535 == 1,                      # Condition: if V7535 equals 1\n  0,                                   # Then: assign 0 (Never feel unsafe)\n  ifelse(df$V7535 %in% c(2,3,4,5),    # Else if: V7535 is 2, 3, 4, or 5\n         1,                            # Then: assign 1 (Ever feel unsafe)\n         NA)                           # Else: assign NA (missing)\n)\n\n# Verify the recoding\ncat(\"Original V7535 Distribution:\\n\")\n\nOriginal V7535 Distribution:\n\ntable(df$V7535, useNA = \"ifany\")\n\n\n    1     2     3     4     5  &lt;NA&gt; \n 3301  1591   504   113    89 11753 \n\ncat(\"\\n\\nRecoded Feel_Unsafe Distribution:\\n\")\n\n\n\nRecoded Feel_Unsafe Distribution:\n\ntable(df$Feel_Unsafe, useNA = \"ifany\")\n\n\n    0     1  &lt;NA&gt; \n 3301  2297 11753",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html#recode-v7536-school-absence-due-to-safety",
    "href": "MTF-solution.html#recode-v7536-school-absence-due-to-safety",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "Recode V7536 (School Absence Due to Safety)",
    "text": "Recode V7536 (School Absence Due to Safety)\n\n# Original variable V7536: 1=0 days, 2=1 day, 3=2-3 days, 4=4+ days\n# Goal: Create binary variable where 0=No days missed, 1=Any days missed\n\ndf$Absent_Safety &lt;- ifelse(\n  df$V7536 == 1,                      # Condition: if V7536 equals 1 (0 days)\n  0,                                   # Then: assign 0 (No days missed)\n  ifelse(df$V7536 %in% c(2,3,4),      # Else if: V7536 is 2, 3, or 4\n         1,                            # Then: assign 1 (Any days missed)\n         NA)                           # Else: assign NA (missing)\n)\n\n# Verify the recoding\ncat(\"Original V7536 Distribution:\\n\")\n\nOriginal V7536 Distribution:\n\ntable(df$V7536, useNA = \"ifany\")\n\n\n    1     2     3     4  &lt;NA&gt; \n 4975   281   214   129 11752 \n\ncat(\"\\n\\nRecoded Absent_Safety Distribution:\\n\")\n\n\n\nRecoded Absent_Safety Distribution:\n\ntable(df$Absent_Safety, useNA = \"ifany\")\n\n\n    0     1  &lt;NA&gt; \n 4975   624 11752 \n\n\n\n\n\n\n\n\nTipRecoding Check\n\n\n\nBoth variables have been successfully converted to binary format: - Feel_Unsafe: 0 = Never, 1 = Ever feel unsafe - Absent_Safety: 0 = No days missed, 1 = Any days missed",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html#calculate-row-percentages",
    "href": "MTF-solution.html#calculate-row-percentages",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "Calculate Row Percentages",
    "text": "Calculate Row Percentages\n\n# Calculate percentages within each \"feeling unsafe\" category\nprop_tab &lt;- prop.table(tab, margin = 1) * 100\n\ncat(\"Row Percentages:\\n\")\n\nRow Percentages:\n\ncat(\"(% of students who missed school within each 'feeling unsafe' group)\\n\\n\")\n\n(% of students who missed school within each 'feeling unsafe' group)\n\nprint(round(prop_tab, 2))\n\n           Absent Due to Safety\nFeel Unsafe No Days (0) Any Days (1)\n  Never (0)       93.39         6.61\n  Ever (1)        82.50        17.50\n\n\n\n\n\n\n\n\nImportantKey Finding from Cross-Tabulation\n\n\n\nAmong students who NEVER feel unsafe:\n218 out of 3297 students (6.6%) missed school due to safety concerns.\nAmong students who EVER feel unsafe:\n401 out of 2292 students (17.5%) missed school due to safety concerns.\nDifference: Students who feel unsafe had a 10.9 percentage point higher rate of school absence.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html#extract-values-from-22-table",
    "href": "MTF-solution.html#extract-values-from-22-table",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "Extract Values from 2×2 Table",
    "text": "Extract Values from 2×2 Table\n\n# Table structure:\n#                Absent=0  Absent=1\n# Feel_Unsafe=0     a         b\n# Feel_Unsafe=1     c         d\n\na &lt;- tab[1,1]  # Never feel unsafe, no absence\nb &lt;- tab[1,2]  # Never feel unsafe, any absence\nc &lt;- tab[2,1]  # Ever feel unsafe, no absence\nd &lt;- tab[2,2]  # Ever feel unsafe, any absence\n\ncat(\"2×2 Table Cell Values:\\n\")\n\n2×2 Table Cell Values:\n\ncat(\"a (Never unsafe, No absence):\", a, \"\\n\")\n\na (Never unsafe, No absence): 3079 \n\ncat(\"b (Never unsafe, Any absence):\", b, \"\\n\")\n\nb (Never unsafe, Any absence): 218 \n\ncat(\"c (Ever unsafe, No absence):\", c, \"\\n\")\n\nc (Ever unsafe, No absence): 1891 \n\ncat(\"d (Ever unsafe, Any absence):\", d, \"\\n\")\n\nd (Ever unsafe, Any absence): 401",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html#calculate-odds-for-each-group",
    "href": "MTF-solution.html#calculate-odds-for-each-group",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "Calculate Odds for Each Group",
    "text": "Calculate Odds for Each Group\n\n# Odds of absence for students who feel unsafe\nodds_feel_unsafe &lt;- d / c\n\n# Odds of absence for students who never feel unsafe\nodds_never_unsafe &lt;- b / a\n\ncat(\"Odds of school absence among students who FEEL UNSAFE:\\n\")\n\nOdds of school absence among students who FEEL UNSAFE:\n\ncat(\"  \", round(odds_feel_unsafe, 4), \"\\n\")\n\n   0.2121 \n\ncat(\"  Interpretation: For every\", round(c), \"students who feel unsafe and don't miss school,\\n\")\n\n  Interpretation: For every 1891 students who feel unsafe and don't miss school,\n\ncat(\"  \", d, \"students feel unsafe and DO miss school\\n\")\n\n   401 students feel unsafe and DO miss school\n\ncat(\"\\n\\nOdds of school absence among students who NEVER feel unsafe:\\n\")\n\n\n\nOdds of school absence among students who NEVER feel unsafe:\n\ncat(\"  \", round(odds_never_unsafe, 4), \"\\n\")\n\n   0.0708 \n\ncat(\"  Interpretation: For every\", round(a), \"students who never feel unsafe and don't miss school,\\n\")\n\n  Interpretation: For every 3079 students who never feel unsafe and don't miss school,\n\ncat(\"  \", b, \"students never feel unsafe but still miss school\\n\")\n\n   218 students never feel unsafe but still miss school",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html#calculate-the-odds-ratio",
    "href": "MTF-solution.html#calculate-the-odds-ratio",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "Calculate the Odds Ratio",
    "text": "Calculate the Odds Ratio\n\n# Calculate odds ratio\nodds_ratio &lt;- odds_feel_unsafe / odds_never_unsafe\n\ncat(\"Odds Ratio:\\n\")\n\nOdds Ratio:\n\ncat(\"  OR = (d/c) / (b/a)\\n\")\n\n  OR = (d/c) / (b/a)\n\ncat(\"  OR = (\", d, \"/\", c, \") / (\", b, \"/\", a, \")\\n\")\n\n  OR = ( 401 / 1891 ) / ( 218 / 3079 )\n\ncat(\"  OR = \", round(odds_feel_unsafe, 4), \" / \", round(odds_never_unsafe, 4), \"\\n\")\n\n  OR =  0.2121  /  0.0708 \n\ncat(\"  OR = \", round(odds_ratio, 2), \"\\n\")\n\n  OR =  3",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html#calculate-95-confidence-interval",
    "href": "MTF-solution.html#calculate-95-confidence-interval",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "Calculate 95% Confidence Interval",
    "text": "Calculate 95% Confidence Interval\n\n# Calculate 95% confidence interval for the odds ratio\nlog_or &lt;- log(odds_ratio)\nse_log_or &lt;- sqrt(1/a + 1/b + 1/c + 1/d)\nci_lower &lt;- exp(log_or - 1.96 * se_log_or)\nci_upper &lt;- exp(log_or + 1.96 * se_log_or)\n\ncat(\"95% Confidence Interval for Odds Ratio:\\n\")\n\n95% Confidence Interval for Odds Ratio:\n\ncat(\"  [\", round(ci_lower, 2), \", \", round(ci_upper, 2), \"]\\n\")\n\n  [ 2.52 ,  3.57 ]\n\n\n\n\n\n\n\n\nWarningInterpretation of the Odds Ratio\n\n\n\nOdds Ratio: 3 (95% CI: [2.52, 3.57])\nStudents who reported feeling unsafe going to or from school had approximately 3 times the odds of missing school due to safety concerns compared to students who never felt unsafe.\nIn plain language: Students who feel unsafe during their school commute are about 3 times more likely to actually miss school days because of safety concerns.\nThis is a very strong association—much stronger than the football-concussion relationship (OR ≈ 1.9) we examined earlier.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "MTF-solution.html#summary-of-findings",
    "href": "MTF-solution.html#summary-of-findings",
    "title": "School Safety and Attendance Analysis - SOLUTION",
    "section": "Summary of Findings",
    "text": "Summary of Findings\nThis analysis examined whether students’ feelings of safety while traveling to and from school are associated with actual school absence due to safety concerns. The results reveal a powerful relationship:\n\nStrength and Direction of Association\n\nStudents who report feeling unsafe going to/from school have significantly higher rates of school absence\nThe association is positive and strong: feeling unsafe is associated with increased likelihood of missing school\nThe odds ratio of 3 indicates approximately 3-fold higher odds of absence among students who feel unsafe\n\n\n\nStatistical Significance\n\nChi-square test: χ² = 161.51, p &lt; 0.001\nThe relationship is highly statistically significant\nThe 95% confidence interval for the odds ratio [2.52, 3.57] does not include 1.0, confirming the association is not due to chance\nWe can be confident this relationship exists in the broader population, not just in this sample\n\n\n\nPractical Implications\nFor Schools and Educators:\n\nStudents’ reports of feeling unsafe should be taken seriously—they predict actual behavioral consequences\nFeelings of unsafety are not just subjective concerns; they translate into measurable school avoidance\nAddressing route safety could be an effective intervention for reducing chronic absenteeism\n\nFor Policy:\n\nSchool safety means more than crash risk or mass violence.\nSafe passage programs may help improve attendance rates (but see (G. Barboza-Salerno et al., 2024; G. E. Barboza-Salerno & Meshelemiah, 2023))\nConsider implementing safe corridors with adult supervision\nSchool transportation options may benefit students who feel unsafe walking/using public transit\nSchool violence interventions (e.g., IEPs for students exposed to community violence or community-school partnerships to address neighborhood safety) could impact educational outcomes\n\nFor Research:\n\nThis strong association warrants further investigation into causal mechanisms\nLongitudinal studies could determine whether improving safety perceptions leads to better attendance\nIdentifying specific threats (violence, bullying, traffic) could help target interventions\n\n\n\nLimitations to Consider\nWhile this analysis reveals a strong association, it’s important to note:\n\nCross-sectional design: We cannot determine causality—does feeling unsafe cause absence, or do prior threatening experiences cause both?\nSelf-report data: Both variables rely on student perceptions and recall\nTemporal ordering: The measures use different time frames (general feelings vs. past 4 weeks)\nUnmeasured confounders: Other factors (neighborhood violence, family factors, anxiety) may explain part of the relationship\n\nDespite these limitations, the magnitude and significance of this association suggest that students’ safety perceptions are an important factor in school attendance that deserves attention from educators and policymakers.\n\nAnalysis completed: 2026-01-17\n\n\n\n\nBarboza-Salerno, G. E., & Meshelemiah, J. C. A. (2023). Gun Violence on Walkable Routes to and from School: Recommendations for Policy and Practice. Journal of Urban Health, 100(6), 1102–1117. https://doi.org/10.1007/s11524-023-00802-2Gun-related violence exposure is a significant public health problem for urban youth. Few studies have implemented methods to estimate the spatial influence of activity spaces on gun violence exposure constrained by the physical configuration of walkable street networks. The present research uses computational network and local indicators of spatial autocorrelation methods to explore gun violence exposure along the walkable streets near schools in Compton, California. Findings demonstrated strong evidence that gun violence is clustered at all distances along the pedestrian network and in proximity to Compton Unified School District (K-12) schools, reaching a maximum between 1.2 and 1.8 mi; thereafter the “attractiveness” of schools to gun violence was inhibiting. Almost all schools had at least one shooting within a 5-min walk (i.e., about 400 m); 37.8% of schools had an average shooting distance of less than 400 m; about 250 incidents occurred within 5 min of schools; and about 30 schools had a shooting within a 5-min walking distance. Determining the spatial extent of violence exposure in proximity to key activity spaces for youth, such as schools, has substantial implications for the health and wellbeing of youth living in violence-prone areas. The public health and legal implications of this study are discussed in context.\n\n\nBarboza-Salerno, G., Duhaney, S., & Yang, H. (2024). Spatial accessibility to gun violence exposure on walkable routes to and from school. SSM - Population Health, 28, 101730. https://doi.org/10.1016/j.ssmph.2024.101730This study investigates the spatial accessibility of gun violence exposure along walkable routes to and from schools in Englewood, Chicago. Focusing on both direct and indirect forms of gun violence, the study uses acoustic detection technology to quantify the cumulative burden of gun violence exposure potentially encountered by students during their commute to and from school. We examined the spatial distribution of shooting incidents in proximity to schools using network-constrained kernel density estimation, secondary spatial analysis, and rapid realistic routing. G-function analysis revealed that shooting incidents cluster along streets, including safe passage routes, near schools. An average of 1.30 and 18.06 gunshots were reachable within 5- and 15-min commute times in the morning and afternoon, respectively Our findings underscore the urgent need to reframe the narrative around “school gun violence” to consider exposures that occur in proximity to school boundaries to more effectively reduce violence exposure for youth who walk to school in violence-prone neighborhoods.\n\n\nMeyer, H. A., & Astor, R. A. (2002). Child and Parent Perspectives on Routes to and from School in High Crime Neighborhoods. Journal of School Violence, 1(4), 101–128. https://doi.org/10.1300/J202v01n04_07\n\n\nSweeney, S. M., & Von Hagen, L. A. (2015). Middle School Students’ Perceptions of Safety: A Mixed-Methods Study. Journal of School Health, 85(10), 688–696. https://doi.org/10.1111/josh.12298BACKGROUND Active travel to school has been on the decline, despite its beneficial influence on children’s current and future well-being. Adults’ safety perceptions have been shown to influence children’s active travel. Children’s perceptions, particularly of safety, may be an important link not only to their present health and travel behaviors, but also their future health and behaviors. This study examined middle school students’ perceptions of the built environment and safety. METHODS Overall, 776 students from 3 schools in Hudson County, New Jersey participated in a visual survey and structured, interactive classroom discussions. Emergent themes from the discussions were tested using multivariate statistical models. RESULTS Findings suggest that older students, boys, and students who self-identified as black, rated built environment scenes as safer. Students also perceived being near adults, traveling in a group, and using crosswalks as significantly safer and want additional recognition of these to further improve safety. Students perceived that being near a school, in daylight, and aesthetics as factors contributing to safety. CONCLUSIONS Schools and municipalities may increase programs for students to travel in groups, prioritize maintenance in school zones, and increase the number of crossing guards, particularly outside the immediate school proximity to further improve safety.\n\n\nWiebe, D. J., Guo, W., Allison, P. D., Anderson, E., Richmond, T. S., & Branas, C. C. (2013). Fears of Violence During Morning Travel to School. Journal of Adolescent Health, 53(1), 54–61. https://doi.org/10.1016/j.jadohealth.2013.01.023Purpose Children’s safety as they travel to school is a concern nationwide. We investigated how safe children felt from the risk of being assaulted during morning travel to school. Methods Children between 10 and 18 years old were recruited in Philadelphia and interviewed with the aid of geographic information system (GIS) mapping software about a recent trip to school, situational characteristics, and how safe they felt as they travelled based on a 10-point item (1 = very unsafe, 10 = very safe). Ordinal regression was used to estimate the probability of perceiving different levels of safety based on transportation mode, companion type, and neighborhood characteristics. Results Among 65 randomly selected subjects, routes to school ranged from 7 to 177 minutes (median = 36) and .1–15.1 street miles (median = 1.9), and included between 1–5 transportation modes (median = 2). Among students interviewed, 58.5% felt less than very safe (i.e., \\(&lt;\\)10) at some point while traveling to school and one-third (32.5%) of the total person time was spent feeling less than very safe. Nearly a quarter of students, or 24.6%, felt a reduction in safety immediately upon exiting their home. The probability of reporting a safety of \\(&gt;\\)8, for example, was .99 while in a car and .94 while on foot but was .86 and .87 when on a public bus or trolley. Probability was .98 while with an adult but was .72 while with another child and .71 when alone. Also, perceived safety was lower in areas of high crime and high density of off-premise alcohol outlets. Conclusions Efforts that target situational risk factors are warranted to help children feel safe over their entire travel routes to school.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>School Safety and Attendance Analysis - SOLUTION</span>"
    ]
  },
  {
    "objectID": "dataweb.html",
    "href": "dataweb.html",
    "title": "Data Sources",
    "section": "",
    "text": "Overview\nThis page provides a comprehensive collection of data sources used in my research and teaching. Resources are organized by topic area and include both freely available and restricted-access datasets.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#overview",
    "href": "dataweb.html#overview",
    "title": "Data Sources",
    "section": "",
    "text": "Note\n\n\n\nLast Updated: r Sys.Date()\nLinks are checked regularly, but availability may change. Please contact me if you find broken links.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#health-public-health-data",
    "href": "dataweb.html#health-public-health-data",
    "title": "Data Sources",
    "section": "Health & Public Health Data",
    "text": "Health & Public Health Data\n\nNational Surveys\n\nNational Health Interview Survey (NHIS)\n\nProvider: National Center for Health Statistics (NCHS)\nDescription: Annual household survey covering health status, healthcare access, and health behaviors\nTime Period: 1957-present\nAccess: CDC NHIS Website\nFormat: SAS, SPSS, Stata, CSV\nLicense: Public domain\n\n\n\nBehavioral Risk Factor Surveillance System (BRFSS)\n\nProvider: Centers for Disease Control and Prevention\nDescription: Telephone survey tracking health conditions and risk behaviors\nTime Period: 1984-present\nAccess: BRFSS Website\nFormat: SAS, ASCII\nLicense: Public domain\n\n\n\n\nMedical & Clinical Data\n\nMedical Expenditure Panel Survey (MEPS)\n\nProvider: Agency for Healthcare Research and Quality (AHRQ)\nDescription: Healthcare costs, utilization, insurance coverage, and quality of care\nTime Period: 1996-present\nAccess: MEPS Website\nFormat: SAS, Stata, SPSS, ASCII\nLicense: Public domain",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#social-demographic-data",
    "href": "dataweb.html#social-demographic-data",
    "title": "Data Sources",
    "section": "Social & Demographic Data",
    "text": "Social & Demographic Data\n\nCensus & Demographics\n\nU.S. Census Bureau Data\n\nProvider: U.S. Census Bureau\nDescription: Population, housing, economic, and geographic data\nTime Period: Varies by dataset\nAccess: data.census.gov\nAPI: Available via Census API\nFormat: Multiple formats available\nLicense: Public domain\n\n\n\nAmerican Community Survey (ACS)\n\nProvider: U.S. Census Bureau\nDescription: Detailed demographic and socioeconomic characteristics\nTime Period: 2005-present (annual); 2000-2004 (test phase)\nAccess: ACS Data Portal\nFormat: CSV, API\nLicense: Public domain\n\n\n\n\nSocial Surveys\n\nGeneral Social Survey (GSS)\n\nProvider: NORC at the University of Chicago\nDescription: Attitudes, behaviors, and attributes of U.S. residents\nTime Period: 1972-present\nAccess: GSS Data Explorer\nFormat: Stata, SPSS, SAS, R, Excel\nLicense: Free for research/educational use",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#education-data",
    "href": "dataweb.html#education-data",
    "title": "Data Sources",
    "section": "Education Data",
    "text": "Education Data\n\nNational Center for Education Statistics (NCES)\n\nProvider: U.S. Department of Education\nDescription: Various education datasets including NAEP, CCD, IPEDS\nTime Period: Varies by survey\nAccess: NCES Website\nFormat: Multiple formats\nLicense: Public domain\n\n\n\nIntegrated Postsecondary Education Data System (IPEDS)\n\nProvider: NCES\nDescription: College enrollment, graduation rates, faculty, finances\nTime Period: 1980-present\nAccess: IPEDS Data Center\nFormat: CSV, Access, Excel\nLicense: Public domain\n\n\n\nCivil Rights Data Collection\n\nProvider: U.S. Department of Education Office for Civil Rights\nDescription: School-level data on enrollment, discipline, access to courses, and civil rights issues\nTime Period: 1968-present (biennial since 2009)\nAccess: Civil Rights Data Collection\nFormat: Excel, CSV\nLicense: Public domain\n\n\n\nUrban Institute Education Data Explorer\n\nProvider: Urban Institute\nDescription: School and district-level data on enrollment, disability, race/ethnicity, income, discipline\nTime Period: Varies\nAccess: Education Data Portal\nAPI: Available\nFormat: CSV, API\nLicense: Public domain\n\n\n\nNCES Education Demographic and Geographic Estimates (EDGE)\n\nProvider: National Center for Education Statistics\nDescription: School- and district-level demographic and socioeconomic characteristics\nTime Period: Varies\nAccess: EDGE Program\nFormat: Shapefiles, CSV\nLicense: Public domain\n\n\n\nMonitoring the Future\n\nProvider: University of Michigan Institute for Social Research (via ICPSR)\nDescription: Annual survey of 8th, 10th, and 12th grade students on substance use, attitudes, and behaviors\nTime Period: 1975-present\nAccess: ICPSR MTF Studies\nFormat: SAS, SPSS, Stata, R, delimited\nLicense: Registration required",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#criminal-justice-safety",
    "href": "dataweb.html#criminal-justice-safety",
    "title": "Data Sources",
    "section": "Criminal Justice & Safety",
    "text": "Criminal Justice & Safety\n\nGun Violence Data\n\nGun Violence Archive\n\nProvider: Gun Violence Archive\nDescription: Comprehensive database of gun violence incidents in the United States\nTime Period: 2013-present\nAccess: Gun Violence Archive\nFormat: Online database, CSV (by request)\nLicense: Varies\n\n\n\nNational Violent Death Reporting System (NVDRS)\n\nProvider: Centers for Disease Control and Prevention\nDescription: State-based surveillance system providing detailed information on violent deaths including homicides, suicides, and firearm-related deaths\nTime Period: 2003-present\nAccess: NVDRS Website\nFormat: Restricted-use data files available through application\nLicense: Restricted access\n\n\n\nFirearm Injury Surveillance\n\nProvider: Centers for Disease Control and Prevention\nDescription: Surveillance data on fatal and nonfatal firearm injuries\nTime Period: Varies\nAccess: CDC WISQARS\nFormat: Online query system\nLicense: Public domain\n\n\n\nMother Jones Gun Violence Data\n\nProvider: Mother Jones\nDescription: Database of mass shootings in the United States\nTime Period: 1982-present\nAccess: Mother Jones Database\nFormat: Excel, Google Sheets\nLicense: Varies\n\n\n\nMass Shooter Database\n\nProvider: The Violence Project\nDescription: Comprehensive database of mass shooters including demographic, psychological, and incident characteristics\nTime Period: 1966-present\nAccess: The Violence Project\nFormat: Online database\nLicense: Available for research use\n\n\n\nSchool Shooting Data\n\nProvider: K-12 School Shooting Database\nDescription: Comprehensive data on school shooting incidents\nTime Period: 1970-present\nAccess: K-12 SSDB\nFormat: Excel, CSV\nLicense: Free for research use\n\n\n\nViolent Deaths at School & Shootings\n\nProvider: National Center for Education Statistics\nDescription: Data on violent deaths and shootings at schools\nTime Period: Varies\nAccess: NCES Indicators\nFormat: Excel, PDF\nLicense: Public domain\n\n\n\nSchool Campus Database (CSCD)\n\nProvider: National Center for Education Statistics\nDescription: Geographic data on school campuses and facilities\nTime Period: Varies\nAccess: NCES School Locations\nFormat: Shapefiles, CSV\nLicense: Public domain\n\n\n\nLos Angeles Times Homicide Report\n\nProvider: Los Angeles Times\nDescription: Database of homicides in Los Angeles County\nTime Period: 2000-present\nAccess: LA Times Homicide Report\nFormat: Interactive database\nLicense: Varies\n\n\n\nChicago ShotSpotter Data\n\nProvider: City of Chicago Data Portal\nDescription: Acoustic gunshot detection data from ShotSpotter sensors\nTime Period: Varies\nAccess: Chicago Data Portal\nFormat: CSV, JSON, API\nLicense: Public domain\n\n\n\nMedical Examiner Case Archive\n\nProvider: Various County Medical Examiners\nDescription: Death investigation data including manner and cause of death\nTime Period: Varies by jurisdiction\nAccess: Varies by jurisdiction\nFormat: Varies\nLicense: Varies; often requires data use agreement\n\n\n\nPA Child Fatality Reports\n\nProvider: Pennsylvania Department of Human Services\nDescription: Reports on child fatalities including abuse and neglect-related deaths\nTime Period: Annual reports\nAccess: PA DHS Website\nFormat: PDF reports\nLicense: Public domain\n\n\n\n\nCrime & Justice\n\nUniform Crime Reporting (UCR) Program\n\nProvider: Federal Bureau of Investigation\nDescription: Crime statistics from law enforcement agencies\nTime Period: 1930-present\nAccess: FBI Crime Data Explorer\nFormat: CSV, Excel, API\nLicense: Public domain\n\n\n\nNational Crime Victimization Survey (NCVS)\n\nProvider: Bureau of Justice Statistics\nDescription: Victimization experiences, characteristics, and reporting\nTime Period: 1972-present\nAccess: NCVS Data\nFormat: SAS, SPSS, Stata, ASCII\nLicense: Public domain\n\n\n\nTexas Death Row Information\n\nProvider: Texas Department of Criminal Justice\nDescription: Information on executed offenders including demographics, offense details, and execution dates\nTime Period: Historical executions\nAccess: TDCJ Death Row Data\nFormat: HTML tables\nLicense: Public domain\n\n\n\nPhiladelphia Gun Violence Mapping\n\nProvider: Philadelphia City Controller’s Office (Christy Brady, CPA)\nDescription: Interactive mapping of gun violence incidents across Philadelphia\nTime Period: 2015-present\nAccess: Gun Violence Map\nFormat: Interactive web map\nLicense: Public domain\n\n\n\nEverytown Gun Violence Research\n\nProvider: Everytown Research & Policy\nDescription: Gun violence data, research, and policy analysis\nTime Period: Varies by dataset\nAccess: Everytown Research\nFormat: Reports, datasets, interactive tools\nLicense: Varies",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#economic-labor-data",
    "href": "dataweb.html#economic-labor-data",
    "title": "Data Sources",
    "section": "Economic & Labor Data",
    "text": "Economic & Labor Data\n\nBureau of Labor Statistics (BLS) Data\n\nProvider: U.S. Department of Labor\nDescription: Employment, wages, inflation, productivity data\nTime Period: Varies by series\nAccess: BLS Data Tools\nAPI: BLS API\nFormat: Excel, CSV, JSON, PDF\nLicense: Public domain\n\n\n\nPanel Study of Income Dynamics (PSID)\n\nProvider: University of Michigan\nDescription: Longitudinal household survey tracking economic and social behavior\nTime Period: 1968-present\nAccess: PSID Website\nFormat: Stata, SAS, SPSS, ASCII\nLicense: Free registration required\n\n\n\nLongitudinal Household & Employer Dynamics Data (LODES)\n\nProvider: U.S. Census Bureau\nDescription: Job counts by census block, worker characteristics, and employment flows\nTime Period: 2002-present\nAccess: LEHD LODES\nFormat: CSV\nLicense: Public domain",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#international-comparative-data",
    "href": "dataweb.html#international-comparative-data",
    "title": "Data Sources",
    "section": "International & Comparative Data",
    "text": "International & Comparative Data\n\nWorld Bank Open Data\n\nProvider: The World Bank\nDescription: International development data covering 200+ countries\nTime Period: Varies by indicator\nAccess: World Bank Data\nAPI: Available\nFormat: CSV, Excel, XML, JSON\nLicense: Creative Commons Attribution 4.0\n\n\n\nOECD Data\n\nProvider: Organisation for Economic Co-operation and Development\nDescription: Economic and social statistics for member countries\nTime Period: Varies\nAccess: OECD.Stat\nFormat: CSV, Excel, SDMX\nLicense: Varies by dataset",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#environmental-geographic-data",
    "href": "dataweb.html#environmental-geographic-data",
    "title": "Data Sources",
    "section": "Environmental & Geographic Data",
    "text": "Environmental & Geographic Data\n\nEnvironmental Quality & Hazards\n\nEPA Environmental Dataset Gateway\n\nProvider: U.S. Environmental Protection Agency\nDescription: Air quality, water quality, emissions, toxic releases\nTime Period: Varies\nAccess: EPA Data\nFormat: Various\nLicense: Public domain\n\n\n\nUSGS Earth Explorer\n\nProvider: U.S. Geological Survey\nDescription: Satellite imagery, aerial photography, cartographic products\nTime Period: Historical to present\nAccess: Earth Explorer\nFormat: GeoTIFF, JPEG, various GIS formats\nLicense: Public domain\n\n\n\nOpenTopography Data\n\nProvider: OpenTopography\nDescription: High-resolution topographic data and digital elevation models\nTime Period: Varies\nAccess: OpenTopography\nFormat: Various GIS formats\nLicense: Varies by dataset\n\n\n\nDigital Elevation Model Data\n\nProvider: USGS, NASA, and other providers\nDescription: Terrain elevation data for geographic analysis\nTime Period: Varies\nAccess: Various sources including USGS Earth Explorer\nFormat: GeoTIFF, ASCII, various GIS formats\nLicense: Typically public domain\n\n\n\nHUD Environmental Health Hazards Index\n\nProvider: U.S. Department of Housing and Urban Development\nDescription: Exposure to harmful toxins including air quality, carcinogenic, respiratory, and neurological hazards\nTime Period: Varies\nAccess: HUD Data\nFormat: Various\nLicense: Public domain\n\n\n\nEPA EJScreen: Environmental Justice Mapping Tool\n\nProvider: U.S. Environmental Protection Agency\nDescription: Environmental and demographic indicators including particulate matter, ozone, air toxins, traffic proximity, and hazardous waste\nTime Period: Updated annually\nAccess: EJScreen\nFormat: Online tool, downloadable data\nLicense: Public domain\n\n\n\n\nBuilt Environment & Accessibility\n\nEPA National Walkability Index\n\nProvider: U.S. Environmental Protection Agency\nDescription: Street intersection density and walkability metrics for neighborhoods\nTime Period: Updated periodically\nAccess: National Walkability Index\nFormat: Geodatabase, CSV\nLicense: Public domain\n\n\n\nEPA Smart Location Database\n\nProvider: U.S. Environmental Protection Agency\nDescription: Nationwide data on development patterns, diversity of land use, street network design, and accessibility\nTime Period: Updated periodically\nAccess: Smart Location Database\nFormat: Geodatabase, CSV\nLicense: Public domain\n\n\n\nEPA Access to Jobs and Workers Via Transit\n\nProvider: U.S. Environmental Protection Agency\nDescription: Transit accessibility index comparing block groups within metropolitan regions\nTime Period: Updated periodically\nAccess: EPA Transit Access Data\nFormat: Geodatabase, CSV\nLicense: Public domain\n\n\n\nOpenStreetMap Data\n\nProvider: OpenStreetMap Foundation\nDescription: Collaborative mapping data including streets, buildings, points of interest\nTime Period: Continuously updated\nAccess: OpenStreetMap\nFormat: XML, PBF, various GIS formats\nLicense: Open Database License (ODbL)\n\n\n\nZoning Data\n\nProvider: Various municipal and county planning departments\nDescription: Land use and zoning designations\nTime Period: Varies by jurisdiction\nAccess: Varies by jurisdiction\nFormat: Shapefiles, geodatabase\nLicense: Varies\n\n\n\nSafeGraph Data\n\nProvider: SafeGraph\nDescription: Points of interest, foot traffic patterns, and demographic data\nTime Period: 2018-present\nAccess: SafeGraph\nFormat: CSV, Parquet\nLicense: Requires data agreement; free for academic research\n\n\n\nFoursquare Venues\n\nProvider: Foursquare\nDescription: Location data and venue information including restaurants, retail, services\nTime Period: Current\nAccess: Foursquare API\nFormat: JSON via API\nLicense: Requires API key\n\n\n\n\nSocial & Health Vulnerability\n\nCDC Social Vulnerability Index (SVI)\n\nProvider: Centers for Disease Control and Prevention\nDescription: Census tract-level social vulnerability including socioeconomic status, household composition, housing, race/ethnicity, and health factors\nTime Period: 2000, 2010, 2014, 2016, 2018, 2020\nAccess: SVI Data Download\nFormat: CSV, geodatabase, shapefiles\nLicense: Public domain\n\n\n\nNeighborhood Atlas Area Deprivation Index (ADI)\n\nProvider: University of Wisconsin School of Medicine and Public Health\nDescription: Neighborhood-level measure of socioeconomic disadvantage including income, education, employment, and housing quality\nTime Period: Updated periodically\nAccess: Neighborhood Atlas\nFormat: CSV, online mapping tool\nLicense: Free for research use\n\n\n\nHealthy Places Index\n\nProvider: Public Health Alliance of Southern California\nDescription: Community conditions that predict life expectancy including economic, social, and environmental factors\nTime Period: Updated periodically\nAccess: Healthy Places Index\nFormat: Interactive map, CSV\nLicense: Free for public use\n\n\n\nUrbanization Index\n\nProvider: Various sources including Census Bureau\nDescription: Measures of urban versus rural character of geographic areas\nTime Period: Varies\nAccess: Varies by source\nFormat: Various\nLicense: Typically public domain\n\n\n\n\nFood Access & Nutrition\n\nUSDA Food Desert Data\n\nProvider: U.S. Department of Agriculture Economic Research Service\nDescription: Low-income census tracts with limited access to supermarkets and healthy food sources\nTime Period: Updated periodically\nAccess: Food Access Research Atlas\nFormat: Excel, CSV, GIS files\nLicense: Public domain\n\n\n\nSNAP Retailer Database\n\nProvider: U.S. Department of Agriculture Food and Nutrition Service\nDescription: Locations of retailers authorized to accept SNAP benefits\nTime Period: Updated monthly\nAccess: SNAP Retailer Locator\nFormat: CSV, API\nLicense: Public domain\n\n\n\n\nParks, Green Space & Environmental Justice\n\nTrust for Public Land ParkServe\n\nProvider: Trust for Public Land\nDescription: Park access and equity data including 10-minute walk access to parks\nTime Period: Updated regularly\nAccess: ParkServe\nFormat: Interactive map, API\nLicense: Varies\n\n\n\nAmerican Forests Tree Equity Score\n\nProvider: American Forests\nDescription: Tree equity scores, heat extremity, and heat disparity metrics\nTime Period: Current\nAccess: Tree Equity Score\nFormat: Interactive map, downloadable data\nLicense: Varies\n\n\n\nNational Tree Equity Score\n\nProvider: American Forests\nDescription: National-level tree canopy and equity analysis\nTime Period: Current\nAccess: Tree Equity Score\nFormat: Interactive map, CSV\nLicense: Varies\n\n\n\n\nHousing & Neighborhood Change\n\nUniversity of Richmond Mapping Inequality\n\nProvider: Digital Scholarship Lab, University of Richmond\nDescription: HOLC redlining maps and neighborhood grades for U.S. cities\nTime Period: 1930s-1940s\nAccess: Mapping Inequality\nFormat: Interactive maps, downloadable shapefiles\nLicense: CC BY-NC-SA 4.0\n\n\n\nRedlining Data\n\nProvider: Various sources including University of Richmond\nDescription: Historical HOLC maps and modern redlining analysis\nTime Period: 1930s-present\nAccess: Various sources\nFormat: Shapefiles, GeoJSON\nLicense: Varies\n\n\n\nGentrification & Displacement Data\n\nProvider: Urban Displacement Project, Federal Reserve Banks, academic researchers\nDescription: Indicators of neighborhood gentrification and displacement risk\nTime Period: Varies\nAccess: Urban Displacement Project\nFormat: Interactive maps, CSV, shapefiles\nLicense: Varies\n\n\n\nHousing Affordability Index\n\nProvider: National Association of Realtors, HUD, various sources\nDescription: Measures of housing cost burden and affordability\nTime Period: Varies\nAccess: Various sources\nFormat: Excel, CSV\nLicense: Varies\n\n\n\nHousing & Mortgage Act Disclosure Data (HMDA)\n\nProvider: Consumer Financial Protection Bureau\nDescription: Mortgage lending data including loan applications, originations, and denials\nTime Period: 1975-present\nAccess: FFIEC HMDA Data\nFormat: CSV, API\nLicense: Public domain\n\n\n\nCenter for Neighborhood Technology Housing + Transportation Index\n\nProvider: Center for Neighborhood Technology\nDescription: Comprehensive housing and transportation cost data by neighborhood\nTime Period: Updated periodically\nAccess: H+T Index\nFormat: CSV, interactive maps\nLicense: Varies\n\n\n\nTransit Center Transit-Oriented Development Database (TED)\n\nProvider: Transit Center\nDescription: Accessibility to neighborhood amenities including colleges, hospitals, urgent care, parks, and supermarkets\nTime Period: Varies\nAccess: TED Database\nFormat: Interactive web tool\nLicense: Varies\n\n\n\nGoogle Open Buildings Dataset\n\nProvider: Google Research\nDescription: Building footprints by type (residential, commercial, etc.) from satellite imagery\nTime Period: Current\nAccess: Open Buildings\nFormat: GeoJSON, CSV\nLicense: CC BY 4.0",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#data-repositories-archives",
    "href": "dataweb.html#data-repositories-archives",
    "title": "Data Sources",
    "section": "Data Repositories & Archives",
    "text": "Data Repositories & Archives\n\nInter-university Consortium for Political and Social Research (ICPSR)\n\nProvider: University of Michigan\nDescription: Archive of social science data\nAccess: ICPSR Website\nFormat: Multiple formats\nLicense: Varies; institutional membership may be required\n\n\n\nHarvard Dataverse\n\nProvider: Harvard University\nDescription: Open research data repository\nAccess: Dataverse\nFormat: Various\nLicense: Varies by dataset\n\n\n\nOpen Science Framework (OSF)\n\nProvider: Center for Open Science\nDescription: Research data, materials, and preprints\nAccess: OSF.io\nFormat: Various\nLicense: Varies by project",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#data-tools-apis",
    "href": "dataweb.html#data-tools-apis",
    "title": "Data Sources",
    "section": "Data Tools & APIs",
    "text": "Data Tools & APIs\n\nR Packages for Data Access\n# Census data\nlibrary(tidycensus)\nlibrary(censusapi)\n\n# Health data\nlibrary(nhanesA)\n\n# Economics\nlibrary(fredr)  # FRED API\nlibrary(wbstats) # World Bank\n\n# General\nlibrary(dataRetrieval) # USGS water data\n\n\nPython Libraries\n# Census data\nimport census\nfrom census import Census\n\n# World Bank\nimport wbdata\n\n# Federal Reserve\nfrom fredapi import Fred\n\n# General APIs\nimport requests\nimport pandas as pd",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#data-citation-guidelines",
    "href": "dataweb.html#data-citation-guidelines",
    "title": "Data Sources",
    "section": "Data Citation Guidelines",
    "text": "Data Citation Guidelines\nWhen using these data sources, please follow appropriate citation practices:\n\n\n\n\n\n\nImportantGeneral Citation Format\n\n\n\nAuthor/Organization. (Year). Dataset Title [Data file]. Retrieved from URL\nExample:\nNational Center for Health Statistics. (2023). National Health Interview Survey, 2022 [Data file]. Retrieved from https://www.cdc.gov/nchs/nhis/",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "dataweb.html#additional-resources",
    "href": "dataweb.html#additional-resources",
    "title": "Data Sources",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nData.gov - U.S. Government’s open data portal\nGoogle Dataset Search - Search engine for datasets\nRegistry of Open Data on AWS - Public datasets on Amazon Web Services\nKaggle Datasets - Community-contributed datasets\n\n\n\n\n\n\n\n\nTipSuggest a Data Source\n\n\n\nKnow of a valuable data source not listed here? Please submit a suggestion.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Data Sources</span>"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources for learning and applying R",
    "section": "",
    "text": "Learning R\nR Style Suggestions\nData\nOpen Source Software",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Resources for learning and applying R</span>"
    ]
  },
  {
    "objectID": "learning-r.html",
    "href": "learning-r.html",
    "title": "Learning R",
    "section": "",
    "text": "Learning R\nI highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful. Also check out StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nThese resources are also really really helpful:\nR for Data Science: A free online book for learning the basics of R and the tidyverse.\nR and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, ggplot2, and other R-related things.\nStat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online.\nSTA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online.\nCSE 631: Principles & Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Learning R</span>"
    ]
  },
  {
    "objectID": "learning-r.html#r-in-the-wild",
    "href": "learning-r.html#r-in-the-wild",
    "title": "Learning R",
    "section": "R in the wild",
    "text": "R in the wild\nA popular (and increasingly standard) way for sharing your analyses and visualizations is to post an annotated explanation of your process somewhere online. RStudio allows you to publish knitted HTML files directly to RPubs, but you can also post your output to a blog or other type of website.1 Reading these kinds of posts is one of the best ways to learn R, since they walk you through each step of the process and show the code and output.\nHere are some of the best examples I’ve come across:\nText analysis of Trump’s tweets confirms he writes only the (angrier) Android half (with a follow-up)\nBob Ross - Joy of Painting\nBechdel analysis using the tidyverse: There are also a bunch of other examples using data from FiveThirtyEight.\nSexism on the Silver Screen: Exploring film’s gender divide\nComparison of Quentin Tarantino Movies by Box Office and the Bechdel Test\nWho came to vote in Utah’s caucuses?\nHealth care indicators in Utah counties\nSong lyrics across the United States\nA decade (ish) of listening to Sigur Rós\nWhen is Tom peeping these days?\nMapping Fall Foliage\nGeneral (Attys) Distributions\nDisproving Approval\nFootnotes\n1 This list of resources was compiled by Andrew Weiss↩︎",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Learning R</span>"
    ]
  },
  {
    "objectID": "open-source-software.html",
    "href": "open-source-software.html",
    "title": "Open Source Software",
    "section": "",
    "text": "Statistical Software Packages\nThere are a wide variety of different open source and proprietary software tools that are simple to learn and make data management and analysis easier, more effective and fun. Here is my list of the most important tools to be familiar with. The items in bold are the software that we will use during the course of the week.\nThe software is listed by availability (i.e., open source, license, package add-on)",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Open Source Software</span>"
    ]
  },
  {
    "objectID": "open-source-software.html#open-source-software",
    "href": "open-source-software.html#open-source-software",
    "title": "Open Source Software",
    "section": "Open Source Software",
    "text": "Open Source Software\n\nR\nIMHO the best statistical analysis tool ever created (yes, better than python for statistics)\n\nIn this class we will use both R and RStudio (the GUI for R) which can be downloaded here: RStudio Desktop - Posit\n\n\n\njamovi\nThe next best option, it is built on an R framework, nobody will know you are NOT using R :)\njamovi is a new “3rd generation” statistical spreadsheet designed from the ground up to be easy to use. jamovi is a compelling alternative to costly statistical products such as SPSS and SAS. It is also a simpler alternative to R that is built on top of the R statistical language.\nFeatures:\n\nAnalyses: jamovi provides a complete suite of analyses for (not just) the social sciences; t-tests, ANOVAs, correlation and regression, non-parametric tests, contingency tables, reliability and factor analysis. The jamovi library contains many more libraries that will allow you to perform additional analyses from simple crosstabs to multilevel modeling and more.\nExcel integration: jamovi is a fully functional spreadsheet, immediately familiar to anyone. Enter, copy/paste data, filter rows, compute new values, perform transforms across many columns at once – jamovi provides a streamlined spreadsheet experience, optimized for statistical data.\nR syntax: Love R? Check out jamovi’s “syntax mode”, where the underlying R syntax for each analysis is made available. Just copy and paste this into R for a seamless transition. Alternatively, run R code directly inside jamovi with the Rj Editor.\n\nTwo versions of jamovi:\n\njamovi Cloud\njamovi desktop – downloads and installs jamovi onto your desktop\n\nIt is available for Windows, Mac and Linux\n\n\n\n\nJASP - A Fresh Way to Do Statistics\n“Just Another Statistics Program” JASP offers another great alternative to SPSS. Visit jasp-stats.org\n\nIn some ways JASP is better than jamovi, but it seems less stable and so it is my second best option\nThere are some benefits to using JASP including flexibility in making plots and nice visualizations for the statistical analyses you are conducting\nClick here to download JASP\nJASP in particular provides a great way to both learn statistics and R at the same time\nLet’s take a look at the data library in JASP now\n\n\n\nQGIS\n“Quantum Geographical Information Systems” allows you to do geospatial analysis like a (ArcGIS) pro – QGIS is great for creating, editing, visualizing, analyzing and publishing geospatial information\n\nThe Applications page gives you a sense of all the cool things you can do with QGIS\nTo download the software click here\n\n\n\nPSPP\nPSPP - GNU Project - Free Software Foundation is an open source equivalent to SPSS and it is freely downloadable. It is not very robust and so I would not recommend it.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Open Source Software</span>"
    ]
  },
  {
    "objectID": "open-source-software.html#proprietary-software",
    "href": "open-source-software.html#proprietary-software",
    "title": "Open Source Software",
    "section": "Proprietary Software",
    "text": "Proprietary Software\nOSU has obtained a license for the following software packages:\n\nSPSS: It’s like a necessary evil - everyone must know how to use SPSS. There are some things that are actually easier in SPSS\nSAS: ugh!\nEXCEL: Can be great to clean your data, particularly if you use the built-in functions\nArcGIS Map, Pro\njmp: This is a very cool data science program from the makers of SAS (the archaic and soon to be extinct software program)\n\nTo download these software packages: Log In to the Office of Business and Finance",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Open Source Software</span>"
    ]
  },
  {
    "objectID": "r-style.html",
    "href": "r-style.html",
    "title": "R Style Suggestions",
    "section": "",
    "text": "Introduction\nR is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\nBut you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>R Style Suggestions</span>"
    ]
  },
  {
    "objectID": "r-style.html#introduction",
    "href": "r-style.html#introduction",
    "title": "R Style Suggestions",
    "section": "",
    "text": "mpg %&gt;% \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg %&gt;% filter(cty &gt; 10, class == \"compact\")\n\nmpg %&gt;% \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg %&gt;% filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg %&gt;% \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\n\n\n\n\n\n\n\nTipRStudio Auto-formatting\n\n\n\nRStudio has a built-in way of cleaning up your code. Select some code, press Ctrl + I (on Windows) or ⌘ + I (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>R Style Suggestions</span>"
    ]
  },
  {
    "objectID": "r-style.html#main-style-things-to-pay-attention-to-for-this-class",
    "href": "r-style.html#main-style-things-to-pay-attention-to-for-this-class",
    "title": "R Style Suggestions",
    "section": "Main Style Things to Pay Attention to for This Class",
    "text": "Main Style Things to Pay Attention to for This Class\n\n\n\n\n\n\nNoteImportant Note\n\n\n\nI won’t ever grade you on any of this! If you submit something like filter(mpg,cty&gt;10,class==\"compact\"), I might recommend adding spaces, but it won’t affect your grade or points or anything.\n\n\n\nSpacing\nSee the “Spacing” section in the tidyverse style guide.\nPut spaces after commas (like in regular English):\n\nGoodBad\n\n\nfilter(mpg, cty &gt; 10)\n\n\nfilter(mpg , cty &gt; 10)\nfilter(mpg ,cty &gt; 10)\nfilter(mpg,cty &gt; 10)\n\n\n\nPut spaces around operators like +, -, &gt;, =, etc.:\n\nGoodBad\n\n\nfilter(mpg, cty &gt; 10)\n\n\nfilter(mpg, cty&gt;10)\nfilter(mpg, cty&gt; 10)\nfilter(mpg, cty &gt;10)\n\n\n\nDon’t put spaces around parentheses that are parts of functions:\n\nGoodBad\n\n\nfilter(mpg, cty &gt; 10)\n\n\nfilter (mpg, cty &gt; 10)\nfilter ( mpg, cty &gt; 10)\nfilter( mpg, cty &gt; 10 )\n\n\n\n\n\nLong Lines\nSee the “Long lines” section in the tidyverse style guide.\nIt’s generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters.\n\n\n\n\n\n\nTipShow Margin in RStudio\n\n\n\nInstead of counting characters by hand (ew), in RStudio go to “Tools” &gt; “Global Options” &gt; “Code” &gt; “Display” and check the box for “Show margin”. You should now see a really thin line indicating 80 characters. Again, you can go beyond this—that’s fine. It’s just good practice to avoid going too far past it.\n\n\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n\nGoodBadBetter\n\n\nfilter(mpg, cty &gt; 10, class == \"compact\")\n\nfilter(mpg, cty &gt; 10, \n       class == \"compact\")\n\nfilter(mpg,\n       cty &gt; 10,\n       class == \"compact\")\n\n\nfilter(mpg, cty &gt; 10, class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \"suv\", \"2seater\", \"minivan\"))\n\n\nfilter(mpg, \n       cty &gt; 10, \n       class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \n                    \"suv\", \"2seater\", \"minivan\"))\n\n\n\n\n\nPipes (%&gt;%) and ggplot Layers (+)\nggplot layers: Put each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n\nGoodBadSuper BadSuper Bad (Won’t Work!)\n\n\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth() +\n  theme_bw()\n\n\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() + geom_smooth() +\n  theme_bw()\n\n\nggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw()\n\n\nggplot(mpg, aes(x = cty, y = hwy, color = class))\n  + geom_point()\n  + geom_smooth() \n  + theme_bw()\n\n\n\ndplyr pipelines: Put each step in a dplyr pipeline on separate lines, with the %&gt;% at the end of the line, indented with two spaces:\n\nGoodBadSuper BadSuper Bad (Won’t Work!)\n\n\nmpg %&gt;% \n  filter(cty &gt; 10) %&gt;% \n  group_by(class) %&gt;% \n  summarize(avg_hwy = mean(hwy))\n\n\nmpg %&gt;% filter(cty &gt; 10) %&gt;% group_by(class) %&gt;% \n  summarize(avg_hwy = mean(hwy))\n\n\nmpg %&gt;% filter(cty &gt; 10) %&gt;% group_by(class) %&gt;% summarize(avg_hwy = mean(hwy))\n\n\nmpg %&gt;% \n  filter(cty &gt; 10)\n  %&gt;% group_by(class)\n  %&gt;% summarize(avg_hwy = mean(hwy))\n\n\n\n\n\nComments\nSee the “Comments” section in the tidyverse style guide.\nComments should start with a comment symbol and a single space: #\n\nGoodBad\n\n\n# Good\n\n\n#Bad\n\n    #Bad\n\n\n\nIf the comment is really short (and won’t cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\nmpg %&gt;% \n  filter(cty &gt; 10) %&gt;%  # Only rows where cty is 10 +\n  group_by(class) %&gt;%  # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\nYou can add extra spaces to get inline comments to align, if you want:\nmpg %&gt;% \n  filter(cty &gt; 10) %&gt;%            # Only rows where cty is 10 +\n  group_by(class) %&gt;%             # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\nIf the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to “Code” &gt; “Reflow comment”\n\nGoodBad\n\n\n# Happy families are all alike; every unhappy family is unhappy in its own way.\n# Everything was in confusion in the Oblonskys' house. The wife had discovered\n# that the husband was carrying on an intrigue with a French girl, who had been\n# a governess in their family, and she had announced to her husband that she\n# could not go on living in the same house with him. This position of affairs\n# had now lasted three days, and not only the husband and wife themselves, but\n# all the members of their family and household, were painfully conscious of it.\n\n\n# Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys' house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThough, if you’re dealing with comments that are that long, consider putting the text in R Markdown instead and having it be actual prose.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>R Style Suggestions</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html",
    "href": "assessment_ans.html",
    "title": "Statistics II Initial Assessment",
    "section": "",
    "text": "Question 1: Introduction to Data\nQuestion: The table below describes an intervention to reduce PTSD among violence-exposed youth.\nAnswer:",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-1-introduction-to-data",
    "href": "assessment_ans.html#question-1-introduction-to-data",
    "title": "Statistics II Initial Assessment",
    "section": "",
    "text": "0-365 days PTSD\n0-365 days No PTSD\n\n\n\n\nTreatment\n45\n179\n\n\nControl\n28\n199\n\n\n\n\nAmong all youth in a treatment group, what proportion had PTSD by the end of the first year?\nWhat proportion of youth had PTSD in the control group by the end of the first year?\n\n\n\n1a. Treatment: \\(\\frac{45}{224} = 0.201\\) or \\(20.1\\%\\)\n1b. Control: \\(\\frac{28}{227} = 0.123\\) or \\(12.3\\%\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-2-independence",
    "href": "assessment_ans.html#question-2-independence",
    "title": "Statistics II Initial Assessment",
    "section": "Question 2: Independence",
    "text": "Question 2: Independence\nQuestion: True or False: A pair of variables are either related or not (independent). Two variables can’t be both associated and independent.\nAnswer: True\nTwo variables cannot be both associated and independent. Independence means that knowing the value of one variable provides no information about the other variable. If variables are associated (related), they are by definition not independent.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-3a-b-interquartile-range",
    "href": "assessment_ans.html#question-3a-b-interquartile-range",
    "title": "Statistics II Initial Assessment",
    "section": "Question 3a-b: Interquartile Range",
    "text": "Question 3a-b: Interquartile Range\nQuestion:\n\nAssume that \\(Q_1\\) describes the 25th percentile. Define \\(Q_1\\) in words.\nAssume \\(Q_3\\) is the 75th percentile. \\(Q_3 = 300\\); \\(Q_1 = 100\\). Calculate the IQR.\n\nAnswer:\n3a. \\(Q_1\\) is the value below which \\(25\\%\\) of the data falls. It represents the first quartile, meaning one-quarter of observations are smaller than this value.\n3b. \\(\\text{IQR} = Q_3 - Q_1 = 300 - 100 = 200\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-3c-iqr-vs-standard-deviation",
    "href": "assessment_ans.html#question-3c-iqr-vs-standard-deviation",
    "title": "Statistics II Initial Assessment",
    "section": "Question 3c: IQR vs Standard Deviation",
    "text": "Question 3c: IQR vs Standard Deviation\nQuestion: Describe why extreme observations affect the standard deviation more than the interquartile range (IQR).\nAnswer:\nThe IQR uses only the middle \\(50\\%\\) of data, ignoring the top and bottom \\(25\\%\\). Standard deviation uses squared deviations from the mean, so extreme values (which have large deviations) are squared and heavily weighted. The IQR is resistant to outliers; SD is not.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-4-contingency-tables",
    "href": "assessment_ans.html#question-4-contingency-tables",
    "title": "Statistics II Initial Assessment",
    "section": "Question 4: Contingency Tables",
    "text": "Question 4: Contingency Tables\nQuestion: Use the table below to answer the following questions:\n\n\n\n\nNone\nSmall\nBig\nTotal\n\n\n\n\nYes\n.406\n.458\n.136\n1\n\n\nNo\n.113\n.748\n.139\n1\n\n\n\n\nWhat does the .458 represent in the table?\nWhat does the .139 at the intersection of No and Big represent?\n\nAnswer:\n4a. The .458 represents \\(P(\\text{Small}|\\text{Yes}) = 45.8\\%\\) - the conditional probability of “Small” given “Yes”\n4b. The .139 represents \\(P(\\text{Big}|\\text{No}) = 13.9\\%\\) - the conditional probability of “Big” given “No”",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-5-probability-distributions",
    "href": "assessment_ans.html#question-5-probability-distributions",
    "title": "Statistics II Initial Assessment",
    "section": "Question 5: Probability Distributions",
    "text": "Question 5: Probability Distributions\nQuestion: The table below suggests three salary distributions for social workers in Columbus. Only one is correct. Which one must it be? What is wrong with the other two?\n\n\n\nIncome ($1000s)\n0-25\n25-50\n50-100\n100+\n\n\n\n\nA\n.18\n.39\n.33\n.16\n\n\nB\n.38\n-.27\n.52\n.37\n\n\nC\n.28\n.27\n.29\n.16\n\n\n\nAnswer:\nCorrect: A (probabilities sum to \\(1.06 \\approx 1.00\\))\nB is wrong: Contains negative probability \\((-.27)\\), which is impossible\nC is wrong: Sums to exactly \\(1.00\\) but appears less plausible than A given context",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-6a-b-independent-random-variables",
    "href": "assessment_ans.html#question-6a-b-independent-random-variables",
    "title": "Statistics II Initial Assessment",
    "section": "Question 6a-b: Independent Random Variables",
    "text": "Question 6a-b: Independent Random Variables\nQuestion: About 9% of people exposed to a natural disaster develop PTSD. Suppose 2 people are selected at random. Assume independence.\n\nWhat is the probability they both developed symptoms?\nWhat is the probability that neither did?\n\nAnswer:\n6a. \\(P(\\text{both}) = 0.09 \\times 0.09 = 0.0081\\) or \\(0.81\\%\\)\n6b. \\(P(\\text{neither}) = 0.91 \\times 0.91 = 0.8281\\) or \\(82.81\\%\\)\nNote: this is also \\((1-0.09) \\times (1-0.09) = 0.8281\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-6c-independence-explained",
    "href": "assessment_ans.html#question-6c-independence-explained",
    "title": "Statistics II Initial Assessment",
    "section": "Question 6c: Independence Explained",
    "text": "Question 6c: Independence Explained\nQuestion: Explain what ‘independence’ means and why your calculation depends on this assumption.\nAnswer:\nIndependence means one person developing PTSD doesn’t affect the probability of another person developing PTSD. The events are unrelated.\nWe can multiply individual probabilities only under independence: \\(P(A \\cap B) = P(A) \\times P(B)\\).\nWithout independence, we’d need conditional probabilities: \\(P(A \\cap B) = P(A) \\times P(B|A)\\).",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-7-five-independent-people",
    "href": "assessment_ans.html#question-7-five-independent-people",
    "title": "Statistics II Initial Assessment",
    "section": "Question 7: Five Independent People",
    "text": "Question 7: Five Independent People\nQuestion: Use the data from above. Now, suppose 5 people are selected at random.\n\nWhat is the probability they all develop PTSD symptoms?\nWhat is the probability none did?\n\nAnswer:\n7a. \\(P(\\text{all 5}) = (0.09)^5 = 0.0000059 \\approx 0.00059\\%\\)\n7b. \\(P(\\text{none}) = (0.91)^5 = 0.6240\\) or \\(62.40\\%\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-8-covid-19-conditional-probability",
    "href": "assessment_ans.html#question-8-covid-19-conditional-probability",
    "title": "Statistics II Initial Assessment",
    "section": "Question 8: COVID-19 Conditional Probability",
    "text": "Question 8: COVID-19 Conditional Probability\nQuestion: Find the probability a randomly selected person who was not given the COVID-19 vaccine died from COVID using the following table:\n\n\n\n\nVaccinated Yes\nVaccinated No\n\n\n\n\nLived\n.0382\n.8252\n\n\nDied\n.0010\n.1356\n\n\n\nAnswer:\n\\[P(\\text{Died}|\\text{Not Vaccinated}) = \\frac{P(\\text{Not Vax} \\cap \\text{Died})}{P(\\text{Not Vax})}\\]\n\\[= \\frac{0.1356}{0.8252 + 0.1356} = \\frac{0.1356}{0.9608} = 0.1411 \\text{ or } 14.11\\%\\]",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-9a-tree-diagram",
    "href": "assessment_ans.html#question-9a-tree-diagram",
    "title": "Statistics II Initial Assessment",
    "section": "Question 9a: Tree Diagram",
    "text": "Question 9a: Tree Diagram\nQuestion: Create a tree diagram for the COVID-19 vaccination data.\nAnswer:\nStart \n├─ Vaccinated (0.0392)\n│  ├─ Lived (0.0382)\n│  └─ Died (0.0010)\n│\n└─ Not Vaccinated (0.9608)\n   ├─ Lived (0.8252)\n   └─ Died (0.1356)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-9b-c-tree-diagram-probabilities",
    "href": "assessment_ans.html#question-9b-c-tree-diagram-probabilities",
    "title": "Statistics II Initial Assessment",
    "section": "Question 9b-c: Tree Diagram Probabilities",
    "text": "Question 9b-c: Tree Diagram Probabilities\nQuestion: Use the tree diagram to calculate:\n\nThe probability that a random person was vaccinated and lived\nThe probability that the person died (regardless of vaccination status)\n\nAnswer:\n9b. \\(P(\\text{Vaccinated} \\cap \\text{Lived}) = 0.0382\\)\n9c. \\(P(\\text{Died}) = P(\\text{Vax} \\cap \\text{Died}) + P(\\text{Not Vax} \\cap \\text{Died})\\)\n\\[= 0.0010 + 0.1356 = 0.1366 \\text{ or } 13.66\\%\\]",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-10-mean-variance-sd",
    "href": "assessment_ans.html#question-10-mean-variance-sd",
    "title": "Statistics II Initial Assessment",
    "section": "Question 10: Mean, Variance, SD",
    "text": "Question 10: Mean, Variance, SD\nQuestion: Compute the variable’s mean, variance, and standard deviation.\n\n\n\n\\(x_i\\)\n\\(P(X = x_i)\\)\n\\(x_i \\cdot P(X = x_i)\\)\n\n\n\n\n0\n0.20\n0.00\n\n\n137\n0.55\n75.35\n\n\n170\n0.25\n42.50\n\n\n\nAnswer:\nMean: \\(\\mu = \\sum[x_i \\cdot P(x_i)] = 0.00 + 75.35 + 42.50 = 117.85\\)\nVariance: \\(\\sigma^2 = \\sum[(x_i - \\mu)^2 \\cdot P(x_i)]\\)\n\n\\((0 - 117.85)^2 \\times 0.20 = 2{,}777.70\\)\n\\((137 - 117.85)^2 \\times 0.55 = 201.70\\)\n\\((170 - 117.85)^2 \\times 0.25 = 679.56\\)\n\\(\\sigma^2 = 3{,}659\\)\n\nStandard Deviation: \\(\\sigma = \\sqrt{3{,}659} = 60\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-11-z-scores",
    "href": "assessment_ans.html#question-11-z-scores",
    "title": "Statistics II Initial Assessment",
    "section": "Question 11: Z-scores",
    "text": "Question 11: Z-scores\nQuestion: Let \\(X\\) represent a random variable from \\(N(\\mu = 3, \\sigma = 2)\\). Suppose we observe that \\(x = 5.19\\).\n\nFind the Z-score of \\(x\\)\nUse the Z-score to determine how many standard deviations above or below the mean, \\(x\\), falls.\n\nAnswer:\n11a. \\(Z = \\frac{x - \\mu}{\\sigma} = \\frac{5.19 - 3}{2} = 1.095\\)\n11b. The observation \\(x = 5.19\\) falls 1.095 standard deviations above the mean.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-12a-c-licensing-exam-z-scores",
    "href": "assessment_ans.html#question-12a-c-licensing-exam-z-scores",
    "title": "Statistics II Initial Assessment",
    "section": "Question 12a-c: Licensing Exam Z-scores",
    "text": "Question 12a-c: Licensing Exam Z-scores\nQuestion: The social work licensing exam follows a nearly normal distribution with mean 92.6 and standard deviation 3.6.\n\nCompute the Z-score for an exam score of 95.4\nCompute the Z-score for an exam of 85.8\nWhich of the two observations is more unusual?\n\nAnswer:\n12a. \\(Z = \\frac{95.4 - 92.6}{3.6} = 0.778\\)\n12b. \\(Z = \\frac{85.8 - 92.6}{3.6} = -1.889\\)\n12c. The score of 85.8 is more unusual \\((|Z| = 1.889 \\text{ vs. } 0.778)\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-12d-e-percentiles",
    "href": "assessment_ans.html#question-12d-e-percentiles",
    "title": "Statistics II Initial Assessment",
    "section": "Question 12d-e: Percentiles",
    "text": "Question 12d-e: Percentiles\nQuestion:\n\nBoth students come to you to calculate and interpret their percentile on the exam.\nWhat proportion of test takers scored higher than these two?\n\nAnswer:\n12d. Percentiles:\n\nScore 95.4 \\((Z = 0.778)\\): approximately 78th percentile\nScore 85.8 \\((Z = -1.889)\\): approximately 3rd percentile\n\n12e. Proportion scoring higher:\n\nHigher than 95.4: approximately \\(22\\%\\)\nHigher than 85.8: approximately \\(97\\%\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-13a-b-sat-scores",
    "href": "assessment_ans.html#question-13a-b-sat-scores",
    "title": "Statistics II Initial Assessment",
    "section": "Question 13a-b: SAT Scores",
    "text": "Question 13a-b: SAT Scores\nQuestion: The SAT test is approximately normally distributed with \\(\\mu = 1500\\), \\(\\sigma = 300\\).\n\nWhat is the probability of scoring at least 1630 on the SAT?\nOne year something unusual happened and more than 75% of test takers scored above 1600. How does that affect the calculation?\n\nAnswer:\n13a. \\(Z = \\frac{1630 - 1500}{300} = 0.433\\)\n\\(P(X \\geq 1630) \\approx 0.3325\\) or \\(33.25\\%\\)\n13b. This violates normality assumptions. If \\(75\\%\\) scored above 1600, the distribution is no longer \\(N(1500, 300)\\). We cannot use normal distribution calculations; we’d need the actual distribution.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-13c-social-justice",
    "href": "assessment_ans.html#question-13c-social-justice",
    "title": "Statistics II Initial Assessment",
    "section": "Question 13c: Social Justice",
    "text": "Question 13c: Social Justice\nQuestion: From a social justice standpoint, describe the problem with interpreting aptitude using a statistical analysis.\nAnswer:\nAptitude tests may reflect socioeconomic advantages (test prep access, quality education, tutoring, educational resources) rather than innate ability. They can perpetuate inequality by disadvantaging students from under-resourced backgrounds, marginalized communities, and those who lack access to test preparation resources. Statistical analysis treats scores as objective measures but ignores systemic inequities.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-14-binomial-distribution",
    "href": "assessment_ans.html#question-14-binomial-distribution",
    "title": "Statistics II Initial Assessment",
    "section": "Question 14: Binomial Distribution",
    "text": "Question 14: Binomial Distribution\nQuestion: On 70% of days, a therapist’s office admits at least one new client. On 30% of the days, no clients are admitted. What is the probability that the therapist will admit a new client on exactly three days this week?\nAnswer:\nUsing binomial theorem: \\(P(X = 3) = \\binom{7}{3} \\times (0.70)^3 \\times (0.30)^4\\)\n\n\\(\\binom{7}{3} = 35\\)\n\\((0.70)^3 = 0.343\\)\n\\((0.30)^4 = 0.0081\\)\n\\(P(X = 3) = 35 \\times 0.343 \\times 0.0081 = 0.0972\\) or \\(9.72\\%\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-15a-hypothesis-testing-framework",
    "href": "assessment_ans.html#question-15a-hypothesis-testing-framework",
    "title": "Statistics II Initial Assessment",
    "section": "Question 15a: Hypothesis Testing Framework",
    "text": "Question 15a: Hypothesis Testing Framework\nQuestion: A US court is weighing two possible claims about a defendant: she is not guilty or guilty. How can a hypothesis testing framework be used to evaluate these claims?\nAnswer:\n\n\\(H_0\\) (null hypothesis): Defendant is not guilty\n\\(H_1\\) (alternative hypothesis): Defendant is guilty\nBurden of proof is on prosecution to reject \\(H_0\\)\nRequires evidence “beyond reasonable doubt” (like \\(\\alpha\\) level)\nType I error: Convicting an innocent person\nType II error: Acquitting a guilty person",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-15b-innocent-vs-not-guilty",
    "href": "assessment_ans.html#question-15b-innocent-vs-not-guilty",
    "title": "Statistics II Initial Assessment",
    "section": "Question 15b: Innocent vs Not Guilty",
    "text": "Question 15b: Innocent vs Not Guilty\nQuestion: What is the problem with falsely using the term ‘innocent’ rather than ‘not guilty’ in this framework?\nAnswer:\n“Not guilty” means insufficient evidence to prove guilt beyond reasonable doubt. “Innocent” implies proof of non-involvement.\nCourts don’t prove innocence; they determine if guilt is proven. This mirrors statistics: we reject or fail to reject \\(H_0\\), but never “accept” or “prove” \\(H_0\\). Failing to reject \\(H_0 \\neq\\) proving \\(H_0\\) is true.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-16a-confidence-interval",
    "href": "assessment_ans.html#question-16a-confidence-interval",
    "title": "Statistics II Initial Assessment",
    "section": "Question 16a: Confidence Interval",
    "text": "Question 16a: Confidence Interval\nQuestion: In a sample of 100 students from the 2022 NCHS, the average number of days per year a child was reported ill was 2.78, with a standard deviation of 2.56 days. Compute a 95% confidence interval. Assume conditions for normality are met.\nAnswer:\n\\[SE = \\frac{s}{\\sqrt{n}} = \\frac{2.56}{\\sqrt{100}} = 0.256\\]\n\\[95\\% \\text{ CI} = \\bar{x} \\pm (1.96 \\times SE) = 2.78 \\pm (1.96 \\times 0.256)\\]\n\\[= 2.78 \\pm 0.502\\]\n95% CI: (2.28, 3.28) days",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-16b-ci-interpretation",
    "href": "assessment_ans.html#question-16b-ci-interpretation",
    "title": "Statistics II Initial Assessment",
    "section": "Question 16b: CI Interpretation",
    "text": "Question 16b: CI Interpretation\nQuestion: Interpret the confidence interval.\nAnswer:\nWe are 95% confident that the true average number of days per year all children in the NCHS population are reported ill falls between 2.28 and 3.28 days.\nThis means if we repeated this sampling process many times, approximately 95% of the resulting confidence intervals would contain the true population mean.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-17-hypothesis-setup",
    "href": "assessment_ans.html#question-17-hypothesis-setup",
    "title": "Statistics II Initial Assessment",
    "section": "Question 17: Hypothesis Setup",
    "text": "Question 17: Hypothesis Setup\nQuestion: UCLA estimates the cost of in-state tuition is $23,000/year. I estimate it at $33,000/year. What are the null and alternative hypotheses to test whether this claim is accurate?\nAnswer:\n\\(H_0: \\mu = \\$23{,}000\\) (UCLA’s estimate is correct)\n\\(H_1: \\mu \\neq \\$23{,}000\\) (UCLA’s estimate is not correct)\nThis is a two-tailed test since we’re testing whether the claim is accurate (could be higher or lower), not specifically testing a directional hypothesis.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-18-p-value-vs-significance-level",
    "href": "assessment_ans.html#question-18-p-value-vs-significance-level",
    "title": "Statistics II Initial Assessment",
    "section": "Question 18: P-value vs Significance Level",
    "text": "Question 18: P-value vs Significance Level\nQuestion: What is the substantive difference between a p-value and the significance level of a test?\nAnswer:\nP-value: The probability of observing data as extreme as (or more extreme than) what we observed, assuming \\(H_0\\) is true. Calculated from the data after the study.\nSignificance level \\((\\alpha)\\): The threshold we set before conducting the test to determine whether to reject \\(H_0\\). Chosen by the researcher (commonly 0.05).\nKey difference: \\(\\alpha\\) is predetermined; p-value is calculated. We reject \\(H_0\\) if p-value \\(&lt; \\alpha\\).",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-19-p-value-frequency",
    "href": "assessment_ans.html#question-19-p-value-frequency",
    "title": "Statistics II Initial Assessment",
    "section": "Question 19: P-value Frequency",
    "text": "Question 19: P-value Frequency\nQuestion: If the null hypothesis is true, how often should the p-value be less than .10?\nAnswer:\n10% of the time\nIf the null hypothesis is true, the p-value follows a uniform distribution between 0 and 1. Therefore, \\(P(\\text{p-value} &lt; 0.10) = 0.10\\).\nThis is exactly the definition of the significance level—it represents the probability of a Type I error (rejecting a true null hypothesis).",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-20-practical-vs-statistical-significance",
    "href": "assessment_ans.html#question-20-practical-vs-statistical-significance",
    "title": "Statistics II Initial Assessment",
    "section": "Question 20: Practical vs Statistical Significance",
    "text": "Question 20: Practical vs Statistical Significance\nQuestion: Describe the difference between practical and statistical significance. Provide an example.\nAnswer:\nStatistical significance: Result is unlikely due to chance alone (p-value \\(&lt; \\alpha\\)). Depends on sample size.\nPractical significance: Result is meaningful in real-world terms. Depends on effect size.\nExample: With \\(n=1{,}000{,}000\\), a reading intervention increases test scores by 0.5 points \\((p &lt; 0.001)\\). Statistically significant but practically meaningless—0.5 points won’t change educational outcomes. A 10-point increase might be practically significant even if \\(p = 0.06\\).",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-21-dependent-sample-t-test",
    "href": "assessment_ans.html#question-21-dependent-sample-t-test",
    "title": "Statistics II Initial Assessment",
    "section": "Question 21: Dependent Sample t-test",
    "text": "Question 21: Dependent Sample t-test\nQuestion: Set up and implement a hypothesis test to determine whether, on average, there is a difference in outcomes for the treatment and control group using a dependent sample t-test. Summary statistics: \\(N=73\\); mean difference \\(= 12.76\\), SD of difference \\(= 14.26\\).\nAnswer:\nHypotheses: \\(H_0: \\mu_{\\text{diff}} = 0\\) vs. \\(H_1: \\mu_{\\text{diff}} \\neq 0\\)\n\\[SE = \\frac{14.26}{\\sqrt{73}} = 1.669\\]\n\\[t = \\frac{12.76}{1.669} = 7.65, \\quad df = 72\\]\nConclusion: With \\(t = 7.65\\), \\(p &lt; 0.001\\). We reject \\(H_0\\). Strong evidence of a significant difference between treatment and control groups.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-22a-b-independent-samples-t-test",
    "href": "assessment_ans.html#question-22a-b-independent-samples-t-test",
    "title": "Statistics II Initial Assessment",
    "section": "Question 22a-b: Independent Samples t-test",
    "text": "Question 22a-b: Independent Samples t-test\nQuestion: The summary statistics below show newborn weights for mothers who smoked and did not smoke during pregnancy.\n\n\n\n\nSmoked\nDid not smoke\n\n\n\n\nMean\n6.78\n7.18\n\n\nSt. Dev.\n1.43\n1.6\n\n\nN\n50\n100\n\n\n\n\nWhat is the estimate of the population difference?\nCompute the standard error of the estimate from (a)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-22-answer",
    "href": "assessment_ans.html#question-22-answer",
    "title": "Statistics II Initial Assessment",
    "section": "Question 22: Answer",
    "text": "Question 22: Answer\n22a. Estimate of population difference:\n\\[\\bar{x}_1 - \\bar{x}_2 = 6.78 - 7.18 = -0.40 \\text{ pounds}\\]\nBabies born to mothers who smoked weighed on average 0.40 pounds less.\n22b. Standard error:\n\\[SE = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\\]\n\\[SE = \\sqrt{\\frac{1.43^2}{50} + \\frac{1.6^2}{100}}\\]\n\\[SE = \\sqrt{0.0409 + 0.0256} = \\sqrt{0.0665} = 0.258 \\text{ pounds}\\]",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-23a-anova-hypotheses",
    "href": "assessment_ans.html#question-23a-anova-hypotheses",
    "title": "Statistics II Initial Assessment",
    "section": "Question 23a: ANOVA Hypotheses",
    "text": "Question 23a: ANOVA Hypotheses\nQuestion: College departments offer many lectures of the same course. CSW offers three lectures of an intro stats course to PhD students (A, B, and C). Describe the appropriate hypotheses to determine whether there are any differences between the classes.\nAnswer:\n\\(H_0: \\mu_A = \\mu_B = \\mu_C\\)\n(No difference in mean exam scores across the three classes)\n\\(H_1:\\) At least one class mean differs from the others\n(At least one \\(\\mu_i \\neq \\mu_j\\) for some \\(i \\neq j\\))",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#question-23b-anova-results",
    "href": "assessment_ans.html#question-23b-anova-results",
    "title": "Statistics II Initial Assessment",
    "section": "Question 23b: ANOVA Results",
    "text": "Question 23b: ANOVA Results\nQuestion: An ANOVA was conducted, and the summary results are below. Is the difference significant at the .05 level? Why or why not?\n\n\n\nSource\nDf\nSum Sq\nMean Sq\nF-Value\np-value\n\n\n\n\nClass\n2\n1290.11\n645.06\n3.48\n.033\n\n\nResiduals\n161\n29810.13\n185.16\n\n\n\n\n\nAnswer:\nYes, the difference is significant at \\(\\alpha = 0.05\\).\nThe p-value \\(= 0.033 &lt; 0.05\\), so we reject the null hypothesis. There is statistically significant evidence that at least one class has a different mean exam score than the others.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#part-ii-applied-analysis-overview",
    "href": "assessment_ans.html#part-ii-applied-analysis-overview",
    "title": "Statistics II Initial Assessment",
    "section": "Part II: Applied Analysis Overview",
    "text": "Part II: Applied Analysis Overview\nRequirements:\nThe applied section requires:\n\nWhat is the prevalence of concussion or brain injury in children? (Use appropriate test statistic)\nAre there racial differences in concussion or brain injury? (Use the race variable)\nAre children with concussion/brain injury more likely to bully others? (Compare “not a bully” to categories 2-7)\nProvide a compelling visualization OR interpretation with 1-2 sentences on implications",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#part-ii-analysis-approach",
    "href": "assessment_ans.html#part-ii-analysis-approach",
    "title": "Statistics II Initial Assessment",
    "section": "Part II: Analysis Approach",
    "text": "Part II: Analysis Approach\nData Source: 2023 National Child Health Survey (NSCH)\nStatistical Methods:\n\nPrevalence (Q a): Calculate proportion with 95% CI; one-sample proportion test\nRacial differences (Q b): Chi-square test of independence\nBullying relationship (Q c): Chi-square test or two-proportion z-test\n\nVisualization Options:\n\nBar charts showing prevalence by race\nMosaic plots for categorical relationships\nForest plots for effect sizes across groups\n\nNote: Requires external data download and statistical software (SAS/STATA/R)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  },
  {
    "objectID": "assessment_ans.html#summary",
    "href": "assessment_ans.html#summary",
    "title": "Statistics II Initial Assessment",
    "section": "Summary",
    "text": "Summary\nKey Concepts Covered:\n\nDescriptive statistics and probability theory\nIndependence and conditional probability\nZ-scores and normal distributions\nHypothesis testing frameworks (legal analogy)\nConfidence intervals and interpretation\nt-tests (dependent and independent samples)\nANOVA for comparing multiple groups\nStatistical vs. practical significance\nApplied data analysis with real-world implications\n\nRemember: Statistics is about choosing the right method for the research question and interpreting findings for policy and social justice implications.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Statistics II Initial Assessment</span>"
    ]
  }
]